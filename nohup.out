2019-10-07 08:25:36.638249: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2
2019-10-07 08:25:36.716247: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3466855000 Hz
2019-10-07 08:25:36.736851: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55cbdfdbc3e0 executing computations on platform Host. Devices:
2019-10-07 08:25:36.736915: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
Using TensorFlow backend.
WARNING:tensorflow:From /home/kraljiva/miniconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /home/kraljiva/miniconda3/envs/keras/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From /home/kraljiva/miniconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
StratifiedKFold(n_splits=5, random_state=42, shuffle=True)
flst [bottles]
load fdb /home/kraljiva/Projects/uasr-data/bottles/Versuch004_E/log/fdb
save fdb /home/kraljiva/Projects/uasr-data/bottles/Versuch004_E/log/fdb [14 blocks]
trnargs = {'batch_size':32,'max_iter':200,'lay':[('ip',256),('lrelu',),('batch',),('dropout',0.6), ('ip',128),('lrelu',),('batch',),('dropout',0.6)],'base_lr':0.0005,'optimizer':'adagrad','val_split':0.2,'monitor': 'val_loss','patience':10, 'stop': True}
Keras TF start  snn_sig_bottles_0
Train DNN with Keras
Train on 3123 samples, validate on 781 samples
Epoch 1/200
 - 28s - loss: 1.4055 - acc: 0.7826 - val_loss: 0.8439 - val_acc: 0.9744
Epoch 2/200
 - 23s - loss: 0.9358 - acc: 0.9075 - val_loss: 0.7002 - val_acc: 0.9744
Epoch 3/200
 - 23s - loss: 0.7302 - acc: 0.9420 - val_loss: 0.5895 - val_acc: 0.9744
Epoch 4/200
 - 23s - loss: 0.5927 - acc: 0.9574 - val_loss: 0.5145 - val_acc: 0.9744
Epoch 5/200
 - 23s - loss: 0.5117 - acc: 0.9600 - val_loss: 0.5096 - val_acc: 0.9744
Epoch 6/200
 - 23s - loss: 0.4760 - acc: 0.9613 - val_loss: 0.4340 - val_acc: 0.9744
Epoch 7/200
 - 23s - loss: 0.4175 - acc: 0.9683 - val_loss: 0.3944 - val_acc: 0.9744
Epoch 8/200
 - 23s - loss: 0.3915 - acc: 0.9622 - val_loss: 0.3989 - val_acc: 0.9744
Epoch 9/200
 - 23s - loss: 0.3616 - acc: 0.9689 - val_loss: 0.3600 - val_acc: 0.9744
Epoch 10/200
 - 23s - loss: 0.3344 - acc: 0.9750 - val_loss: 0.3429 - val_acc: 0.9744
Epoch 11/200
 - 21s - loss: 0.3311 - acc: 0.9763 - val_loss: 0.3740 - val_acc: 0.9744
Epoch 12/200
 - 21s - loss: 0.3004 - acc: 0.9782 - val_loss: 0.3624 - val_acc: 0.9744
Epoch 13/200
 - 21s - loss: 0.2936 - acc: 0.9785 - val_loss: 0.3194 - val_acc: 0.9744
Epoch 14/200
 - 21s - loss: 0.2890 - acc: 0.9747 - val_loss: 0.3244 - val_acc: 0.9744
Epoch 15/200
 - 21s - loss: 0.2638 - acc: 0.9801 - val_loss: 0.2850 - val_acc: 0.9757
Epoch 16/200
 - 23s - loss: 0.2526 - acc: 0.9814 - val_loss: 0.2950 - val_acc: 0.9744
Epoch 17/200
 - 23s - loss: 0.2492 - acc: 0.9824 - val_loss: 0.2606 - val_acc: 0.9795
Epoch 18/200
 - 23s - loss: 0.2339 - acc: 0.9827 - val_loss: 0.2510 - val_acc: 0.9782
Epoch 19/200
 - 22s - loss: 0.2317 - acc: 0.9837 - val_loss: 0.3431 - val_acc: 0.9744
Epoch 20/200
 - 22s - loss: 0.2126 - acc: 0.9875 - val_loss: 0.2998 - val_acc: 0.9744
Epoch 21/200
 - 23s - loss: 0.2246 - acc: 0.9833 - val_loss: 0.3324 - val_acc: 0.9744
Epoch 22/200
 - 24s - loss: 0.2056 - acc: 0.9875 - val_loss: 0.2394 - val_acc: 0.9782
Epoch 23/200
 - 23s - loss: 0.1991 - acc: 0.9894 - val_loss: 0.2414 - val_acc: 0.9770
Epoch 24/200
 - 23s - loss: 0.1948 - acc: 0.9866 - val_loss: 0.2279 - val_acc: 0.9821
Epoch 25/200
 - 23s - loss: 0.1840 - acc: 0.9907 - val_loss: 0.2310 - val_acc: 0.9782
Epoch 26/200
 - 23s - loss: 0.1884 - acc: 0.9885 - val_loss: 0.2312 - val_acc: 0.9782
Epoch 27/200
 - 23s - loss: 0.1881 - acc: 0.9850 - val_loss: 0.2666 - val_acc: 0.9693
Epoch 28/200
 - 23s - loss: 0.1818 - acc: 0.9891 - val_loss: 0.2716 - val_acc: 0.9757
Epoch 29/200
 - 23s - loss: 0.1883 - acc: 0.9869 - val_loss: 0.6427 - val_acc: 0.7682
Epoch 30/200
 - 23s - loss: 0.1890 - acc: 0.9878 - val_loss: 0.2956 - val_acc: 0.9488
Epoch 31/200
 - 23s - loss: 0.1859 - acc: 0.9872 - val_loss: 0.2742 - val_acc: 0.9744
Epoch 32/200
 - 21s - loss: 0.1876 - acc: 0.9856 - val_loss: 0.2817 - val_acc: 0.9757
Epoch 33/200
 - 21s - loss: 0.1809 - acc: 0.9869 - val_loss: 0.2803 - val_acc: 0.9757
Epoch 34/200
 - 24s - loss: 0.1752 - acc: 0.9885 - val_loss: 0.2231 - val_acc: 0.9795
Epoch 35/200
 - 21s - loss: 0.1660 - acc: 0.9917 - val_loss: 0.1983 - val_acc: 0.9808
Epoch 36/200
 - 21s - loss: 0.1612 - acc: 0.9914 - val_loss: 0.2293 - val_acc: 0.9782
Epoch 37/200
 - 21s - loss: 0.1649 - acc: 0.9888 - val_loss: 0.2660 - val_acc: 0.9757
Epoch 38/200
 - 20s - loss: 0.1573 - acc: 0.9907 - val_loss: 0.2240 - val_acc: 0.9770
Epoch 39/200
 - 21s - loss: 0.1547 - acc: 0.9898 - val_loss: 0.3127 - val_acc: 0.9360
Epoch 40/200
 - 21s - loss: 0.1543 - acc: 0.9917 - val_loss: 0.1970 - val_acc: 0.9834
Epoch 41/200
 - 21s - loss: 0.1573 - acc: 0.9910 - val_loss: 0.2339 - val_acc: 0.9795
Epoch 42/200
 - 21s - loss: 0.1494 - acc: 0.9914 - val_loss: 0.2158 - val_acc: 0.9795
Epoch 43/200
 - 21s - loss: 0.1483 - acc: 0.9914 - val_loss: 0.2701 - val_acc: 0.9757
Epoch 44/200
 - 21s - loss: 0.1443 - acc: 0.9901 - val_loss: 0.2442 - val_acc: 0.9757
Epoch 45/200
 - 21s - loss: 0.1451 - acc: 0.9914 - val_loss: 0.2139 - val_acc: 0.9782
Epoch 46/200
 - 21s - loss: 0.1405 - acc: 0.9936 - val_loss: 0.2024 - val_acc: 0.9757
Epoch 47/200
 - 21s - loss: 0.1380 - acc: 0.9920 - val_loss: 0.1846 - val_acc: 0.9808
Epoch 48/200
 - 21s - loss: 0.1318 - acc: 0.9952 - val_loss: 0.2223 - val_acc: 0.9808
Epoch 49/200
 - 22s - loss: 0.1312 - acc: 0.9942 - val_loss: 0.3055 - val_acc: 0.9744
Epoch 50/200
 - 23s - loss: 0.1301 - acc: 0.9936 - val_loss: 0.2233 - val_acc: 0.9782
Epoch 51/200
 - 23s - loss: 0.1337 - acc: 0.9917 - val_loss: 0.4125 - val_acc: 0.8758
Epoch 52/200
 - 23s - loss: 0.1366 - acc: 0.9914 - val_loss: 1.0446 - val_acc: 0.5442
Epoch 53/200
 - 23s - loss: 0.1436 - acc: 0.9898 - val_loss: 0.1872 - val_acc: 0.9795
Epoch 54/200
 - 23s - loss: 0.1363 - acc: 0.9926 - val_loss: 0.1928 - val_acc: 0.9795
Epoch 55/200
 - 23s - loss: 0.1355 - acc: 0.9898 - val_loss: 0.2567 - val_acc: 0.9757
Epoch 56/200
 - 22s - loss: 0.1268 - acc: 0.9949 - val_loss: 0.1984 - val_acc: 0.9808
Epoch 57/200
 - 23s - loss: 0.1287 - acc: 0.9946 - val_loss: 0.2268 - val_acc: 0.9782
Restoring model weights from the end of the best epoch
Epoch 00057: early stopping
End-train DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Keras TF Training sig_bottles_0: 3886/3904 99.5%
              precision    recall  f1-score   support

           B       0.98      0.83      0.90        96
           V       1.00      1.00      1.00      3808

    accuracy                           1.00      3904
   macro avg       0.99      0.92      0.95      3904
weighted avg       1.00      1.00      1.00      3904

Keras TF Testing sig_bottles_0: 958/977 98.1%
              precision    recall  f1-score   support

           B       0.73      0.33      0.46        24
           V       0.98      1.00      0.99       953

    accuracy                           0.98       977
   macro avg       0.86      0.67      0.72       977
weighted avg       0.98      0.98      0.98       977

Keras TF CV sig_bottles_0: 2457/2519 97.5%
              precision    recall  f1-score   support

           B       0.48      0.25      0.33        61
           V       0.98      0.99      0.99      2458

    accuracy                           0.98      2519
   macro avg       0.73      0.62      0.66      2519
weighted avg       0.97      0.98      0.97      2519

Keras TF stop snn_sig_bottles_0
trnargs = {'batch_size':32,'max_iter':200,'lay':[('ip',256),('lrelu',),('batch',),('dropout',0.7), ('ip',128),('lrelu',),('batch',),('dropout',0.7)],'base_lr':0.0005,'optimizer':'adagrad','val_split':0.2,'monitor': 'val_loss','patience':10, 'stop': True}
Keras TF start  snn_pfa_bottles_0
Train DNN with Keras
Train on 3123 samples, validate on 781 samples
Epoch 1/200
 - 7s - loss: 1.0821 - acc: 0.7307 - val_loss: 0.6565 - val_acc: 0.9744
Epoch 2/200
 - 4s - loss: 0.7318 - acc: 0.8774 - val_loss: 0.4741 - val_acc: 0.9744
Epoch 3/200
 - 4s - loss: 0.5709 - acc: 0.9260 - val_loss: 0.4259 - val_acc: 0.9744
Epoch 4/200
 - 4s - loss: 0.4859 - acc: 0.9449 - val_loss: 0.3943 - val_acc: 0.9744
Epoch 5/200
 - 4s - loss: 0.4150 - acc: 0.9597 - val_loss: 0.3598 - val_acc: 0.9744
Epoch 6/200
 - 4s - loss: 0.3717 - acc: 0.9664 - val_loss: 0.3430 - val_acc: 0.9744
Epoch 7/200
 - 4s - loss: 0.3342 - acc: 0.9702 - val_loss: 0.3161 - val_acc: 0.9744
Epoch 8/200
 - 4s - loss: 0.3094 - acc: 0.9741 - val_loss: 0.3099 - val_acc: 0.9744
Epoch 9/200
 - 4s - loss: 0.2911 - acc: 0.9737 - val_loss: 0.3070 - val_acc: 0.9744
Epoch 10/200
 - 4s - loss: 0.2699 - acc: 0.9763 - val_loss: 0.2620 - val_acc: 0.9770
Epoch 11/200
 - 4s - loss: 0.2602 - acc: 0.9776 - val_loss: 0.2679 - val_acc: 0.9757
Epoch 12/200
 - 4s - loss: 0.2439 - acc: 0.9817 - val_loss: 0.2557 - val_acc: 0.9770
Epoch 13/200
 - 4s - loss: 0.2319 - acc: 0.9833 - val_loss: 0.2744 - val_acc: 0.9744
Epoch 14/200
 - 4s - loss: 0.2226 - acc: 0.9837 - val_loss: 0.2147 - val_acc: 0.9821
Epoch 15/200
 - 4s - loss: 0.2126 - acc: 0.9872 - val_loss: 0.2077 - val_acc: 0.9834
Epoch 16/200
 - 4s - loss: 0.1980 - acc: 0.9878 - val_loss: 0.2190 - val_acc: 0.9795
Epoch 17/200
 - 4s - loss: 0.1919 - acc: 0.9894 - val_loss: 0.2558 - val_acc: 0.9757
Epoch 18/200
 - 4s - loss: 0.1875 - acc: 0.9914 - val_loss: 0.2204 - val_acc: 0.9770
Epoch 19/200
 - 4s - loss: 0.1840 - acc: 0.9878 - val_loss: 0.1806 - val_acc: 0.9872
Epoch 20/200
 - 4s - loss: 0.1773 - acc: 0.9894 - val_loss: 0.1977 - val_acc: 0.9821
Epoch 21/200
 - 4s - loss: 0.1697 - acc: 0.9894 - val_loss: 0.2156 - val_acc: 0.9770
Epoch 22/200
 - 4s - loss: 0.1686 - acc: 0.9894 - val_loss: 0.1695 - val_acc: 0.9910
Epoch 23/200
 - 4s - loss: 0.1609 - acc: 0.9920 - val_loss: 0.1771 - val_acc: 0.9872
Epoch 24/200
 - 4s - loss: 0.1542 - acc: 0.9942 - val_loss: 0.1979 - val_acc: 0.9821
Epoch 25/200
 - 4s - loss: 0.1466 - acc: 0.9949 - val_loss: 0.1668 - val_acc: 0.9859
Epoch 26/200
 - 4s - loss: 0.1537 - acc: 0.9894 - val_loss: 0.1641 - val_acc: 0.9859
Epoch 27/200
 - 4s - loss: 0.1503 - acc: 0.9936 - val_loss: 0.1605 - val_acc: 0.9910
Epoch 28/200
 - 4s - loss: 0.1425 - acc: 0.9926 - val_loss: 0.1633 - val_acc: 0.9859
Epoch 29/200
 - 4s - loss: 0.1327 - acc: 0.9955 - val_loss: 0.1785 - val_acc: 0.9821
Epoch 30/200
 - 4s - loss: 0.1374 - acc: 0.9942 - val_loss: 0.2603 - val_acc: 0.9744
Epoch 31/200
 - 4s - loss: 0.1360 - acc: 0.9930 - val_loss: 0.2432 - val_acc: 0.9757
Epoch 32/200
 - 4s - loss: 0.1319 - acc: 0.9949 - val_loss: 0.1704 - val_acc: 0.9821
Epoch 33/200
 - 4s - loss: 0.1302 - acc: 0.9920 - val_loss: 0.1514 - val_acc: 0.9859
Epoch 34/200
 - 4s - loss: 0.1263 - acc: 0.9942 - val_loss: 0.1351 - val_acc: 0.9910
Epoch 35/200
 - 4s - loss: 0.1285 - acc: 0.9920 - val_loss: 0.1470 - val_acc: 0.9898
Epoch 36/200
 - 4s - loss: 0.1226 - acc: 0.9949 - val_loss: 0.1500 - val_acc: 0.9859
Epoch 37/200
 - 4s - loss: 0.1300 - acc: 0.9917 - val_loss: 0.1924 - val_acc: 0.9770
Epoch 38/200
 - 4s - loss: 0.1246 - acc: 0.9955 - val_loss: 0.1674 - val_acc: 0.9834
Epoch 39/200
 - 4s - loss: 0.1148 - acc: 0.9974 - val_loss: 0.1488 - val_acc: 0.9859
Epoch 40/200
 - 4s - loss: 0.1166 - acc: 0.9958 - val_loss: 0.1972 - val_acc: 0.9808
Epoch 41/200
 - 4s - loss: 0.1190 - acc: 0.9926 - val_loss: 0.3056 - val_acc: 0.9142
Epoch 42/200
 - 4s - loss: 0.1133 - acc: 0.9939 - val_loss: 0.1989 - val_acc: 0.9782
Epoch 43/200
 - 4s - loss: 0.1148 - acc: 0.9958 - val_loss: 0.1491 - val_acc: 0.9846
Epoch 44/200
 - 4s - loss: 0.1164 - acc: 0.9952 - val_loss: 0.1478 - val_acc: 0.9910
Restoring model weights from the end of the best epoch
Epoch 00044: early stopping
End-train DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Keras TF Training pfa_bottles_0: 3897/3904 99.8%
              precision    recall  f1-score   support

           B       1.00      0.93      0.96        96
           V       1.00      1.00      1.00      3808

    accuracy                           1.00      3904
   macro avg       1.00      0.96      0.98      3904
weighted avg       1.00      1.00      1.00      3904

Keras TF Testing pfa_bottles_0: 972/977 99.5%
              precision    recall  f1-score   support

           B       1.00      0.79      0.88        24
           V       0.99      1.00      1.00       953

    accuracy                           0.99       977
   macro avg       1.00      0.90      0.94       977
weighted avg       0.99      0.99      0.99       977

Keras TF CV pfa_bottles_0: 2505/2519 99.4%
              precision    recall  f1-score   support

           B       0.98      0.79      0.87        61
           V       0.99      1.00      1.00      2458

    accuracy                           0.99      2519
   macro avg       0.99      0.89      0.93      2519
weighted avg       0.99      0.99      0.99      2519

Keras TF stop snn_pfa_bottles_0
trnargs = {'batch_size':32,'max_iter':200,'lay':[('ip',128),('lrelu',),('batch',),('dropout',0.7), ('ip',64),('lrelu',),('batch',),('dropout',0.7)],'base_lr':0.0005,'optimizer':'adagrad','val_split':0.2,'monitor': 'val_loss','patience':10, 'stop': True}
Keras TF start  snn_sfa_bottles_0
Train DNN with Keras
Train on 3123 samples, validate on 781 samples
Epoch 1/200
 - 4s - loss: 1.0235 - acc: 0.6795 - val_loss: 0.5298 - val_acc: 0.9744
Epoch 2/200
 - 2s - loss: 0.7353 - acc: 0.8133 - val_loss: 0.4705 - val_acc: 0.9744
Epoch 3/200
 - 2s - loss: 0.6408 - acc: 0.8678 - val_loss: 0.4244 - val_acc: 0.9744
Epoch 4/200
 - 2s - loss: 0.5464 - acc: 0.9084 - val_loss: 0.3951 - val_acc: 0.9744
Epoch 5/200
 - 2s - loss: 0.4932 - acc: 0.9267 - val_loss: 0.3808 - val_acc: 0.9744
Epoch 6/200
 - 2s - loss: 0.4578 - acc: 0.9401 - val_loss: 0.3657 - val_acc: 0.9744
Epoch 7/200
 - 2s - loss: 0.4300 - acc: 0.9526 - val_loss: 0.3512 - val_acc: 0.9744
Epoch 8/200
 - 2s - loss: 0.4059 - acc: 0.9526 - val_loss: 0.3401 - val_acc: 0.9744
Epoch 9/200
 - 2s - loss: 0.3821 - acc: 0.9641 - val_loss: 0.3302 - val_acc: 0.9744
Epoch 10/200
 - 2s - loss: 0.3705 - acc: 0.9654 - val_loss: 0.3201 - val_acc: 0.9821
Epoch 11/200
 - 2s - loss: 0.3583 - acc: 0.9686 - val_loss: 0.3123 - val_acc: 0.9770
Epoch 12/200
 - 2s - loss: 0.3407 - acc: 0.9734 - val_loss: 0.3073 - val_acc: 0.9770
Epoch 13/200
 - 2s - loss: 0.3290 - acc: 0.9721 - val_loss: 0.3001 - val_acc: 0.9770
Epoch 14/200
 - 2s - loss: 0.3104 - acc: 0.9779 - val_loss: 0.2954 - val_acc: 0.9782
Epoch 15/200
 - 2s - loss: 0.2993 - acc: 0.9808 - val_loss: 0.2899 - val_acc: 0.9782
Epoch 16/200
 - 2s - loss: 0.3009 - acc: 0.9766 - val_loss: 0.2792 - val_acc: 0.9808
Epoch 17/200
 - 2s - loss: 0.2884 - acc: 0.9827 - val_loss: 0.2798 - val_acc: 0.9782
Epoch 18/200
 - 2s - loss: 0.2760 - acc: 0.9837 - val_loss: 0.2706 - val_acc: 0.9821
Epoch 19/200
 - 2s - loss: 0.2747 - acc: 0.9824 - val_loss: 0.2631 - val_acc: 0.9834
Epoch 20/200
 - 2s - loss: 0.2629 - acc: 0.9846 - val_loss: 0.2589 - val_acc: 0.9834
Epoch 21/200
 - 2s - loss: 0.2582 - acc: 0.9853 - val_loss: 0.2585 - val_acc: 0.9821
Epoch 22/200
 - 2s - loss: 0.2430 - acc: 0.9885 - val_loss: 0.2491 - val_acc: 0.9821
Epoch 23/200
 - 2s - loss: 0.2409 - acc: 0.9862 - val_loss: 0.2489 - val_acc: 0.9821
Epoch 24/200
 - 2s - loss: 0.2330 - acc: 0.9894 - val_loss: 0.2514 - val_acc: 0.9821
Epoch 25/200
 - 2s - loss: 0.2344 - acc: 0.9878 - val_loss: 0.2307 - val_acc: 0.9872
Epoch 26/200
 - 2s - loss: 0.2294 - acc: 0.9891 - val_loss: 0.2345 - val_acc: 0.9859
Epoch 27/200
 - 2s - loss: 0.2214 - acc: 0.9894 - val_loss: 0.2320 - val_acc: 0.9859
Epoch 28/200
 - 2s - loss: 0.2205 - acc: 0.9894 - val_loss: 0.2341 - val_acc: 0.9821
Epoch 29/200
 - 2s - loss: 0.2094 - acc: 0.9914 - val_loss: 0.2277 - val_acc: 0.9846
Epoch 30/200
 - 2s - loss: 0.2085 - acc: 0.9891 - val_loss: 0.2297 - val_acc: 0.9821
Epoch 31/200
 - 2s - loss: 0.2064 - acc: 0.9891 - val_loss: 0.2180 - val_acc: 0.9872
Epoch 32/200
 - 2s - loss: 0.1987 - acc: 0.9930 - val_loss: 0.2132 - val_acc: 0.9872
Epoch 33/200
 - 2s - loss: 0.1988 - acc: 0.9907 - val_loss: 0.2160 - val_acc: 0.9846
Epoch 34/200
 - 2s - loss: 0.1900 - acc: 0.9936 - val_loss: 0.2125 - val_acc: 0.9846
Epoch 35/200
 - 2s - loss: 0.1962 - acc: 0.9910 - val_loss: 0.2140 - val_acc: 0.9846
Epoch 36/200
 - 2s - loss: 0.1810 - acc: 0.9936 - val_loss: 0.2143 - val_acc: 0.9846
Epoch 37/200
 - 2s - loss: 0.1744 - acc: 0.9958 - val_loss: 0.2064 - val_acc: 0.9846
Epoch 38/200
 - 2s - loss: 0.1746 - acc: 0.9952 - val_loss: 0.2099 - val_acc: 0.9846
Epoch 39/200
 - 2s - loss: 0.1735 - acc: 0.9936 - val_loss: 0.2030 - val_acc: 0.9846
Epoch 40/200
 - 2s - loss: 0.1729 - acc: 0.9926 - val_loss: 0.1998 - val_acc: 0.9846
Epoch 41/200
 - 2s - loss: 0.1660 - acc: 0.9955 - val_loss: 0.2011 - val_acc: 0.9846
Epoch 42/200
 - 2s - loss: 0.1678 - acc: 0.9926 - val_loss: 0.1927 - val_acc: 0.9859
Epoch 43/200
 - 2s - loss: 0.1657 - acc: 0.9942 - val_loss: 0.1914 - val_acc: 0.9859
Epoch 44/200
 - 2s - loss: 0.1617 - acc: 0.9949 - val_loss: 0.1968 - val_acc: 0.9846
Epoch 45/200
 - 2s - loss: 0.1578 - acc: 0.9942 - val_loss: 0.1891 - val_acc: 0.9859
Epoch 46/200
 - 2s - loss: 0.1545 - acc: 0.9955 - val_loss: 0.1880 - val_acc: 0.9859
Epoch 47/200
 - 2s - loss: 0.1556 - acc: 0.9936 - val_loss: 0.1850 - val_acc: 0.9859
Epoch 48/200
 - 2s - loss: 0.1521 - acc: 0.9942 - val_loss: 0.1793 - val_acc: 0.9859
Epoch 49/200
 - 2s - loss: 0.1493 - acc: 0.9946 - val_loss: 0.1774 - val_acc: 0.9859
Epoch 50/200
 - 2s - loss: 0.1453 - acc: 0.9965 - val_loss: 0.1761 - val_acc: 0.9859
Epoch 51/200
 - 2s - loss: 0.1511 - acc: 0.9926 - val_loss: 0.1685 - val_acc: 0.9885
Epoch 52/200
 - 2s - loss: 0.1391 - acc: 0.9968 - val_loss: 0.1676 - val_acc: 0.9872
Epoch 53/200
 - 2s - loss: 0.1395 - acc: 0.9946 - val_loss: 0.1679 - val_acc: 0.9872
Epoch 54/200
 - 2s - loss: 0.1399 - acc: 0.9958 - val_loss: 0.1611 - val_acc: 0.9885
Epoch 55/200
 - 2s - loss: 0.1377 - acc: 0.9949 - val_loss: 0.1589 - val_acc: 0.9885
Epoch 56/200
 - 2s - loss: 0.1343 - acc: 0.9971 - val_loss: 0.1582 - val_acc: 0.9885
Epoch 57/200
 - 2s - loss: 0.1292 - acc: 0.9971 - val_loss: 0.1679 - val_acc: 0.9859
Epoch 58/200
 - 2s - loss: 0.1265 - acc: 0.9981 - val_loss: 0.1627 - val_acc: 0.9872
Epoch 59/200
 - 2s - loss: 0.1246 - acc: 0.9968 - val_loss: 0.1547 - val_acc: 0.9898
Epoch 60/200
 - 2s - loss: 0.1288 - acc: 0.9942 - val_loss: 0.1528 - val_acc: 0.9885
Epoch 61/200
 - 2s - loss: 0.1206 - acc: 0.9981 - val_loss: 0.1543 - val_acc: 0.9872
Epoch 62/200
 - 2s - loss: 0.1240 - acc: 0.9955 - val_loss: 0.1491 - val_acc: 0.9885
Epoch 63/200
 - 2s - loss: 0.1191 - acc: 0.9968 - val_loss: 0.1502 - val_acc: 0.9885
Epoch 64/200
 - 2s - loss: 0.1192 - acc: 0.9962 - val_loss: 0.1466 - val_acc: 0.9885
Epoch 65/200
 - 2s - loss: 0.1181 - acc: 0.9965 - val_loss: 0.1499 - val_acc: 0.9885
Epoch 66/200
 - 2s - loss: 0.1165 - acc: 0.9965 - val_loss: 0.1514 - val_acc: 0.9885
Epoch 67/200
 - 2s - loss: 0.1139 - acc: 0.9965 - val_loss: 0.1501 - val_acc: 0.9872
Epoch 68/200
 - 2s - loss: 0.1159 - acc: 0.9958 - val_loss: 0.1433 - val_acc: 0.9885
Epoch 69/200
 - 2s - loss: 0.1096 - acc: 0.9984 - val_loss: 0.1373 - val_acc: 0.9885
Epoch 70/200
 - 2s - loss: 0.1056 - acc: 0.9990 - val_loss: 0.1385 - val_acc: 0.9885
Epoch 71/200
 - 2s - loss: 0.1119 - acc: 0.9952 - val_loss: 0.1393 - val_acc: 0.9885
Epoch 72/200
 - 2s - loss: 0.1067 - acc: 0.9974 - val_loss: 0.1411 - val_acc: 0.9885
Epoch 73/200
 - 2s - loss: 0.1036 - acc: 0.9990 - val_loss: 0.1456 - val_acc: 0.9872
Epoch 74/200
 - 2s - loss: 0.1048 - acc: 0.9971 - val_loss: 0.1398 - val_acc: 0.9885
Epoch 75/200
 - 2s - loss: 0.1049 - acc: 0.9968 - val_loss: 0.1359 - val_acc: 0.9885
Epoch 76/200
 - 2s - loss: 0.1033 - acc: 0.9968 - val_loss: 0.1359 - val_acc: 0.9885
Epoch 77/200
 - 2s - loss: 0.0991 - acc: 0.9981 - val_loss: 0.1431 - val_acc: 0.9872
Epoch 78/200
 - 2s - loss: 0.0972 - acc: 0.9990 - val_loss: 0.1389 - val_acc: 0.9885
Epoch 79/200
 - 2s - loss: 0.1000 - acc: 0.9968 - val_loss: 0.1359 - val_acc: 0.9885
Epoch 80/200
 - 2s - loss: 0.0963 - acc: 0.9978 - val_loss: 0.1356 - val_acc: 0.9885
Epoch 81/200
 - 2s - loss: 0.0940 - acc: 0.9994 - val_loss: 0.1327 - val_acc: 0.9885
Epoch 82/200
 - 2s - loss: 0.0936 - acc: 0.9981 - val_loss: 0.1354 - val_acc: 0.9885
Epoch 83/200
 - 2s - loss: 0.0934 - acc: 0.9984 - val_loss: 0.1334 - val_acc: 0.9885
Epoch 84/200
 - 2s - loss: 0.0926 - acc: 0.9974 - val_loss: 0.1331 - val_acc: 0.9885
Epoch 85/200
 - 2s - loss: 0.0929 - acc: 0.9965 - val_loss: 0.1306 - val_acc: 0.9885
Epoch 86/200
 - 2s - loss: 0.0902 - acc: 0.9978 - val_loss: 0.1275 - val_acc: 0.9885
Epoch 87/200
 - 2s - loss: 0.0918 - acc: 0.9978 - val_loss: 0.1273 - val_acc: 0.9885
Epoch 88/200
 - 2s - loss: 0.0886 - acc: 0.9981 - val_loss: 0.1261 - val_acc: 0.9885
Epoch 89/200
 - 2s - loss: 0.0882 - acc: 0.9978 - val_loss: 0.1246 - val_acc: 0.9885
Epoch 90/200
 - 2s - loss: 0.0856 - acc: 0.9990 - val_loss: 0.1252 - val_acc: 0.9885
Epoch 91/200
 - 2s - loss: 0.0833 - acc: 0.9990 - val_loss: 0.1358 - val_acc: 0.9872
Epoch 92/200
 - 2s - loss: 0.0857 - acc: 0.9968 - val_loss: 0.1296 - val_acc: 0.9885
Epoch 93/200
 - 2s - loss: 0.0842 - acc: 0.9974 - val_loss: 0.1299 - val_acc: 0.9885
Epoch 94/200
 - 2s - loss: 0.0831 - acc: 0.9984 - val_loss: 0.1332 - val_acc: 0.9885
Epoch 95/200
 - 2s - loss: 0.0810 - acc: 0.9990 - val_loss: 0.1258 - val_acc: 0.9885
Epoch 96/200
 - 2s - loss: 0.0803 - acc: 0.9987 - val_loss: 0.1217 - val_acc: 0.9885
Epoch 97/200
 - 2s - loss: 0.0794 - acc: 0.9987 - val_loss: 0.1232 - val_acc: 0.9885
Epoch 98/200
 - 2s - loss: 0.0821 - acc: 0.9962 - val_loss: 0.1188 - val_acc: 0.9885
Epoch 99/200
 - 2s - loss: 0.0786 - acc: 0.9990 - val_loss: 0.1155 - val_acc: 0.9885
Epoch 100/200
 - 2s - loss: 0.0828 - acc: 0.9971 - val_loss: 0.1122 - val_acc: 0.9885
Epoch 101/200
 - 2s - loss: 0.0785 - acc: 0.9981 - val_loss: 0.1200 - val_acc: 0.9885
Epoch 102/200
 - 2s - loss: 0.0764 - acc: 0.9987 - val_loss: 0.1187 - val_acc: 0.9885
Epoch 103/200
 - 2s - loss: 0.0789 - acc: 0.9978 - val_loss: 0.1163 - val_acc: 0.9885
Epoch 104/200
 - 2s - loss: 0.0739 - acc: 0.9990 - val_loss: 0.1163 - val_acc: 0.9885
Epoch 105/200
 - 2s - loss: 0.0750 - acc: 0.9990 - val_loss: 0.1087 - val_acc: 0.9885
Epoch 106/200
 - 2s - loss: 0.0745 - acc: 0.9987 - val_loss: 0.1107 - val_acc: 0.9885
Epoch 107/200
 - 2s - loss: 0.0745 - acc: 0.9984 - val_loss: 0.1147 - val_acc: 0.9885
Epoch 108/200
 - 2s - loss: 0.0757 - acc: 0.9965 - val_loss: 0.1158 - val_acc: 0.9885
Epoch 109/200
 - 2s - loss: 0.0729 - acc: 0.9978 - val_loss: 0.1131 - val_acc: 0.9885
Epoch 110/200
 - 2s - loss: 0.0714 - acc: 0.9990 - val_loss: 0.1168 - val_acc: 0.9885
Epoch 111/200
 - 2s - loss: 0.0716 - acc: 0.9978 - val_loss: 0.1136 - val_acc: 0.9885
Epoch 112/200
 - 2s - loss: 0.0704 - acc: 0.9984 - val_loss: 0.1055 - val_acc: 0.9885
Epoch 113/200
 - 2s - loss: 0.0699 - acc: 0.9987 - val_loss: 0.1149 - val_acc: 0.9885
Epoch 114/200
 - 2s - loss: 0.0700 - acc: 0.9978 - val_loss: 0.1104 - val_acc: 0.9885
Epoch 115/200
 - 2s - loss: 0.0690 - acc: 0.9990 - val_loss: 0.1052 - val_acc: 0.9872
Epoch 116/200
 - 2s - loss: 0.0679 - acc: 0.9981 - val_loss: 0.1118 - val_acc: 0.9885
Epoch 117/200
 - 2s - loss: 0.0689 - acc: 0.9978 - val_loss: 0.1222 - val_acc: 0.9885
Epoch 118/200
 - 2s - loss: 0.0684 - acc: 0.9984 - val_loss: 0.1160 - val_acc: 0.9885
Epoch 119/200
 - 2s - loss: 0.0654 - acc: 0.9994 - val_loss: 0.1107 - val_acc: 0.9885
Epoch 120/200
 - 2s - loss: 0.0654 - acc: 0.9987 - val_loss: 0.1146 - val_acc: 0.9885
Epoch 121/200
 - 2s - loss: 0.0656 - acc: 0.9981 - val_loss: 0.1152 - val_acc: 0.9885
Epoch 122/200
 - 2s - loss: 0.0629 - acc: 1.0000 - val_loss: 0.1081 - val_acc: 0.9885
Epoch 123/200
 - 2s - loss: 0.0639 - acc: 0.9987 - val_loss: 0.1030 - val_acc: 0.9885
Epoch 124/200
 - 2s - loss: 0.0633 - acc: 0.9997 - val_loss: 0.1071 - val_acc: 0.9885
Epoch 125/200
 - 2s - loss: 0.0657 - acc: 0.9981 - val_loss: 0.1184 - val_acc: 0.9885
Epoch 126/200
 - 2s - loss: 0.0637 - acc: 0.9981 - val_loss: 0.1154 - val_acc: 0.9872
Epoch 127/200
 - 2s - loss: 0.0623 - acc: 0.9990 - val_loss: 0.1151 - val_acc: 0.9885
Epoch 128/200
 - 2s - loss: 0.0619 - acc: 0.9987 - val_loss: 0.1052 - val_acc: 0.9885
Epoch 129/200
 - 2s - loss: 0.0609 - acc: 0.9990 - val_loss: 0.0985 - val_acc: 0.9885
Epoch 130/200
 - 2s - loss: 0.0613 - acc: 0.9994 - val_loss: 0.1076 - val_acc: 0.9885
Epoch 131/200
 - 2s - loss: 0.0600 - acc: 0.9987 - val_loss: 0.0994 - val_acc: 0.9885
Epoch 132/200
 - 2s - loss: 0.0588 - acc: 0.9994 - val_loss: 0.1051 - val_acc: 0.9885
Epoch 133/200
 - 2s - loss: 0.0593 - acc: 0.9987 - val_loss: 0.1002 - val_acc: 0.9885
Epoch 134/200
 - 2s - loss: 0.0579 - acc: 0.9990 - val_loss: 0.1046 - val_acc: 0.9885
Epoch 135/200
 - 2s - loss: 0.0578 - acc: 0.9994 - val_loss: 0.1067 - val_acc: 0.9872
Epoch 136/200
 - 2s - loss: 0.0594 - acc: 0.9974 - val_loss: 0.0989 - val_acc: 0.9885
Epoch 137/200
 - 2s - loss: 0.0604 - acc: 0.9971 - val_loss: 0.1012 - val_acc: 0.9885
Epoch 138/200
 - 2s - loss: 0.0577 - acc: 0.9987 - val_loss: 0.1050 - val_acc: 0.9885
Epoch 139/200
 - 2s - loss: 0.0556 - acc: 1.0000 - val_loss: 0.1109 - val_acc: 0.9872
Restoring model weights from the end of the best epoch
Epoch 00139: early stopping
End-train DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Keras TF Training sfa_bottles_0: 3895/3904 99.8%
              precision    recall  f1-score   support

           B       1.00      0.91      0.95        96
           V       1.00      1.00      1.00      3808

    accuracy                           1.00      3904
   macro avg       1.00      0.95      0.97      3904
weighted avg       1.00      1.00      1.00      3904

Keras TF Testing sfa_bottles_0: 971/977 99.4%
              precision    recall  f1-score   support

           B       1.00      0.75      0.86        24
           V       0.99      1.00      1.00       953

    accuracy                           0.99       977
   macro avg       1.00      0.88      0.93       977
weighted avg       0.99      0.99      0.99       977

Keras TF CV sfa_bottles_0: 2490/2519 98.8%
              precision    recall  f1-score   support

           B       1.00      0.52      0.69        61
           V       0.99      1.00      0.99      2458

    accuracy                           0.99      2519
   macro avg       0.99      0.76      0.84      2519
weighted avg       0.99      0.99      0.99      2519

Keras TF stop snn_sfa_bottles_0
trnargs = {'batch_size':64,'max_iter':200,'lay':[('conv1d',16,64,2),('relu',),('batch',),('pool',8,8),('conv1d',32,32,2),('relu',),('batch',),('pool',8,8),('conv1d',64,16,8),('relu',),('batch',),('conv1d',128,8,2),('relu',),('batch',),('conv1d',256,4,2),('relu',),('batch',),('pool',4,4),('flatten',),('ip',64),('relu',),('dropout',0.25),('ip',32),('relu',),('dropout',0.25)],'base_lr':0.0005, 'optimizer':'adadelta','val_split':0.2,'monitor': 'val_loss','patience':15, 'stop': True}
Keras TF start  cnn_sig_bottles_0
Train DNN with Keras
Train on 3123 samples, validate on 781 samples
Epoch 1/200
 - 161s - loss: 0.3899 - acc: 0.9648 - val_loss: 0.3701 - val_acc: 0.9744
Epoch 2/200
 - 139s - loss: 0.3469 - acc: 0.9753 - val_loss: 0.3624 - val_acc: 0.9744
Epoch 3/200
 - 136s - loss: 0.3228 - acc: 0.9734 - val_loss: 0.3514 - val_acc: 0.9744
Epoch 4/200
 - 144s - loss: 0.2902 - acc: 0.9782 - val_loss: 0.3614 - val_acc: 0.9744
Epoch 5/200
 - 143s - loss: 0.2724 - acc: 0.9808 - val_loss: 0.3998 - val_acc: 0.9744
Epoch 6/200
 - 144s - loss: 0.2406 - acc: 0.9875 - val_loss: 0.2866 - val_acc: 0.9744
Epoch 7/200
 - 140s - loss: 0.2216 - acc: 0.9946 - val_loss: 0.2910 - val_acc: 0.9770
Epoch 8/200
 - 139s - loss: 0.2009 - acc: 0.9930 - val_loss: 0.3100 - val_acc: 0.9731
Epoch 9/200
 - 137s - loss: 0.1999 - acc: 0.9901 - val_loss: 0.2386 - val_acc: 0.9770
Epoch 10/200
 - 140s - loss: 0.1764 - acc: 0.9942 - val_loss: 0.2561 - val_acc: 0.9821
Epoch 11/200
 - 137s - loss: 0.1723 - acc: 0.9942 - val_loss: 0.2027 - val_acc: 0.9795
Epoch 12/200
 - 138s - loss: 0.1547 - acc: 0.9965 - val_loss: 0.1667 - val_acc: 0.9923
Epoch 13/200
 - 141s - loss: 0.1444 - acc: 0.9974 - val_loss: 0.3603 - val_acc: 0.9770
Epoch 14/200
 - 140s - loss: 0.1354 - acc: 0.9987 - val_loss: 0.2255 - val_acc: 0.9834
Epoch 15/200
 - 140s - loss: 0.1368 - acc: 0.9955 - val_loss: 0.1592 - val_acc: 0.9859
Epoch 16/200
 - 137s - loss: 0.1194 - acc: 0.9990 - val_loss: 0.1348 - val_acc: 0.9910
Epoch 17/200
 - 141s - loss: 0.1189 - acc: 0.9971 - val_loss: 0.1917 - val_acc: 0.9693
Epoch 18/200
 - 132s - loss: 0.1117 - acc: 0.9974 - val_loss: 0.1306 - val_acc: 0.9859
Epoch 19/200
 - 130s - loss: 0.1077 - acc: 0.9971 - val_loss: 0.2953 - val_acc: 0.9795
Epoch 20/200
 - 131s - loss: 0.0974 - acc: 0.9981 - val_loss: 0.2028 - val_acc: 0.9872
Epoch 21/200
 - 134s - loss: 0.0898 - acc: 0.9997 - val_loss: 0.1341 - val_acc: 0.9910
Epoch 22/200
 - 145s - loss: 0.0832 - acc: 1.0000 - val_loss: 0.1267 - val_acc: 0.9910
Epoch 23/200
 - 134s - loss: 0.0879 - acc: 0.9974 - val_loss: 0.2249 - val_acc: 0.9834
Epoch 24/200
 - 137s - loss: 0.0789 - acc: 0.9984 - val_loss: 0.0922 - val_acc: 0.9910
Epoch 25/200
 - 140s - loss: 0.0708 - acc: 1.0000 - val_loss: 0.1368 - val_acc: 0.9680
Epoch 26/200
 - 143s - loss: 0.0785 - acc: 0.9965 - val_loss: 0.3196 - val_acc: 0.9757
Epoch 27/200
 - 143s - loss: 0.0639 - acc: 0.9997 - val_loss: 0.0789 - val_acc: 0.9962
Epoch 28/200
 - 143s - loss: 0.0597 - acc: 1.0000 - val_loss: 0.0892 - val_acc: 0.9949
Epoch 29/200
 - 140s - loss: 0.0554 - acc: 1.0000 - val_loss: 0.1007 - val_acc: 0.9923
Epoch 30/200
 - 141s - loss: 0.0510 - acc: 1.0000 - val_loss: 0.0765 - val_acc: 0.9910
Epoch 31/200
 - 142s - loss: 0.0588 - acc: 0.9987 - val_loss: 0.8328 - val_acc: 0.7631
Epoch 32/200
 - 141s - loss: 0.0494 - acc: 0.9984 - val_loss: 0.1110 - val_acc: 0.9718
Epoch 33/200
 - 139s - loss: 0.0518 - acc: 0.9974 - val_loss: 0.2886 - val_acc: 0.9782
Epoch 34/200
 - 137s - loss: 0.0447 - acc: 0.9990 - val_loss: 0.0587 - val_acc: 0.9949
Epoch 35/200
 - 148s - loss: 0.0396 - acc: 1.0000 - val_loss: 0.0945 - val_acc: 0.9898
Epoch 36/200
 - 152s - loss: 0.0369 - acc: 1.0000 - val_loss: 0.0756 - val_acc: 0.9923
Epoch 37/200
 - 154s - loss: 0.0341 - acc: 1.0000 - val_loss: 0.0611 - val_acc: 0.9923
Epoch 38/200
 - 154s - loss: 0.0312 - acc: 1.0000 - val_loss: 0.0666 - val_acc: 0.9936
Epoch 39/200
 - 149s - loss: 0.0398 - acc: 0.9981 - val_loss: 0.5147 - val_acc: 0.8425
Epoch 40/200
 - 156s - loss: 0.0444 - acc: 0.9978 - val_loss: 1.5444 - val_acc: 0.5570
Epoch 41/200
 - 159s - loss: 0.0308 - acc: 0.9984 - val_loss: 0.1081 - val_acc: 0.9846
Epoch 42/200
 - 164s - loss: 0.0269 - acc: 0.9997 - val_loss: 0.2819 - val_acc: 0.8988
Epoch 43/200
 - 150s - loss: 0.0418 - acc: 0.9949 - val_loss: 0.1470 - val_acc: 0.9834
Epoch 44/200
 - 135s - loss: 0.0318 - acc: 0.9978 - val_loss: 2.1123 - val_acc: 0.4430
Epoch 45/200
 - 134s - loss: 0.0245 - acc: 1.0000 - val_loss: 0.0449 - val_acc: 0.9962
Epoch 46/200
 - 134s - loss: 0.0389 - acc: 0.9974 - val_loss: 0.0763 - val_acc: 0.9923
Epoch 47/200
 - 134s - loss: 0.0271 - acc: 0.9984 - val_loss: 0.1294 - val_acc: 0.9834
Epoch 48/200
 - 133s - loss: 0.0225 - acc: 1.0000 - val_loss: 0.0613 - val_acc: 0.9936
Epoch 49/200
 - 132s - loss: 0.0220 - acc: 0.9997 - val_loss: 0.0613 - val_acc: 0.9846
Epoch 50/200
 - 129s - loss: 0.0215 - acc: 0.9997 - val_loss: 0.0604 - val_acc: 0.9936
Epoch 51/200
 - 124s - loss: 0.0314 - acc: 0.9968 - val_loss: 0.3859 - val_acc: 0.9744
Epoch 52/200
 - 130s - loss: 0.0244 - acc: 0.9990 - val_loss: 0.2095 - val_acc: 0.9808
Epoch 53/200
 - 135s - loss: 0.0210 - acc: 0.9994 - val_loss: 0.0848 - val_acc: 0.9923
Epoch 54/200
 - 135s - loss: 0.0288 - acc: 0.9974 - val_loss: 0.2062 - val_acc: 0.9117
Epoch 55/200
 - 137s - loss: 0.0206 - acc: 0.9997 - val_loss: 0.0689 - val_acc: 0.9949
Epoch 56/200
 - 134s - loss: 0.0220 - acc: 0.9981 - val_loss: 0.0670 - val_acc: 0.9936
Epoch 57/200
 - 132s - loss: 0.0172 - acc: 1.0000 - val_loss: 0.0571 - val_acc: 0.9949
Epoch 58/200
 - 132s - loss: 0.0162 - acc: 1.0000 - val_loss: 0.0639 - val_acc: 0.9936
Epoch 59/200
 - 134s - loss: 0.0153 - acc: 1.0000 - val_loss: 0.4946 - val_acc: 0.8361
Epoch 60/200
 - 133s - loss: 0.0416 - acc: 0.9923 - val_loss: 0.2901 - val_acc: 0.9744
Restoring model weights from the end of the best epoch
Epoch 00060: early stopping
End-train DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Keras TF Training sig_bottles_0: 3899/3904 99.9%
              precision    recall  f1-score   support

           B       0.97      0.98      0.97        96
           V       1.00      1.00      1.00      3808

    accuracy                           1.00      3904
   macro avg       0.98      0.99      0.99      3904
weighted avg       1.00      1.00      1.00      3904

Keras TF Testing sig_bottles_0: 968/977 99.1%
              precision    recall  f1-score   support

           B       0.78      0.88      0.82        24
           V       1.00      0.99      1.00       953

    accuracy                           0.99       977
   macro avg       0.89      0.93      0.91       977
weighted avg       0.99      0.99      0.99       977

Keras TF CV sig_bottles_0: 2487/2519 98.7%
              precision    recall  f1-score   support

           B       0.70      0.82      0.76        61
           V       1.00      0.99      0.99      2458

    accuracy                           0.99      2519
   macro avg       0.85      0.91      0.88      2519
weighted avg       0.99      0.99      0.99      2519

Keras TF stop cnn_sig_bottles_0
trnargs = {'batch_size':32,'max_iter':200,'lay':[('conv2d',32,[5,5],[2,2]),('elu',),('batch',),('dropout',0.1),('pool',[2,2],[2,2]),('conv2d',32,[5,5],[2,2]),('elu',),('batch',),('dropout',0.1),('pool',[2,2],[2,2]),('flatten',),('ip',90),('relu',),('dropout',0.7)],'base_lr':0.0005, 'optimizer':'adadelta','val_split':0.2,'monitor': 'val_loss','patience':15, 'stop': True}
Keras TF start  cnn_pfa_bottles_0
Train DNN with Keras
Train on 3123 samples, validate on 781 samples
Epoch 1/200
 - 16s - loss: 0.2799 - acc: 0.9651 - val_loss: 0.2226 - val_acc: 0.9744
Epoch 2/200
 - 14s - loss: 0.2311 - acc: 0.9750 - val_loss: 0.1948 - val_acc: 0.9744
Epoch 3/200
 - 13s - loss: 0.1498 - acc: 0.9798 - val_loss: 0.1284 - val_acc: 0.9795
Epoch 4/200
 - 13s - loss: 0.1035 - acc: 0.9920 - val_loss: 0.1305 - val_acc: 0.9821
Epoch 5/200
 - 13s - loss: 0.0914 - acc: 0.9936 - val_loss: 0.1501 - val_acc: 0.9821
Epoch 6/200
 - 14s - loss: 0.0846 - acc: 0.9946 - val_loss: 0.1160 - val_acc: 0.9846
Epoch 7/200
 - 13s - loss: 0.0783 - acc: 0.9955 - val_loss: 0.0940 - val_acc: 0.9885
Epoch 8/200
 - 13s - loss: 0.0651 - acc: 0.9978 - val_loss: 0.0690 - val_acc: 0.9949
Epoch 9/200
 - 14s - loss: 0.0667 - acc: 0.9942 - val_loss: 0.0645 - val_acc: 0.9949
Epoch 10/200
 - 14s - loss: 0.0511 - acc: 0.9984 - val_loss: 0.0515 - val_acc: 0.9962
Epoch 11/200
 - 14s - loss: 0.0509 - acc: 0.9968 - val_loss: 0.0458 - val_acc: 0.9974
Epoch 12/200
 - 14s - loss: 0.0470 - acc: 0.9978 - val_loss: 0.0452 - val_acc: 0.9974
Epoch 13/200
 - 14s - loss: 0.0397 - acc: 0.9987 - val_loss: 0.0420 - val_acc: 0.9974
Epoch 14/200
 - 14s - loss: 0.0381 - acc: 0.9974 - val_loss: 0.0326 - val_acc: 0.9987
Epoch 15/200
 - 15s - loss: 0.0372 - acc: 0.9984 - val_loss: 0.0308 - val_acc: 0.9987
Epoch 16/200
 - 14s - loss: 0.0338 - acc: 0.9987 - val_loss: 0.0311 - val_acc: 0.9974
Epoch 17/200
 - 13s - loss: 0.0300 - acc: 0.9984 - val_loss: 0.0380 - val_acc: 0.9974
Epoch 18/200
 - 14s - loss: 0.0289 - acc: 0.9981 - val_loss: 0.0290 - val_acc: 0.9949
Epoch 19/200
 - 14s - loss: 0.0278 - acc: 0.9978 - val_loss: 0.0358 - val_acc: 0.9962
Epoch 20/200
 - 14s - loss: 0.0260 - acc: 0.9987 - val_loss: 0.0322 - val_acc: 0.9949
Epoch 21/200
 - 15s - loss: 0.0214 - acc: 0.9990 - val_loss: 0.0192 - val_acc: 1.0000
Epoch 22/200
 - 18s - loss: 0.0200 - acc: 0.9994 - val_loss: 0.0196 - val_acc: 0.9987
Epoch 23/200
 - 16s - loss: 0.0231 - acc: 0.9990 - val_loss: 0.0203 - val_acc: 0.9974
Epoch 24/200
 - 16s - loss: 0.0160 - acc: 1.0000 - val_loss: 0.0189 - val_acc: 0.9974
Epoch 25/200
 - 15s - loss: 0.0177 - acc: 0.9981 - val_loss: 0.0149 - val_acc: 1.0000
Epoch 26/200
 - 15s - loss: 0.0171 - acc: 0.9984 - val_loss: 0.0266 - val_acc: 0.9974
Epoch 27/200
 - 15s - loss: 0.0136 - acc: 0.9997 - val_loss: 0.0224 - val_acc: 0.9974
Epoch 28/200
 - 14s - loss: 0.0148 - acc: 0.9990 - val_loss: 0.0126 - val_acc: 1.0000
Epoch 29/200
 - 14s - loss: 0.0124 - acc: 0.9994 - val_loss: 0.0173 - val_acc: 0.9974
Epoch 30/200
 - 14s - loss: 0.0110 - acc: 0.9997 - val_loss: 0.0179 - val_acc: 0.9974
Epoch 31/200
 - 14s - loss: 0.0120 - acc: 0.9994 - val_loss: 0.0208 - val_acc: 0.9974
Epoch 32/200
 - 15s - loss: 0.0132 - acc: 0.9987 - val_loss: 0.0181 - val_acc: 0.9987
Epoch 33/200
 - 14s - loss: 0.0105 - acc: 0.9994 - val_loss: 0.0333 - val_acc: 0.9962
Epoch 34/200
 - 15s - loss: 0.0163 - acc: 0.9981 - val_loss: 0.0854 - val_acc: 0.9744
Epoch 35/200
 - 15s - loss: 0.0115 - acc: 0.9987 - val_loss: 0.0347 - val_acc: 0.9949
Epoch 36/200
 - 15s - loss: 0.0116 - acc: 0.9987 - val_loss: 0.0139 - val_acc: 0.9974
Epoch 37/200
 - 15s - loss: 0.0092 - acc: 0.9997 - val_loss: 0.0121 - val_acc: 0.9987
Epoch 38/200
 - 14s - loss: 0.0093 - acc: 0.9990 - val_loss: 0.0249 - val_acc: 0.9974
Epoch 39/200
 - 15s - loss: 0.0076 - acc: 0.9997 - val_loss: 0.0172 - val_acc: 0.9974
Epoch 40/200
 - 15s - loss: 0.0070 - acc: 0.9997 - val_loss: 0.0450 - val_acc: 0.9949
Epoch 41/200
 - 15s - loss: 0.0081 - acc: 0.9994 - val_loss: 0.0065 - val_acc: 1.0000
Epoch 42/200
 - 14s - loss: 0.0110 - acc: 0.9981 - val_loss: 0.0062 - val_acc: 1.0000
Epoch 43/200
 - 14s - loss: 0.0081 - acc: 0.9990 - val_loss: 0.0063 - val_acc: 1.0000
Epoch 44/200
 - 14s - loss: 0.0082 - acc: 0.9990 - val_loss: 0.0064 - val_acc: 1.0000
Epoch 45/200
 - 18s - loss: 0.0063 - acc: 0.9997 - val_loss: 0.0182 - val_acc: 0.9962
Epoch 46/200
 - 14s - loss: 0.0178 - acc: 0.9962 - val_loss: 0.0730 - val_acc: 0.9898
Epoch 47/200
 - 14s - loss: 0.0058 - acc: 1.0000 - val_loss: 0.0184 - val_acc: 0.9974
Epoch 48/200
 - 14s - loss: 0.0056 - acc: 0.9997 - val_loss: 0.0059 - val_acc: 1.0000
Epoch 49/200
 - 14s - loss: 0.0097 - acc: 0.9984 - val_loss: 0.0058 - val_acc: 1.0000
Epoch 50/200
 - 15s - loss: 0.0093 - acc: 0.9981 - val_loss: 0.0117 - val_acc: 0.9974
Epoch 51/200
 - 15s - loss: 0.0072 - acc: 0.9984 - val_loss: 0.0362 - val_acc: 0.9872
Epoch 52/200
 - 15s - loss: 0.0081 - acc: 0.9994 - val_loss: 0.0135 - val_acc: 0.9974
Epoch 53/200
 - 14s - loss: 0.0058 - acc: 0.9997 - val_loss: 0.0056 - val_acc: 1.0000
Epoch 54/200
 - 15s - loss: 0.0079 - acc: 0.9994 - val_loss: 0.0071 - val_acc: 0.9987
Epoch 55/200
 - 14s - loss: 0.0093 - acc: 0.9990 - val_loss: 0.0075 - val_acc: 0.9987
Epoch 56/200
 - 14s - loss: 0.0050 - acc: 1.0000 - val_loss: 0.0078 - val_acc: 0.9987
Epoch 57/200
 - 14s - loss: 0.0048 - acc: 1.0000 - val_loss: 0.0050 - val_acc: 1.0000
Epoch 58/200
 - 15s - loss: 0.0041 - acc: 1.0000 - val_loss: 0.0112 - val_acc: 0.9974
Epoch 59/200
 - 14s - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0866 - val_acc: 0.9872
Epoch 60/200
 - 14s - loss: 0.0250 - acc: 0.9955 - val_loss: 0.0354 - val_acc: 0.9936
Epoch 61/200
 - 14s - loss: 0.0067 - acc: 0.9994 - val_loss: 0.0206 - val_acc: 0.9962
Epoch 62/200
 - 13s - loss: 0.0044 - acc: 0.9997 - val_loss: 0.0114 - val_acc: 0.9974
Epoch 63/200
 - 13s - loss: 0.0068 - acc: 0.9990 - val_loss: 0.2063 - val_acc: 0.9795
Epoch 64/200
 - 13s - loss: 0.0079 - acc: 0.9994 - val_loss: 0.0051 - val_acc: 0.9987
Epoch 65/200
 - 14s - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0112 - val_acc: 0.9974
Epoch 66/200
 - 14s - loss: 0.0048 - acc: 0.9997 - val_loss: 0.0098 - val_acc: 0.9974
Epoch 67/200
 - 14s - loss: 0.0089 - acc: 0.9984 - val_loss: 0.1597 - val_acc: 0.9808
Epoch 68/200
 - 15s - loss: 0.0072 - acc: 0.9987 - val_loss: 0.0049 - val_acc: 0.9987
Epoch 69/200
 - 14s - loss: 0.0044 - acc: 0.9997 - val_loss: 0.0099 - val_acc: 0.9974
Epoch 70/200
 - 15s - loss: 0.0068 - acc: 0.9990 - val_loss: 0.0110 - val_acc: 0.9974
Epoch 71/200
 - 18s - loss: 0.0067 - acc: 0.9994 - val_loss: 0.0088 - val_acc: 0.9987
Epoch 72/200
 - 14s - loss: 0.0040 - acc: 0.9997 - val_loss: 0.0378 - val_acc: 0.9949
Epoch 73/200
 - 15s - loss: 0.0038 - acc: 0.9997 - val_loss: 0.0196 - val_acc: 0.9974
Epoch 74/200
 - 16s - loss: 0.0137 - acc: 0.9978 - val_loss: 0.0056 - val_acc: 0.9987
Epoch 75/200
 - 16s - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0237 - val_acc: 0.9949
Epoch 76/200
 - 14s - loss: 0.0085 - acc: 0.9987 - val_loss: 0.0107 - val_acc: 0.9974
Epoch 77/200
 - 15s - loss: 0.0079 - acc: 0.9978 - val_loss: 0.0194 - val_acc: 0.9949
Epoch 78/200
 - 17s - loss: 0.0088 - acc: 0.9984 - val_loss: 0.0105 - val_acc: 0.9974
Epoch 79/200
 - 14s - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 0.9974
Epoch 80/200
 - 14s - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0041 - val_acc: 0.9987
Epoch 81/200
 - 16s - loss: 0.0166 - acc: 0.9962 - val_loss: 0.0111 - val_acc: 0.9962
Epoch 82/200
 - 16s - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0106 - val_acc: 0.9974
Epoch 83/200
 - 14s - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 0.9987
Epoch 84/200
 - 13s - loss: 0.0039 - acc: 0.9997 - val_loss: 0.0133 - val_acc: 0.9974
Epoch 85/200
 - 13s - loss: 0.0122 - acc: 0.9971 - val_loss: 0.0049 - val_acc: 1.0000
Epoch 86/200
 - 14s - loss: 0.0122 - acc: 0.9981 - val_loss: 0.0503 - val_acc: 0.9910
Epoch 87/200
 - 15s - loss: 0.0058 - acc: 0.9987 - val_loss: 0.0035 - val_acc: 1.0000
Epoch 88/200
 - 16s - loss: 0.0044 - acc: 0.9994 - val_loss: 0.0332 - val_acc: 0.9936
Epoch 89/200
 - 15s - loss: 0.0131 - acc: 0.9978 - val_loss: 0.0039 - val_acc: 1.0000
Epoch 90/200
 - 12s - loss: 0.0039 - acc: 0.9997 - val_loss: 0.0059 - val_acc: 0.9987
Epoch 91/200
 - 12s - loss: 0.0062 - acc: 0.9994 - val_loss: 0.0056 - val_acc: 0.9987
Epoch 92/200
 - 13s - loss: 0.0070 - acc: 0.9987 - val_loss: 0.0104 - val_acc: 0.9974
Epoch 93/200
 - 13s - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0141 - val_acc: 0.9974
Epoch 94/200
 - 13s - loss: 0.0109 - acc: 0.9981 - val_loss: 0.0135 - val_acc: 0.9974
Epoch 95/200
 - 14s - loss: 0.0049 - acc: 0.9990 - val_loss: 0.0059 - val_acc: 0.9987
Epoch 96/200
 - 14s - loss: 0.0041 - acc: 0.9997 - val_loss: 0.0073 - val_acc: 0.9974
Epoch 97/200
 - 14s - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 1.0000
Epoch 98/200
 - 14s - loss: 0.0262 - acc: 0.9965 - val_loss: 0.0115 - val_acc: 0.9987
Epoch 99/200
 - 14s - loss: 0.0070 - acc: 0.9987 - val_loss: 0.0083 - val_acc: 0.9987
Epoch 100/200
 - 14s - loss: 0.0046 - acc: 0.9994 - val_loss: 0.0089 - val_acc: 0.9987
Epoch 101/200
 - 14s - loss: 0.0090 - acc: 0.9978 - val_loss: 0.1045 - val_acc: 0.9846
Epoch 102/200
 - 14s - loss: 0.0141 - acc: 0.9981 - val_loss: 0.0067 - val_acc: 0.9974
Epoch 103/200
 - 14s - loss: 0.0049 - acc: 0.9997 - val_loss: 0.0035 - val_acc: 1.0000
Epoch 104/200
 - 14s - loss: 0.0061 - acc: 0.9994 - val_loss: 0.0041 - val_acc: 1.0000
Epoch 105/200
 - 14s - loss: 0.0054 - acc: 0.9994 - val_loss: 0.0310 - val_acc: 0.9898
Epoch 106/200
 - 14s - loss: 0.0054 - acc: 0.9990 - val_loss: 0.0033 - val_acc: 1.0000
Epoch 107/200
 - 14s - loss: 0.0052 - acc: 0.9997 - val_loss: 0.0063 - val_acc: 0.9987
Epoch 108/200
 - 14s - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0070 - val_acc: 0.9987
Epoch 109/200
 - 15s - loss: 0.0042 - acc: 0.9997 - val_loss: 0.0265 - val_acc: 0.9962
Epoch 110/200
 - 14s - loss: 0.0082 - acc: 0.9984 - val_loss: 0.0246 - val_acc: 0.9949
Epoch 111/200
 - 14s - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0137 - val_acc: 0.9974
Epoch 112/200
 - 14s - loss: 0.0099 - acc: 0.9978 - val_loss: 0.0199 - val_acc: 0.9936
Restoring model weights from the end of the best epoch
Epoch 00112: early stopping
End-train DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Keras TF Training pfa_bottles_0: 3904/3904 100.0%
              precision    recall  f1-score   support

           B       1.00      1.00      1.00        96
           V       1.00      1.00      1.00      3808

    accuracy                           1.00      3904
   macro avg       1.00      1.00      1.00      3904
weighted avg       1.00      1.00      1.00      3904

Keras TF Testing pfa_bottles_0: 975/977 99.8%
              precision    recall  f1-score   support

           B       0.96      0.96      0.96        24
           V       1.00      1.00      1.00       953

    accuracy                           1.00       977
   macro avg       0.98      0.98      0.98       977
weighted avg       1.00      1.00      1.00       977

Keras TF CV pfa_bottles_0: 2512/2519 99.7%
              precision    recall  f1-score   support

           B       0.98      0.90      0.94        61
           V       1.00      1.00      1.00      2458

    accuracy                           1.00      2519
   macro avg       0.99      0.95      0.97      2519
weighted avg       1.00      1.00      1.00      2519

Keras TF stop cnn_pfa_bottles_0
trnargs = {'batch_size':32,'max_iter':200,'lay':[('conv2d',32,[5,5],[2,2]),('elu',),('batch',),('dropout',0.1),('pool',[2,2],[2,2]),('conv2d',32,[5,5],[2,2]),('elu',),('batch',),('dropout',0.1),('pool',[2,2],[2,2]),('flatten',),('ip',90),('relu',),('dropout',0.7)],'base_lr':0.0005, 'optimizer':'adadelta','val_split':0.2,'monitor': 'val_loss','patience':15, 'stop': True}
Keras TF start  cnn_sfa_bottles_0
Train DNN with Keras
Train on 3123 samples, validate on 781 samples
Epoch 1/200
 - 14s - loss: 0.2742 - acc: 0.9629 - val_loss: 0.2047 - val_acc: 0.9744
Epoch 2/200
 - 11s - loss: 0.1671 - acc: 0.9795 - val_loss: 0.1581 - val_acc: 0.9808
Epoch 3/200
 - 10s - loss: 0.1075 - acc: 0.9920 - val_loss: 0.1325 - val_acc: 0.9859
Epoch 4/200
 - 10s - loss: 0.0904 - acc: 0.9958 - val_loss: 0.1093 - val_acc: 0.9859
Epoch 5/200
 - 10s - loss: 0.0837 - acc: 0.9965 - val_loss: 0.0842 - val_acc: 0.9936
Epoch 6/200
 - 10s - loss: 0.0725 - acc: 0.9984 - val_loss: 0.0715 - val_acc: 0.9949
Epoch 7/200
 - 10s - loss: 0.0649 - acc: 0.9978 - val_loss: 0.0786 - val_acc: 0.9923
Epoch 8/200
 - 10s - loss: 0.0553 - acc: 0.9994 - val_loss: 0.0679 - val_acc: 0.9936
Epoch 9/200
 - 10s - loss: 0.0512 - acc: 0.9981 - val_loss: 0.0487 - val_acc: 0.9987
Epoch 10/200
 - 10s - loss: 0.0442 - acc: 0.9990 - val_loss: 0.0478 - val_acc: 0.9974
Epoch 11/200
 - 10s - loss: 0.0390 - acc: 0.9994 - val_loss: 0.0430 - val_acc: 0.9974
Epoch 12/200
 - 10s - loss: 0.0342 - acc: 1.0000 - val_loss: 0.0463 - val_acc: 0.9974
Epoch 13/200
 - 10s - loss: 0.0304 - acc: 0.9997 - val_loss: 0.0342 - val_acc: 0.9987
Epoch 14/200
 - 10s - loss: 0.0263 - acc: 1.0000 - val_loss: 0.0282 - val_acc: 0.9987
Epoch 15/200
 - 10s - loss: 0.0235 - acc: 0.9997 - val_loss: 0.0235 - val_acc: 0.9974
Epoch 16/200
 - 10s - loss: 0.0207 - acc: 1.0000 - val_loss: 0.0221 - val_acc: 1.0000
Epoch 17/200
 - 10s - loss: 0.0194 - acc: 0.9994 - val_loss: 0.0223 - val_acc: 0.9962
Epoch 18/200
 - 10s - loss: 0.0172 - acc: 0.9997 - val_loss: 0.0630 - val_acc: 0.9885
Epoch 19/200
 - 10s - loss: 0.0153 - acc: 0.9997 - val_loss: 0.0707 - val_acc: 0.9872
Epoch 20/200
 - 10s - loss: 0.0138 - acc: 0.9997 - val_loss: 0.0276 - val_acc: 0.9949
Epoch 21/200
 - 10s - loss: 0.0121 - acc: 1.0000 - val_loss: 0.0218 - val_acc: 0.9962
Epoch 22/200
 - 10s - loss: 0.0110 - acc: 0.9997 - val_loss: 0.0110 - val_acc: 1.0000
Epoch 23/200
 - 10s - loss: 0.0096 - acc: 0.9997 - val_loss: 0.0116 - val_acc: 0.9987
Epoch 24/200
 - 10s - loss: 0.0085 - acc: 0.9997 - val_loss: 0.0751 - val_acc: 0.9872
Epoch 25/200
 - 10s - loss: 0.0073 - acc: 1.0000 - val_loss: 0.0417 - val_acc: 0.9910
Epoch 26/200
 - 10s - loss: 0.0075 - acc: 0.9997 - val_loss: 0.0497 - val_acc: 0.9846
Epoch 27/200
 - 10s - loss: 0.0067 - acc: 0.9997 - val_loss: 0.0084 - val_acc: 0.9987
Epoch 28/200
 - 10s - loss: 0.0070 - acc: 0.9994 - val_loss: 0.0102 - val_acc: 0.9974
Epoch 29/200
 - 10s - loss: 0.0061 - acc: 0.9997 - val_loss: 0.0102 - val_acc: 0.9974
Epoch 30/200
 - 11s - loss: 0.0049 - acc: 1.0000 - val_loss: 0.0321 - val_acc: 0.9923
Epoch 31/200
 - 10s - loss: 0.0049 - acc: 0.9997 - val_loss: 0.0097 - val_acc: 0.9974
Epoch 32/200
 - 10s - loss: 0.0065 - acc: 0.9990 - val_loss: 0.0679 - val_acc: 0.9872
Epoch 33/200
 - 10s - loss: 0.0044 - acc: 0.9997 - val_loss: 0.0163 - val_acc: 0.9936
Epoch 34/200
 - 10s - loss: 0.0050 - acc: 0.9994 - val_loss: 0.0328 - val_acc: 0.9898
Epoch 35/200
 - 10s - loss: 0.0065 - acc: 0.9987 - val_loss: 0.0748 - val_acc: 0.9859
Epoch 36/200
 - 10s - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0068 - val_acc: 0.9974
Epoch 37/200
 - 10s - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 0.9987
Epoch 38/200
 - 10s - loss: 0.0064 - acc: 0.9984 - val_loss: 0.0062 - val_acc: 0.9987
Epoch 39/200
 - 10s - loss: 0.0066 - acc: 0.9987 - val_loss: 0.0174 - val_acc: 0.9962
Epoch 40/200
 - 10s - loss: 0.0036 - acc: 1.0000 - val_loss: 0.0101 - val_acc: 0.9962
Epoch 41/200
 - 10s - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0769 - val_acc: 0.9859
Epoch 42/200
 - 10s - loss: 0.0047 - acc: 0.9994 - val_loss: 0.0233 - val_acc: 0.9949
Epoch 43/200
 - 9s - loss: 0.0033 - acc: 0.9997 - val_loss: 0.0081 - val_acc: 0.9974
Epoch 44/200
 - 9s - loss: 0.0037 - acc: 0.9997 - val_loss: 0.0588 - val_acc: 0.9885
Epoch 45/200
 - 9s - loss: 0.0043 - acc: 0.9994 - val_loss: 0.0052 - val_acc: 0.9987
Epoch 46/200
 - 9s - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0153 - val_acc: 0.9949
Epoch 47/200
 - 9s - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0121 - val_acc: 0.9974
Epoch 48/200
 - 9s - loss: 0.0039 - acc: 0.9994 - val_loss: 0.0086 - val_acc: 0.9974
Epoch 49/200
 - 9s - loss: 0.0028 - acc: 1.0000 - val_loss: 0.1015 - val_acc: 0.9872
Epoch 50/200
 - 9s - loss: 0.0082 - acc: 0.9984 - val_loss: 0.0070 - val_acc: 0.9987
Epoch 51/200
 - 10s - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0101 - val_acc: 0.9962
Epoch 52/200
 - 10s - loss: 0.0037 - acc: 0.9990 - val_loss: 0.0095 - val_acc: 0.9974
Epoch 53/200
 - 10s - loss: 0.0035 - acc: 0.9997 - val_loss: 0.0081 - val_acc: 0.9987
Epoch 54/200
 - 10s - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0307 - val_acc: 0.9949
Epoch 55/200
 - 10s - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0255 - val_acc: 0.9962
Epoch 56/200
 - 10s - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0260 - val_acc: 0.9936
Epoch 57/200
 - 10s - loss: 0.0028 - acc: 0.9997 - val_loss: 0.0259 - val_acc: 0.9936
Epoch 58/200
 - 10s - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0137 - val_acc: 0.9962
Epoch 59/200
 - 10s - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0072 - val_acc: 0.9962
Epoch 60/200
 - 10s - loss: 0.0051 - acc: 0.9990 - val_loss: 0.1074 - val_acc: 0.9872
Restoring model weights from the end of the best epoch
Epoch 00060: early stopping
End-train DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Keras TF Training sfa_bottles_0: 3903/3904 100.0%
              precision    recall  f1-score   support

           B       1.00      0.99      0.99        96
           V       1.00      1.00      1.00      3808

    accuracy                           1.00      3904
   macro avg       1.00      0.99      1.00      3904
weighted avg       1.00      1.00      1.00      3904

Keras TF Testing sfa_bottles_0: 973/977 99.6%
              precision    recall  f1-score   support

           B       1.00      0.83      0.91        24
           V       1.00      1.00      1.00       953

    accuracy                           1.00       977
   macro avg       1.00      0.92      0.95       977
weighted avg       1.00      1.00      1.00       977

Keras TF CV sfa_bottles_0: 2504/2519 99.4%
              precision    recall  f1-score   support

           B       0.88      0.87      0.88        61
           V       1.00      1.00      1.00      2458

    accuracy                           0.99      2519
   macro avg       0.94      0.93      0.94      2519
weighted avg       0.99      0.99      0.99      2519

Keras TF stop cnn_sfa_bottles_0
svm start  sig_bottles_0
SVM Training sig_bottles_0: 3901/3904 99.9%
              precision    recall  f1-score   support

           B       0.97      1.00      0.98        96
           V       1.00      1.00      1.00      3808

    accuracy                           1.00      3904
   macro avg       0.98      1.00      0.99      3904
weighted avg       1.00      1.00      1.00      3904

SVM Testing sig_bottles_0: 970/977 99.3%
              precision    recall  f1-score   support

           B       0.84      0.88      0.86        24
           V       1.00      1.00      1.00       953

    accuracy                           0.99       977
   macro avg       0.92      0.94      0.93       977
weighted avg       0.99      0.99      0.99       977

SVM CV sig_bottles_0: 2413/2519 95.8%
              precision    recall  f1-score   support

           B       0.15      0.16      0.16        61
           V       0.98      0.98      0.98      2458

    accuracy                           0.96      2519
   macro avg       0.57      0.57      0.57      2519
weighted avg       0.96      0.96      0.96      2519

svm finish sig_bottles_0
svm start  pfa_bottles_0
SVM Training pfa_bottles_0: 3904/3904 100.0%
              precision    recall  f1-score   support

           B       1.00      1.00      1.00        96
           V       1.00      1.00      1.00      3808

    accuracy                           1.00      3904
   macro avg       1.00      1.00      1.00      3904
weighted avg       1.00      1.00      1.00      3904

SVM Testing pfa_bottles_0: 973/977 99.6%
              precision    recall  f1-score   support

           B       1.00      0.83      0.91        24
           V       1.00      1.00      1.00       953

    accuracy                           1.00       977
   macro avg       1.00      0.92      0.95       977
weighted avg       1.00      1.00      1.00       977

SVM CV pfa_bottles_0: 2494/2519 99.0%
              precision    recall  f1-score   support

           B       0.97      0.61      0.75        61
           V       0.99      1.00      0.99      2458

    accuracy                           0.99      2519
   macro avg       0.98      0.80      0.87      2519
weighted avg       0.99      0.99      0.99      2519

svm finish pfa_bottles_0
svm start  sfa_bottles_0
SVM Training sfa_bottles_0: 3904/3904 100.0%
              precision    recall  f1-score   support

           B       1.00      1.00      1.00        96
           V       1.00      1.00      1.00      3808

    accuracy                           1.00      3904
   macro avg       1.00      1.00      1.00      3904
weighted avg       1.00      1.00      1.00      3904

SVM Testing sfa_bottles_0: 971/977 99.4%
              precision    recall  f1-score   support

           B       1.00      0.75      0.86        24
           V       0.99      1.00      1.00       953

    accuracy                           0.99       977
   macro avg       1.00      0.88      0.93       977
weighted avg       0.99      0.99      0.99       977

SVM CV sfa_bottles_0: 2468/2519 98.0%
              precision    recall  f1-score   support

           B       0.92      0.18      0.30        61
           V       0.98      1.00      0.99      2458

    accuracy                           0.98      2519
   macro avg       0.95      0.59      0.65      2519
weighted avg       0.98      0.98      0.97      2519

svm finish sfa_bottles_0
trnargs = {'states':1, 'its': [0]}
hmm start  pfa_bottles_0
spl 0
CMP: 967/977 99.0%
HMM Training pfa_bottles_0: 3866/3904 99.0%
              precision    recall  f1-score   support

           B       0.72      1.00      0.83        96
           V       1.00      0.99      0.99      3808

    accuracy                           0.99      3904
   macro avg       0.86      1.00      0.91      3904
weighted avg       0.99      0.99      0.99      3904

HMM Testing pfa_bottles_0: 967/977 99.0%
              precision    recall  f1-score   support

           B       0.71      1.00      0.83        24
           V       1.00      0.99      0.99       953

    accuracy                           0.99       977
   macro avg       0.85      0.99      0.91       977
weighted avg       0.99      0.99      0.99       977

HMM CV pfa_bottles_0: 2476/2519 98.3%
              precision    recall  f1-score   support

           B       0.61      0.80      0.70        61
           V       1.00      0.99      0.99      2458

    accuracy                           0.98      2519
   macro avg       0.80      0.90      0.84      2519
weighted avg       0.99      0.98      0.98      2519

hmm start  sfa_bottles_0
spl 0
CMP: 777/977 79.5%
spl 0 ite 1
CMP: 944/977 96.6%
spl 0 ite 2
CMP: 959/977 98.2%
spl 0 ite 3
CMP: 963/977 98.6%
spl 1
CMP: 962/977 98.5%
spl 1 ite 1
CMP: 972/977 99.5%
spl 1 ite 2
CMP: 972/977 99.5%
spl 1 ite 3
CMP: 974/977 99.7%
spl 1 ite 4
CMP: 973/977 99.6%
spl 1 ite 5
CMP: 975/977 99.8%
spl 2
CMP: 974/977 99.7%
spl 2 ite 1
CMP: 976/977 99.9%
spl 2 ite 2
CMP: 976/977 99.9%
spl 2 ite 3
CMP: 976/977 99.9%
spl 2 ite 4
CMP: 976/977 99.9%
spl 2 ite 5
CMP: 976/977 99.9%
spl 2 ite 6
CMP: 976/977 99.9%
spl 2 ite 7
CMP: 976/977 99.9%
spl 3
CMP: 976/977 99.9%
spl 3 ite 1
CMP: 976/977 99.9%
spl 3 ite 2
CMP: 976/977 99.9%
spl 3 ite 3
CMP: 976/977 99.9%
spl 3 ite 4
CMP: 976/977 99.9%
spl 3 ite 5
CMP: 976/977 99.9%
spl 3 ite 6
CMP: 976/977 99.9%
spl 3 ite 7
CMP: 976/977 99.9%
spl 3 ite 8
CMP: 977/977 100.0%
spl 3 ite 9
CMP: 977/977 100.0%
spl 4
CMP: 976/977 99.9%
spl 4 ite 1
CMP: 977/977 100.0%
spl 4 ite 2
CMP: 977/977 100.0%
spl 4 ite 3
CMP: 977/977 100.0%
spl 4 ite 4
CMP: 977/977 100.0%
spl 4 ite 5
CMP: 977/977 100.0%
spl 4 ite 6
CMP: 977/977 100.0%
spl 4 ite 7
CMP: 977/977 100.0%
spl 4 ite 8
CMP: 977/977 100.0%
spl 4 ite 9
CMP: 977/977 100.0%
spl 4 ite 10
CMP: 977/977 100.0%
spl 4 ite 11
CMP: 977/977 100.0%
spl 5
CMP: 975/977 99.8%
spl 5 ite 1
CMP: 976/977 99.9%
spl 5 ite 2
CMP: 976/977 99.9%
spl 5 ite 3
CMP: 975/977 99.8%
spl 5 ite 4
CMP: 975/977 99.8%
spl 5 ite 5
CMP: 975/977 99.8%
spl 5 ite 6
CMP: 974/977 99.7%
spl 5 ite 7
CMP: 974/977 99.7%
spl 5 ite 8
CMP: 974/977 99.7%
spl 5 ite 9
CMP: 974/977 99.7%
spl 5 ite 10
CMP: 974/977 99.7%
spl 5 ite 11
CMP: 973/977 99.6%
spl 5 ite 12
CMP: 973/977 99.6%
spl 5 ite 13
CMP: 973/977 99.6%
HMM Training sfa_bottles_0: 3904/3904 100.0%
              precision    recall  f1-score   support

           B       1.00      1.00      1.00        96
           V       1.00      1.00      1.00      3808

    accuracy                           1.00      3904
   macro avg       1.00      1.00      1.00      3904
weighted avg       1.00      1.00      1.00      3904

HMM Testing sfa_bottles_0: 973/977 99.6%
              precision    recall  f1-score   support

           B       1.00      0.83      0.91        24
           V       1.00      1.00      1.00       953

    accuracy                           1.00       977
   macro avg       1.00      0.92      0.95       977
weighted avg       1.00      1.00      1.00       977

HMM CV sfa_bottles_0: 2492/2519 98.9%
              precision    recall  f1-score   support

           B       1.00      0.56      0.72        61
           V       0.99      1.00      0.99      2458

    accuracy                           0.99      2519
   macro avg       0.99      0.78      0.86      2519
weighted avg       0.99      0.99      0.99      2519

flst [bottles]
load fdb /home/kraljiva/Projects/uasr-data/bottles/Versuch004_E/log/fdb
trnargs = {'batch_size':32,'max_iter':200,'lay':[('ip',256),('lrelu',),('batch',),('dropout',0.6), ('ip',128),('lrelu',),('batch',),('dropout',0.6)],'base_lr':0.0005,'optimizer':'adagrad','val_split':0.2,'monitor': 'val_loss','patience':10, 'stop': True}
Keras TF start  snn_sig_bottles_1
Train DNN with Keras
Train on 3124 samples, validate on 781 samples
Epoch 1/200
 - 27s - loss: 1.4200 - acc: 0.7666 - val_loss: 0.9064 - val_acc: 0.9667
Epoch 2/200
 - 23s - loss: 0.9348 - acc: 0.9081 - val_loss: 0.7130 - val_acc: 0.9667
Epoch 3/200
 - 22s - loss: 0.7182 - acc: 0.9443 - val_loss: 0.6084 - val_acc: 0.9667
Epoch 4/200
 - 23s - loss: 0.5969 - acc: 0.9565 - val_loss: 0.5411 - val_acc: 0.9667
Epoch 5/200
 - 21s - loss: 0.5306 - acc: 0.9587 - val_loss: 0.5223 - val_acc: 0.9667
Epoch 6/200
 - 22s - loss: 0.4729 - acc: 0.9661 - val_loss: 0.4567 - val_acc: 0.9667
Epoch 7/200
 - 22s - loss: 0.4363 - acc: 0.9661 - val_loss: 0.4462 - val_acc: 0.9667
Epoch 8/200
 - 22s - loss: 0.3944 - acc: 0.9706 - val_loss: 0.4125 - val_acc: 0.9667
Epoch 9/200
 - 23s - loss: 0.3588 - acc: 0.9738 - val_loss: 0.3822 - val_acc: 0.9667
Epoch 10/200
 - 23s - loss: 0.3478 - acc: 0.9738 - val_loss: 0.5835 - val_acc: 0.8976
Epoch 11/200
 - 22s - loss: 0.3311 - acc: 0.9744 - val_loss: 0.4105 - val_acc: 0.9667
Epoch 12/200
 - 23s - loss: 0.3119 - acc: 0.9779 - val_loss: 0.3901 - val_acc: 0.9667
Epoch 13/200
 - 23s - loss: 0.2953 - acc: 0.9789 - val_loss: 0.3664 - val_acc: 0.9667
Epoch 14/200
 - 23s - loss: 0.2806 - acc: 0.9805 - val_loss: 0.3154 - val_acc: 0.9693
Epoch 15/200
 - 24s - loss: 0.2721 - acc: 0.9805 - val_loss: 0.3538 - val_acc: 0.9667
Epoch 16/200
 - 24s - loss: 0.2587 - acc: 0.9830 - val_loss: 0.2916 - val_acc: 0.9718
Epoch 17/200
 - 24s - loss: 0.2448 - acc: 0.9837 - val_loss: 0.4267 - val_acc: 0.9667
Epoch 18/200
 - 24s - loss: 0.2441 - acc: 0.9818 - val_loss: 0.3834 - val_acc: 0.9667
Epoch 19/200
 - 24s - loss: 0.2413 - acc: 0.9837 - val_loss: 0.4108 - val_acc: 0.9667
Epoch 20/200
 - 24s - loss: 0.2313 - acc: 0.9846 - val_loss: 0.2813 - val_acc: 0.9693
Epoch 21/200
 - 24s - loss: 0.2290 - acc: 0.9830 - val_loss: 0.3005 - val_acc: 0.9680
Epoch 22/200
 - 24s - loss: 0.2182 - acc: 0.9843 - val_loss: 0.3740 - val_acc: 0.9667
Epoch 23/200
 - 23s - loss: 0.2185 - acc: 0.9827 - val_loss: 0.2755 - val_acc: 0.9706
Epoch 24/200
 - 22s - loss: 0.2024 - acc: 0.9885 - val_loss: 0.3214 - val_acc: 0.9667
Epoch 25/200
 - 23s - loss: 0.2024 - acc: 0.9859 - val_loss: 0.3150 - val_acc: 0.9667
Epoch 26/200
 - 23s - loss: 0.2041 - acc: 0.9853 - val_loss: 0.3100 - val_acc: 0.9667
Epoch 27/200
 - 23s - loss: 0.1926 - acc: 0.9891 - val_loss: 0.2839 - val_acc: 0.9680
Epoch 28/200
 - 23s - loss: 0.1906 - acc: 0.9872 - val_loss: 0.3196 - val_acc: 0.9667
Epoch 29/200
 - 22s - loss: 0.1945 - acc: 0.9856 - val_loss: 0.2695 - val_acc: 0.9731
Epoch 30/200
 - 22s - loss: 0.1790 - acc: 0.9901 - val_loss: 0.3110 - val_acc: 0.9680
Epoch 31/200
 - 22s - loss: 0.1817 - acc: 0.9878 - val_loss: 0.3838 - val_acc: 0.9667
Epoch 32/200
 - 24s - loss: 0.1685 - acc: 0.9904 - val_loss: 0.5367 - val_acc: 0.9667
Epoch 33/200
 - 24s - loss: 0.1652 - acc: 0.9901 - val_loss: 0.3268 - val_acc: 0.9667
Epoch 34/200
 - 24s - loss: 0.1619 - acc: 0.9920 - val_loss: 0.3296 - val_acc: 0.9680
Epoch 35/200
 - 23s - loss: 0.1591 - acc: 0.9885 - val_loss: 0.3274 - val_acc: 0.9680
Epoch 36/200
 - 23s - loss: 0.1582 - acc: 0.9910 - val_loss: 0.2650 - val_acc: 0.9693
Epoch 37/200
 - 23s - loss: 0.1613 - acc: 0.9885 - val_loss: 0.2627 - val_acc: 0.9693
Epoch 38/200
 - 23s - loss: 0.1611 - acc: 0.9907 - val_loss: 0.3210 - val_acc: 0.9667
Epoch 39/200
 - 23s - loss: 0.1655 - acc: 0.9898 - val_loss: 0.2480 - val_acc: 0.9718
Epoch 40/200
 - 24s - loss: 0.1465 - acc: 0.9942 - val_loss: 0.2599 - val_acc: 0.9718
Epoch 41/200
 - 23s - loss: 0.1490 - acc: 0.9936 - val_loss: 0.3017 - val_acc: 0.9680
Epoch 42/200
 - 22s - loss: 0.1471 - acc: 0.9920 - val_loss: 0.3317 - val_acc: 0.9667
Epoch 43/200
 - 23s - loss: 0.1510 - acc: 0.9904 - val_loss: 0.3319 - val_acc: 0.9680
Epoch 44/200
 - 22s - loss: 0.1444 - acc: 0.9917 - val_loss: 0.3493 - val_acc: 0.9667
Epoch 45/200
 - 24s - loss: 0.1446 - acc: 0.9914 - val_loss: 0.3355 - val_acc: 0.9667
Epoch 46/200
 - 24s - loss: 0.1454 - acc: 0.9910 - val_loss: 0.2194 - val_acc: 0.9744
Epoch 47/200
 - 24s - loss: 0.1468 - acc: 0.9898 - val_loss: 0.2644 - val_acc: 0.9462
Epoch 48/200
 - 24s - loss: 0.1467 - acc: 0.9923 - val_loss: 0.3368 - val_acc: 0.9667
Epoch 49/200
 - 24s - loss: 0.1469 - acc: 0.9894 - val_loss: 2.9798 - val_acc: 0.1613
Epoch 50/200
 - 24s - loss: 0.1350 - acc: 0.9933 - val_loss: 0.2475 - val_acc: 0.9680
Epoch 51/200
 - 23s - loss: 0.1370 - acc: 0.9933 - val_loss: 0.2287 - val_acc: 0.9731
Epoch 52/200
 - 23s - loss: 0.1346 - acc: 0.9923 - val_loss: 0.2422 - val_acc: 0.9718
Epoch 53/200
 - 24s - loss: 0.1344 - acc: 0.9923 - val_loss: 0.2240 - val_acc: 0.9718
Epoch 54/200
 - 23s - loss: 0.1411 - acc: 0.9882 - val_loss: 0.3721 - val_acc: 0.9667
Epoch 55/200
 - 22s - loss: 0.1391 - acc: 0.9917 - val_loss: 0.2298 - val_acc: 0.9731
Epoch 56/200
 - 22s - loss: 0.1285 - acc: 0.9926 - val_loss: 0.2175 - val_acc: 0.9731
Epoch 57/200
 - 23s - loss: 0.1241 - acc: 0.9952 - val_loss: 0.2590 - val_acc: 0.9680
Epoch 58/200
 - 22s - loss: 0.1268 - acc: 0.9930 - val_loss: 0.1955 - val_acc: 0.9731
Epoch 59/200
 - 24s - loss: 0.1315 - acc: 0.9898 - val_loss: 0.3669 - val_acc: 0.9667
Epoch 60/200
 - 24s - loss: 0.1253 - acc: 0.9936 - val_loss: 0.5450 - val_acc: 0.9667
Epoch 61/200
 - 24s - loss: 0.1303 - acc: 0.9910 - val_loss: 0.2010 - val_acc: 0.9744
Epoch 62/200
 - 24s - loss: 0.1286 - acc: 0.9920 - val_loss: 0.3394 - val_acc: 0.9667
Epoch 63/200
 - 25s - loss: 0.1267 - acc: 0.9939 - val_loss: 0.2604 - val_acc: 0.9462
Epoch 64/200
 - 24s - loss: 0.1156 - acc: 0.9958 - val_loss: 0.1991 - val_acc: 0.9731
Epoch 65/200
 - 24s - loss: 0.1195 - acc: 0.9910 - val_loss: 0.2631 - val_acc: 0.9706
Epoch 66/200
 - 24s - loss: 0.1166 - acc: 0.9936 - val_loss: 0.2301 - val_acc: 0.9757
Epoch 67/200
 - 24s - loss: 0.1107 - acc: 0.9949 - val_loss: 0.2751 - val_acc: 0.9680
Epoch 68/200
 - 24s - loss: 0.1099 - acc: 0.9949 - val_loss: 0.2812 - val_acc: 0.9693
Restoring model weights from the end of the best epoch
Epoch 00068: early stopping
End-train DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Keras TF Training sig_bottles_1: 3878/3905 99.3%
              precision    recall  f1-score   support

           B       0.94      0.77      0.85        96
           V       0.99      1.00      1.00      3809

    accuracy                           0.99      3905
   macro avg       0.97      0.88      0.92      3905
weighted avg       0.99      0.99      0.99      3905

Keras TF Testing sig_bottles_1: 959/976 98.3%
              precision    recall  f1-score   support

           B       0.77      0.42      0.54        24
           V       0.99      1.00      0.99       952

    accuracy                           0.98       976
   macro avg       0.88      0.71      0.77       976
weighted avg       0.98      0.98      0.98       976

Keras TF CV sig_bottles_1: 2445/2519 97.1%
              precision    recall  f1-score   support

           B       0.30      0.16      0.21        61
           V       0.98      0.99      0.99      2458

    accuracy                           0.97      2519
   macro avg       0.64      0.58      0.60      2519
weighted avg       0.96      0.97      0.97      2519

Keras TF stop snn_sig_bottles_1
trnargs = {'batch_size':32,'max_iter':200,'lay':[('ip',256),('lrelu',),('batch',),('dropout',0.7), ('ip',128),('lrelu',),('batch',),('dropout',0.7)],'base_lr':0.0005,'optimizer':'adagrad','val_split':0.2,'monitor': 'val_loss','patience':10, 'stop': True}
Keras TF start  snn_pfa_bottles_1
Train DNN with Keras
Train on 3124 samples, validate on 781 samples
Epoch 1/200
 - 7s - loss: 1.1058 - acc: 0.7295 - val_loss: 0.6140 - val_acc: 0.9667
Epoch 2/200
 - 6s - loss: 0.7235 - acc: 0.8761 - val_loss: 0.4923 - val_acc: 0.9667
Epoch 3/200
 - 5s - loss: 0.5774 - acc: 0.9251 - val_loss: 0.4382 - val_acc: 0.9667
Epoch 4/200
 - 4s - loss: 0.4914 - acc: 0.9398 - val_loss: 0.4149 - val_acc: 0.9667
Epoch 5/200
 - 4s - loss: 0.4301 - acc: 0.9561 - val_loss: 0.3757 - val_acc: 0.9667
Epoch 6/200
 - 4s - loss: 0.3810 - acc: 0.9635 - val_loss: 0.3286 - val_acc: 0.9680
Epoch 7/200
 - 4s - loss: 0.3489 - acc: 0.9648 - val_loss: 0.3141 - val_acc: 0.9667
Epoch 8/200
 - 4s - loss: 0.3097 - acc: 0.9738 - val_loss: 0.3282 - val_acc: 0.9667
Epoch 9/200
 - 4s - loss: 0.2996 - acc: 0.9728 - val_loss: 0.3013 - val_acc: 0.9667
Epoch 10/200
 - 4s - loss: 0.2715 - acc: 0.9776 - val_loss: 0.2976 - val_acc: 0.9667
Epoch 11/200
 - 4s - loss: 0.2468 - acc: 0.9834 - val_loss: 0.3441 - val_acc: 0.9667
Epoch 12/200
 - 4s - loss: 0.2402 - acc: 0.9821 - val_loss: 0.2622 - val_acc: 0.9680
Epoch 13/200
 - 4s - loss: 0.2317 - acc: 0.9802 - val_loss: 0.2133 - val_acc: 0.9898
Epoch 14/200
 - 4s - loss: 0.2187 - acc: 0.9859 - val_loss: 0.2310 - val_acc: 0.9718
Epoch 15/200
 - 4s - loss: 0.2053 - acc: 0.9859 - val_loss: 0.2151 - val_acc: 0.9770
Epoch 16/200
 - 4s - loss: 0.1931 - acc: 0.9904 - val_loss: 0.2211 - val_acc: 0.9731
Epoch 17/200
 - 4s - loss: 0.1863 - acc: 0.9898 - val_loss: 0.2302 - val_acc: 0.9718
Epoch 18/200
 - 4s - loss: 0.1879 - acc: 0.9853 - val_loss: 0.2016 - val_acc: 0.9770
Epoch 19/200
 - 4s - loss: 0.1748 - acc: 0.9907 - val_loss: 0.1827 - val_acc: 0.9872
Epoch 20/200
 - 4s - loss: 0.1803 - acc: 0.9898 - val_loss: 0.1726 - val_acc: 0.9910
Epoch 21/200
 - 4s - loss: 0.1651 - acc: 0.9926 - val_loss: 0.1906 - val_acc: 0.9834
Epoch 22/200
 - 4s - loss: 0.1630 - acc: 0.9904 - val_loss: 0.1967 - val_acc: 0.9795
Epoch 23/200
 - 4s - loss: 0.1611 - acc: 0.9920 - val_loss: 0.1688 - val_acc: 0.9872
Epoch 24/200
 - 4s - loss: 0.1577 - acc: 0.9907 - val_loss: 0.1929 - val_acc: 0.9821
Epoch 25/200
 - 4s - loss: 0.1543 - acc: 0.9917 - val_loss: 0.2318 - val_acc: 0.9693
Epoch 26/200
 - 4s - loss: 0.1484 - acc: 0.9914 - val_loss: 0.2063 - val_acc: 0.9757
Epoch 27/200
 - 4s - loss: 0.1488 - acc: 0.9926 - val_loss: 0.2143 - val_acc: 0.9706
Epoch 28/200
 - 4s - loss: 0.1501 - acc: 0.9898 - val_loss: 0.2527 - val_acc: 0.9680
Epoch 29/200
 - 4s - loss: 0.1425 - acc: 0.9926 - val_loss: 0.2208 - val_acc: 0.9693
Epoch 30/200
 - 4s - loss: 0.1389 - acc: 0.9942 - val_loss: 0.1611 - val_acc: 0.9872
Epoch 31/200
 - 4s - loss: 0.1407 - acc: 0.9917 - val_loss: 0.1522 - val_acc: 0.9885
Epoch 32/200
 - 4s - loss: 0.1342 - acc: 0.9936 - val_loss: 0.2132 - val_acc: 0.9706
Epoch 33/200
 - 4s - loss: 0.1345 - acc: 0.9933 - val_loss: 0.1406 - val_acc: 0.9936
Epoch 34/200
 - 4s - loss: 0.1271 - acc: 0.9926 - val_loss: 0.1781 - val_acc: 0.9834
Epoch 35/200
 - 4s - loss: 0.1334 - acc: 0.9923 - val_loss: 0.1749 - val_acc: 0.9795
Epoch 36/200
 - 4s - loss: 0.1318 - acc: 0.9901 - val_loss: 0.2024 - val_acc: 0.9706
Epoch 37/200
 - 4s - loss: 0.1314 - acc: 0.9939 - val_loss: 0.1293 - val_acc: 0.9898
Epoch 38/200
 - 4s - loss: 0.1249 - acc: 0.9936 - val_loss: 0.6744 - val_acc: 0.6927
Epoch 39/200
 - 4s - loss: 0.1215 - acc: 0.9949 - val_loss: 0.1256 - val_acc: 0.9923
Epoch 40/200
 - 4s - loss: 0.1175 - acc: 0.9952 - val_loss: 0.7712 - val_acc: 0.6210
Epoch 41/200
 - 4s - loss: 0.1156 - acc: 0.9965 - val_loss: 0.1253 - val_acc: 0.9898
Epoch 42/200
 - 4s - loss: 0.1136 - acc: 0.9965 - val_loss: 0.1186 - val_acc: 0.9936
Epoch 43/200
 - 4s - loss: 0.1135 - acc: 0.9955 - val_loss: 0.2262 - val_acc: 0.9706
Epoch 44/200
 - 4s - loss: 0.1186 - acc: 0.9946 - val_loss: 0.1589 - val_acc: 0.9821
Epoch 45/200
 - 4s - loss: 0.1098 - acc: 0.9958 - val_loss: 0.1654 - val_acc: 0.9795
Epoch 46/200
 - 4s - loss: 0.1098 - acc: 0.9965 - val_loss: 0.1671 - val_acc: 0.9795
Epoch 47/200
 - 4s - loss: 0.1055 - acc: 0.9955 - val_loss: 0.1915 - val_acc: 0.9744
Epoch 48/200
 - 4s - loss: 0.1021 - acc: 0.9987 - val_loss: 0.1724 - val_acc: 0.9770
Epoch 49/200
 - 4s - loss: 0.1032 - acc: 0.9962 - val_loss: 0.1452 - val_acc: 0.9846
Epoch 50/200
 - 5s - loss: 0.0991 - acc: 0.9974 - val_loss: 0.1353 - val_acc: 0.9872
Epoch 51/200
 - 4s - loss: 0.0992 - acc: 0.9974 - val_loss: 0.1286 - val_acc: 0.9885
Epoch 52/200
 - 4s - loss: 0.0972 - acc: 0.9971 - val_loss: 0.1332 - val_acc: 0.9872
Restoring model weights from the end of the best epoch
Epoch 00052: early stopping
End-train DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Keras TF Training pfa_bottles_1: 3900/3905 99.9%
              precision    recall  f1-score   support

           B       1.00      0.95      0.97        96
           V       1.00      1.00      1.00      3809

    accuracy                           1.00      3905
   macro avg       1.00      0.97      0.99      3905
weighted avg       1.00      1.00      1.00      3905

Keras TF Testing pfa_bottles_1: 975/976 99.9%
              precision    recall  f1-score   support

           B       1.00      0.96      0.98        24
           V       1.00      1.00      1.00       952

    accuracy                           1.00       976
   macro avg       1.00      0.98      0.99       976
weighted avg       1.00      1.00      1.00       976

Keras TF CV pfa_bottles_1: 2509/2519 99.6%
              precision    recall  f1-score   support

           B       1.00      0.84      0.91        61
           V       1.00      1.00      1.00      2458

    accuracy                           1.00      2519
   macro avg       1.00      0.92      0.95      2519
weighted avg       1.00      1.00      1.00      2519

Keras TF stop snn_pfa_bottles_1
trnargs = {'batch_size':32,'max_iter':200,'lay':[('ip',128),('lrelu',),('batch',),('dropout',0.7), ('ip',64),('lrelu',),('batch',),('dropout',0.7)],'base_lr':0.0005,'optimizer':'adagrad','val_split':0.2,'monitor': 'val_loss','patience':10, 'stop': True}
Keras TF start  snn_sfa_bottles_1
Train DNN with Keras
Train on 3124 samples, validate on 781 samples
Epoch 1/200
 - 4s - loss: 1.0643 - acc: 0.6601 - val_loss: 0.6129 - val_acc: 0.9718
Epoch 2/200
 - 2s - loss: 0.7565 - acc: 0.8083 - val_loss: 0.5190 - val_acc: 0.9693
Epoch 3/200
 - 2s - loss: 0.6338 - acc: 0.8684 - val_loss: 0.4572 - val_acc: 0.9667
Epoch 4/200
 - 2s - loss: 0.5461 - acc: 0.9117 - val_loss: 0.4176 - val_acc: 0.9667
Epoch 5/200
 - 2s - loss: 0.5006 - acc: 0.9299 - val_loss: 0.3990 - val_acc: 0.9667
Epoch 6/200
 - 2s - loss: 0.4683 - acc: 0.9411 - val_loss: 0.3797 - val_acc: 0.9667
Epoch 7/200
 - 2s - loss: 0.4293 - acc: 0.9533 - val_loss: 0.3678 - val_acc: 0.9667
Epoch 8/200
 - 2s - loss: 0.4070 - acc: 0.9565 - val_loss: 0.3515 - val_acc: 0.9680
Epoch 9/200
 - 2s - loss: 0.3806 - acc: 0.9667 - val_loss: 0.3408 - val_acc: 0.9680
Epoch 10/200
 - 2s - loss: 0.3662 - acc: 0.9686 - val_loss: 0.3313 - val_acc: 0.9693
Epoch 11/200
 - 2s - loss: 0.3600 - acc: 0.9661 - val_loss: 0.3191 - val_acc: 0.9718
Epoch 12/200
 - 2s - loss: 0.3404 - acc: 0.9718 - val_loss: 0.3129 - val_acc: 0.9706
Epoch 13/200
 - 2s - loss: 0.3364 - acc: 0.9718 - val_loss: 0.3042 - val_acc: 0.9731
Epoch 14/200
 - 2s - loss: 0.3181 - acc: 0.9741 - val_loss: 0.2950 - val_acc: 0.9795
Epoch 15/200
 - 2s - loss: 0.3046 - acc: 0.9766 - val_loss: 0.2912 - val_acc: 0.9744
Epoch 16/200
 - 2s - loss: 0.2929 - acc: 0.9805 - val_loss: 0.2878 - val_acc: 0.9731
Epoch 17/200
 - 2s - loss: 0.2803 - acc: 0.9843 - val_loss: 0.2870 - val_acc: 0.9744
Epoch 18/200
 - 2s - loss: 0.2709 - acc: 0.9859 - val_loss: 0.2762 - val_acc: 0.9744
Epoch 19/200
 - 2s - loss: 0.2655 - acc: 0.9872 - val_loss: 0.2668 - val_acc: 0.9795
Epoch 20/200
 - 2s - loss: 0.2651 - acc: 0.9843 - val_loss: 0.2655 - val_acc: 0.9770
Epoch 21/200
 - 2s - loss: 0.2536 - acc: 0.9862 - val_loss: 0.2645 - val_acc: 0.9770
Epoch 22/200
 - 2s - loss: 0.2419 - acc: 0.9891 - val_loss: 0.2559 - val_acc: 0.9808
Epoch 23/200
 - 2s - loss: 0.2352 - acc: 0.9901 - val_loss: 0.2583 - val_acc: 0.9770
Epoch 24/200
 - 2s - loss: 0.2385 - acc: 0.9850 - val_loss: 0.2486 - val_acc: 0.9782
Epoch 25/200
 - 2s - loss: 0.2246 - acc: 0.9907 - val_loss: 0.2387 - val_acc: 0.9821
Epoch 26/200
 - 2s - loss: 0.2259 - acc: 0.9891 - val_loss: 0.2438 - val_acc: 0.9782
Epoch 27/200
 - 2s - loss: 0.2215 - acc: 0.9891 - val_loss: 0.2409 - val_acc: 0.9795
Epoch 28/200
 - 2s - loss: 0.2175 - acc: 0.9898 - val_loss: 0.2298 - val_acc: 0.9846
Epoch 29/200
 - 2s - loss: 0.2085 - acc: 0.9923 - val_loss: 0.2267 - val_acc: 0.9821
Epoch 30/200
 - 2s - loss: 0.2018 - acc: 0.9923 - val_loss: 0.2244 - val_acc: 0.9834
Epoch 31/200
 - 2s - loss: 0.2013 - acc: 0.9914 - val_loss: 0.2148 - val_acc: 0.9846
Epoch 32/200
 - 2s - loss: 0.1954 - acc: 0.9917 - val_loss: 0.2158 - val_acc: 0.9834
Epoch 33/200
 - 2s - loss: 0.1866 - acc: 0.9955 - val_loss: 0.2178 - val_acc: 0.9821
Epoch 34/200
 - 2s - loss: 0.1882 - acc: 0.9936 - val_loss: 0.2165 - val_acc: 0.9821
Epoch 35/200
 - 2s - loss: 0.1855 - acc: 0.9930 - val_loss: 0.2035 - val_acc: 0.9846
Epoch 36/200
 - 2s - loss: 0.1789 - acc: 0.9946 - val_loss: 0.2073 - val_acc: 0.9834
Epoch 37/200
 - 2s - loss: 0.1770 - acc: 0.9939 - val_loss: 0.2040 - val_acc: 0.9834
Epoch 38/200
 - 2s - loss: 0.1742 - acc: 0.9930 - val_loss: 0.1974 - val_acc: 0.9846
Epoch 39/200
 - 2s - loss: 0.1681 - acc: 0.9965 - val_loss: 0.1876 - val_acc: 0.9846
Epoch 40/200
 - 2s - loss: 0.1679 - acc: 0.9949 - val_loss: 0.1915 - val_acc: 0.9846
Epoch 41/200
 - 2s - loss: 0.1644 - acc: 0.9946 - val_loss: 0.1925 - val_acc: 0.9846
Epoch 42/200
 - 2s - loss: 0.1647 - acc: 0.9939 - val_loss: 0.1954 - val_acc: 0.9821
Epoch 43/200
 - 2s - loss: 0.1540 - acc: 0.9974 - val_loss: 0.1874 - val_acc: 0.9834
Epoch 44/200
 - 2s - loss: 0.1578 - acc: 0.9955 - val_loss: 0.1818 - val_acc: 0.9834
Epoch 45/200
 - 2s - loss: 0.1526 - acc: 0.9962 - val_loss: 0.1806 - val_acc: 0.9834
Epoch 46/200
 - 2s - loss: 0.1511 - acc: 0.9949 - val_loss: 0.1741 - val_acc: 0.9834
Epoch 47/200
 - 2s - loss: 0.1510 - acc: 0.9942 - val_loss: 0.1766 - val_acc: 0.9834
Epoch 48/200
 - 2s - loss: 0.1492 - acc: 0.9952 - val_loss: 0.1733 - val_acc: 0.9834
Epoch 49/200
 - 2s - loss: 0.1456 - acc: 0.9955 - val_loss: 0.1774 - val_acc: 0.9834
Epoch 50/200
 - 2s - loss: 0.1451 - acc: 0.9949 - val_loss: 0.1770 - val_acc: 0.9834
Epoch 51/200
 - 2s - loss: 0.1431 - acc: 0.9955 - val_loss: 0.1783 - val_acc: 0.9834
Epoch 52/200
 - 2s - loss: 0.1354 - acc: 0.9978 - val_loss: 0.1715 - val_acc: 0.9834
Epoch 53/200
 - 2s - loss: 0.1348 - acc: 0.9958 - val_loss: 0.1659 - val_acc: 0.9834
Epoch 54/200
 - 2s - loss: 0.1343 - acc: 0.9955 - val_loss: 0.1650 - val_acc: 0.9834
Epoch 55/200
 - 2s - loss: 0.1303 - acc: 0.9958 - val_loss: 0.1600 - val_acc: 0.9834
Epoch 56/200
 - 2s - loss: 0.1274 - acc: 0.9968 - val_loss: 0.1641 - val_acc: 0.9834
Epoch 57/200
 - 2s - loss: 0.1277 - acc: 0.9974 - val_loss: 0.1648 - val_acc: 0.9834
Epoch 58/200
 - 2s - loss: 0.1253 - acc: 0.9968 - val_loss: 0.1578 - val_acc: 0.9834
Epoch 59/200
 - 2s - loss: 0.1197 - acc: 0.9984 - val_loss: 0.1571 - val_acc: 0.9834
Epoch 60/200
 - 2s - loss: 0.1250 - acc: 0.9968 - val_loss: 0.1554 - val_acc: 0.9834
Epoch 61/200
 - 2s - loss: 0.1181 - acc: 0.9984 - val_loss: 0.1638 - val_acc: 0.9834
Epoch 62/200
 - 2s - loss: 0.1185 - acc: 0.9974 - val_loss: 0.1550 - val_acc: 0.9834
Epoch 63/200
 - 2s - loss: 0.1167 - acc: 0.9978 - val_loss: 0.1564 - val_acc: 0.9846
Epoch 64/200
 - 2s - loss: 0.1141 - acc: 0.9974 - val_loss: 0.1518 - val_acc: 0.9846
Epoch 65/200
 - 2s - loss: 0.1148 - acc: 0.9978 - val_loss: 0.1498 - val_acc: 0.9846
Epoch 66/200
 - 2s - loss: 0.1146 - acc: 0.9962 - val_loss: 0.1434 - val_acc: 0.9846
Epoch 67/200
 - 2s - loss: 0.1123 - acc: 0.9974 - val_loss: 0.1393 - val_acc: 0.9859
Epoch 68/200
 - 2s - loss: 0.1101 - acc: 0.9968 - val_loss: 0.1444 - val_acc: 0.9846
Epoch 69/200
 - 2s - loss: 0.1085 - acc: 0.9971 - val_loss: 0.1440 - val_acc: 0.9846
Epoch 70/200
 - 2s - loss: 0.1073 - acc: 0.9971 - val_loss: 0.1405 - val_acc: 0.9846
Epoch 71/200
 - 2s - loss: 0.1058 - acc: 0.9962 - val_loss: 0.1411 - val_acc: 0.9846
Epoch 72/200
 - 2s - loss: 0.1051 - acc: 0.9981 - val_loss: 0.1379 - val_acc: 0.9834
Epoch 73/200
 - 2s - loss: 0.1025 - acc: 0.9981 - val_loss: 0.1432 - val_acc: 0.9846
Epoch 74/200
 - 2s - loss: 0.1025 - acc: 0.9971 - val_loss: 0.1434 - val_acc: 0.9834
Epoch 75/200
 - 2s - loss: 0.0995 - acc: 0.9987 - val_loss: 0.1394 - val_acc: 0.9834
Epoch 76/200
 - 2s - loss: 0.1001 - acc: 0.9978 - val_loss: 0.1417 - val_acc: 0.9821
Epoch 77/200
 - 2s - loss: 0.1022 - acc: 0.9971 - val_loss: 0.1353 - val_acc: 0.9834
Epoch 78/200
 - 2s - loss: 0.0944 - acc: 0.9987 - val_loss: 0.1376 - val_acc: 0.9834
Epoch 79/200
 - 2s - loss: 0.0936 - acc: 0.9987 - val_loss: 0.1389 - val_acc: 0.9846
Epoch 80/200
 - 2s - loss: 0.0963 - acc: 0.9978 - val_loss: 0.1322 - val_acc: 0.9846
Epoch 81/200
 - 2s - loss: 0.0911 - acc: 0.9994 - val_loss: 0.1342 - val_acc: 0.9846
Epoch 82/200
 - 2s - loss: 0.0905 - acc: 0.9990 - val_loss: 0.1306 - val_acc: 0.9846
Epoch 83/200
 - 2s - loss: 0.0900 - acc: 0.9987 - val_loss: 0.1288 - val_acc: 0.9846
Epoch 84/200
 - 2s - loss: 0.0878 - acc: 0.9990 - val_loss: 0.1332 - val_acc: 0.9846
Epoch 85/200
 - 2s - loss: 0.0896 - acc: 0.9978 - val_loss: 0.1307 - val_acc: 0.9846
Epoch 86/200
 - 2s - loss: 0.0873 - acc: 0.9971 - val_loss: 0.1264 - val_acc: 0.9846
Epoch 87/200
 - 2s - loss: 0.0842 - acc: 0.9990 - val_loss: 0.1278 - val_acc: 0.9846
Epoch 88/200
 - 2s - loss: 0.0861 - acc: 0.9981 - val_loss: 0.1294 - val_acc: 0.9846
Epoch 89/200
 - 2s - loss: 0.0838 - acc: 0.9990 - val_loss: 0.1289 - val_acc: 0.9846
Epoch 90/200
 - 2s - loss: 0.0879 - acc: 0.9962 - val_loss: 0.1324 - val_acc: 0.9834
Epoch 91/200
 - 2s - loss: 0.0844 - acc: 0.9971 - val_loss: 0.1278 - val_acc: 0.9846
Epoch 92/200
 - 2s - loss: 0.0808 - acc: 0.9990 - val_loss: 0.1297 - val_acc: 0.9834
Epoch 93/200
 - 2s - loss: 0.0820 - acc: 0.9984 - val_loss: 0.1242 - val_acc: 0.9834
Epoch 94/200
 - 2s - loss: 0.0811 - acc: 0.9981 - val_loss: 0.1251 - val_acc: 0.9834
Epoch 95/200
 - 2s - loss: 0.0808 - acc: 0.9981 - val_loss: 0.1224 - val_acc: 0.9834
Epoch 96/200
 - 2s - loss: 0.0822 - acc: 0.9981 - val_loss: 0.1166 - val_acc: 0.9846
Epoch 97/200
 - 2s - loss: 0.0803 - acc: 0.9978 - val_loss: 0.1147 - val_acc: 0.9846
Epoch 98/200
 - 2s - loss: 0.0764 - acc: 0.9994 - val_loss: 0.1161 - val_acc: 0.9846
Epoch 99/200
 - 2s - loss: 0.0783 - acc: 0.9974 - val_loss: 0.1019 - val_acc: 0.9923
Epoch 100/200
 - 2s - loss: 0.0762 - acc: 0.9981 - val_loss: 0.1059 - val_acc: 0.9846
Epoch 101/200
 - 2s - loss: 0.0765 - acc: 0.9987 - val_loss: 0.1143 - val_acc: 0.9834
Epoch 102/200
 - 2s - loss: 0.0751 - acc: 0.9981 - val_loss: 0.1113 - val_acc: 0.9846
Epoch 103/200
 - 2s - loss: 0.0736 - acc: 0.9981 - val_loss: 0.1180 - val_acc: 0.9834
Epoch 104/200
 - 2s - loss: 0.0755 - acc: 0.9984 - val_loss: 0.1271 - val_acc: 0.9821
Epoch 105/200
 - 2s - loss: 0.0730 - acc: 0.9978 - val_loss: 0.1200 - val_acc: 0.9834
Epoch 106/200
 - 2s - loss: 0.0717 - acc: 0.9994 - val_loss: 0.1114 - val_acc: 0.9834
Epoch 107/200
 - 2s - loss: 0.0718 - acc: 0.9984 - val_loss: 0.1065 - val_acc: 0.9859
Epoch 108/200
 - 2s - loss: 0.0701 - acc: 0.9990 - val_loss: 0.1115 - val_acc: 0.9834
Epoch 109/200
 - 2s - loss: 0.0687 - acc: 0.9987 - val_loss: 0.1075 - val_acc: 0.9846
Restoring model weights from the end of the best epoch
Epoch 00109: early stopping
End-train DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Keras TF Training sfa_bottles_1: 3899/3905 99.8%
              precision    recall  f1-score   support

           B       0.99      0.95      0.97        96
           V       1.00      1.00      1.00      3809

    accuracy                           1.00      3905
   macro avg       0.99      0.97      0.98      3905
weighted avg       1.00      1.00      1.00      3905

Keras TF Testing sfa_bottles_1: 972/976 99.6%
              precision    recall  f1-score   support

           B       1.00      0.83      0.91        24
           V       1.00      1.00      1.00       952

    accuracy                           1.00       976
   macro avg       1.00      0.92      0.95       976
weighted avg       1.00      1.00      1.00       976

Keras TF CV sfa_bottles_1: 2484/2519 98.6%
              precision    recall  f1-score   support

           B       0.91      0.48      0.62        61
           V       0.99      1.00      0.99      2458

    accuracy                           0.99      2519
   macro avg       0.95      0.74      0.81      2519
weighted avg       0.99      0.99      0.98      2519

Keras TF stop snn_sfa_bottles_1
trnargs = {'batch_size':64,'max_iter':200,'lay':[('conv1d',16,64,2),('relu',),('batch',),('pool',8,8),('conv1d',32,32,2),('relu',),('batch',),('pool',8,8),('conv1d',64,16,8),('relu',),('batch',),('conv1d',128,8,2),('relu',),('batch',),('conv1d',256,4,2),('relu',),('batch',),('pool',4,4),('flatten',),('ip',64),('relu',),('dropout',0.25),('ip',32),('relu',),('dropout',0.25)],'base_lr':0.0005, 'optimizer':'adadelta','val_split':0.2,'monitor': 'val_loss','patience':15, 'stop': True}
Keras TF start  cnn_sig_bottles_1
Train DNN with Keras
Train on 3124 samples, validate on 781 samples
Epoch 1/200
 - 137s - loss: 0.3966 - acc: 0.9593 - val_loss: 0.3827 - val_acc: 0.9667
Epoch 2/200
 - 145s - loss: 0.3429 - acc: 0.9770 - val_loss: 0.3480 - val_acc: 0.9667
Epoch 3/200
 - 143s - loss: 0.3196 - acc: 0.9770 - val_loss: 0.4648 - val_acc: 0.9667
Epoch 4/200
 - 146s - loss: 0.3089 - acc: 0.9754 - val_loss: 0.4591 - val_acc: 0.9667
Epoch 5/200
 - 145s - loss: 0.2752 - acc: 0.9792 - val_loss: 0.4590 - val_acc: 0.9667
Epoch 6/200
 - 147s - loss: 0.2450 - acc: 0.9866 - val_loss: 0.4099 - val_acc: 0.9667
Epoch 7/200
 - 145s - loss: 0.2411 - acc: 0.9859 - val_loss: 0.3132 - val_acc: 0.9667
Epoch 8/200
 - 153s - loss: 0.2201 - acc: 0.9866 - val_loss: 0.3171 - val_acc: 0.9667
Epoch 9/200
 - 154s - loss: 0.1989 - acc: 0.9891 - val_loss: 0.4712 - val_acc: 0.9667
Epoch 10/200
 - 145s - loss: 0.2033 - acc: 0.9875 - val_loss: 0.4693 - val_acc: 0.9667
Epoch 11/200
 - 143s - loss: 0.1791 - acc: 0.9914 - val_loss: 0.4723 - val_acc: 0.9667
Epoch 12/200
 - 146s - loss: 0.1605 - acc: 0.9971 - val_loss: 0.3949 - val_acc: 0.9680
Epoch 13/200
 - 146s - loss: 0.1613 - acc: 0.9914 - val_loss: 0.2896 - val_acc: 0.9718
Epoch 14/200
 - 144s - loss: 0.1401 - acc: 0.9968 - val_loss: 0.1851 - val_acc: 0.9859
Epoch 15/200
 - 148s - loss: 0.1558 - acc: 0.9936 - val_loss: 0.2214 - val_acc: 0.9654
Epoch 16/200
 - 146s - loss: 0.1588 - acc: 0.9910 - val_loss: 0.1617 - val_acc: 0.9898
Epoch 17/200
 - 143s - loss: 0.1250 - acc: 0.9968 - val_loss: 0.1530 - val_acc: 0.9872
Epoch 18/200
 - 143s - loss: 0.1117 - acc: 0.9990 - val_loss: 0.1613 - val_acc: 0.9757
Epoch 19/200
 - 147s - loss: 0.1106 - acc: 0.9971 - val_loss: 0.9164 - val_acc: 0.7951
Epoch 20/200
 - 145s - loss: 0.0969 - acc: 1.0000 - val_loss: 0.1362 - val_acc: 0.9834
Epoch 21/200
 - 147s - loss: 0.0891 - acc: 1.0000 - val_loss: 0.1251 - val_acc: 0.9872
Epoch 22/200
 - 143s - loss: 0.1107 - acc: 0.9923 - val_loss: 0.5485 - val_acc: 0.9667
Epoch 23/200
 - 146s - loss: 0.1150 - acc: 0.9898 - val_loss: 0.2932 - val_acc: 0.9706
Epoch 24/200
 - 139s - loss: 0.0841 - acc: 0.9974 - val_loss: 0.2664 - val_acc: 0.9718
Epoch 25/200
 - 137s - loss: 0.0774 - acc: 0.9994 - val_loss: 0.1102 - val_acc: 0.9885
Epoch 26/200
 - 147s - loss: 0.0767 - acc: 0.9981 - val_loss: 0.2633 - val_acc: 0.9718
Epoch 27/200
 - 148s - loss: 0.0734 - acc: 0.9981 - val_loss: 0.0970 - val_acc: 0.9910
Epoch 28/200
 - 141s - loss: 0.0630 - acc: 1.0000 - val_loss: 0.0960 - val_acc: 0.9923
Epoch 29/200
 - 137s - loss: 0.0584 - acc: 1.0000 - val_loss: 0.0877 - val_acc: 0.9923
Epoch 30/200
 - 141s - loss: 0.0537 - acc: 1.0000 - val_loss: 0.0808 - val_acc: 0.9910
Epoch 31/200
 - 137s - loss: 0.0628 - acc: 0.9958 - val_loss: 0.1374 - val_acc: 0.9706
Epoch 32/200
 - 140s - loss: 0.0577 - acc: 0.9971 - val_loss: 0.0860 - val_acc: 0.9898
Epoch 33/200
 - 136s - loss: 0.0548 - acc: 0.9978 - val_loss: 0.0701 - val_acc: 0.9910
Epoch 34/200
 - 139s - loss: 0.0518 - acc: 0.9974 - val_loss: 0.0675 - val_acc: 0.9923
Epoch 35/200
 - 151s - loss: 0.0467 - acc: 0.9994 - val_loss: 0.1136 - val_acc: 0.9859
Epoch 36/200
 - 143s - loss: 0.0435 - acc: 0.9994 - val_loss: 0.0587 - val_acc: 0.9949
Epoch 37/200
 - 142s - loss: 0.0430 - acc: 0.9994 - val_loss: 0.0945 - val_acc: 0.9885
Epoch 38/200
 - 143s - loss: 0.0366 - acc: 1.0000 - val_loss: 0.0639 - val_acc: 0.9923
Epoch 39/200
 - 145s - loss: 0.0337 - acc: 1.0000 - val_loss: 0.0497 - val_acc: 0.9936
Epoch 40/200
 - 145s - loss: 0.0309 - acc: 1.0000 - val_loss: 0.0605 - val_acc: 0.9910
Epoch 41/200
 - 141s - loss: 0.0292 - acc: 0.9994 - val_loss: 0.7219 - val_acc: 0.8502
Epoch 42/200
 - 140s - loss: 0.0756 - acc: 0.9878 - val_loss: 0.0858 - val_acc: 0.9718
Epoch 43/200
 - 145s - loss: 0.0428 - acc: 0.9962 - val_loss: 0.1218 - val_acc: 0.9629
Epoch 44/200
 - 143s - loss: 0.0335 - acc: 0.9981 - val_loss: 0.0691 - val_acc: 0.9885
Epoch 45/200
 - 140s - loss: 0.0442 - acc: 0.9942 - val_loss: 0.0713 - val_acc: 0.9834
Epoch 46/200
 - 143s - loss: 0.0282 - acc: 0.9990 - val_loss: 0.0444 - val_acc: 0.9910
Epoch 47/200
 - 144s - loss: 0.0342 - acc: 0.9962 - val_loss: 0.2931 - val_acc: 0.9757
Epoch 48/200
 - 147s - loss: 0.0264 - acc: 0.9994 - val_loss: 0.0571 - val_acc: 0.9898
Epoch 49/200
 - 144s - loss: 0.0229 - acc: 1.0000 - val_loss: 0.0511 - val_acc: 0.9923
Epoch 50/200
 - 151s - loss: 0.0213 - acc: 1.0000 - val_loss: 0.0358 - val_acc: 0.9949
Epoch 51/200
 - 151s - loss: 0.0196 - acc: 1.0000 - val_loss: 0.0476 - val_acc: 0.9923
Epoch 52/200
 - 149s - loss: 0.0180 - acc: 1.0000 - val_loss: 0.0491 - val_acc: 0.9910
Epoch 53/200
 - 146s - loss: 0.0303 - acc: 0.9965 - val_loss: 3.3047 - val_acc: 0.0960
Epoch 54/200
 - 141s - loss: 0.0260 - acc: 0.9965 - val_loss: 0.7745 - val_acc: 0.7426
Epoch 55/200
 - 142s - loss: 0.0194 - acc: 0.9987 - val_loss: 0.1250 - val_acc: 0.9795
Epoch 56/200
 - 144s - loss: 0.0168 - acc: 1.0000 - val_loss: 0.0489 - val_acc: 0.9923
Epoch 57/200
 - 143s - loss: 0.0172 - acc: 0.9997 - val_loss: 0.1130 - val_acc: 0.9872
Epoch 58/200
 - 146s - loss: 0.0209 - acc: 0.9984 - val_loss: 0.0471 - val_acc: 0.9936
Epoch 59/200
 - 137s - loss: 0.0151 - acc: 1.0000 - val_loss: 0.0460 - val_acc: 0.9936
Epoch 60/200
 - 142s - loss: 0.0144 - acc: 1.0000 - val_loss: 0.2149 - val_acc: 0.9782
Epoch 61/200
 - 140s - loss: 0.0136 - acc: 1.0000 - val_loss: 0.0350 - val_acc: 0.9949
Epoch 62/200
 - 143s - loss: 0.0206 - acc: 0.9971 - val_loss: 0.3375 - val_acc: 0.9770
Epoch 63/200
 - 145s - loss: 0.0199 - acc: 0.9978 - val_loss: 0.0229 - val_acc: 0.9974
Epoch 64/200
 - 145s - loss: 0.0129 - acc: 1.0000 - val_loss: 0.0210 - val_acc: 0.9987
Epoch 65/200
 - 144s - loss: 0.0154 - acc: 0.9987 - val_loss: 0.0416 - val_acc: 0.9898
Epoch 66/200
 - 143s - loss: 0.0166 - acc: 0.9984 - val_loss: 0.0303 - val_acc: 0.9949
Epoch 67/200
 - 142s - loss: 0.0121 - acc: 1.0000 - val_loss: 0.0444 - val_acc: 0.9936
Epoch 68/200
 - 143s - loss: 0.0113 - acc: 1.0000 - val_loss: 0.0406 - val_acc: 0.9936
Epoch 69/200
 - 144s - loss: 0.0105 - acc: 1.0000 - val_loss: 0.0579 - val_acc: 0.9923
Epoch 70/200
 - 143s - loss: 0.0097 - acc: 1.0000 - val_loss: 0.0367 - val_acc: 0.9949
Epoch 71/200
 - 142s - loss: 0.0317 - acc: 0.9949 - val_loss: 0.0475 - val_acc: 0.9885
Epoch 72/200
 - 143s - loss: 0.0328 - acc: 0.9942 - val_loss: 0.0617 - val_acc: 0.9898
Epoch 73/200
 - 145s - loss: 0.0123 - acc: 0.9994 - val_loss: 0.1075 - val_acc: 0.9821
Epoch 74/200
 - 145s - loss: 0.0133 - acc: 0.9990 - val_loss: 0.0262 - val_acc: 0.9962
Epoch 75/200
 - 143s - loss: 0.0188 - acc: 0.9968 - val_loss: 0.0424 - val_acc: 0.9923
Epoch 76/200
 - 143s - loss: 0.0205 - acc: 0.9978 - val_loss: 0.0689 - val_acc: 0.9910
Epoch 77/200
 - 145s - loss: 0.0108 - acc: 1.0000 - val_loss: 0.0499 - val_acc: 0.9898
Epoch 78/200
 - 144s - loss: 0.0259 - acc: 0.9962 - val_loss: 0.1395 - val_acc: 0.9821
Epoch 79/200
 - 151s - loss: 0.0134 - acc: 0.9987 - val_loss: 0.0864 - val_acc: 0.9834
Restoring model weights from the end of the best epoch
Epoch 00079: early stopping
End-train DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Keras TF Training sig_bottles_1: 3904/3905 100.0%
              precision    recall  f1-score   support

           B       0.99      1.00      0.99        96
           V       1.00      1.00      1.00      3809

    accuracy                           1.00      3905
   macro avg       0.99      1.00      1.00      3905
weighted avg       1.00      1.00      1.00      3905

Keras TF Testing sig_bottles_1: 973/976 99.7%
              precision    recall  f1-score   support

           B       0.92      0.96      0.94        24
           V       1.00      1.00      1.00       952

    accuracy                           1.00       976
   macro avg       0.96      0.98      0.97       976
weighted avg       1.00      1.00      1.00       976

Keras TF CV sig_bottles_1: 2478/2519 98.4%
              precision    recall  f1-score   support

           B       0.69      0.61      0.64        61
           V       0.99      0.99      0.99      2458

    accuracy                           0.98      2519
   macro avg       0.84      0.80      0.82      2519
weighted avg       0.98      0.98      0.98      2519

Keras TF stop cnn_sig_bottles_1
trnargs = {'batch_size':32,'max_iter':200,'lay':[('conv2d',32,[5,5],[2,2]),('elu',),('batch',),('dropout',0.1),('pool',[2,2],[2,2]),('conv2d',32,[5,5],[2,2]),('elu',),('batch',),('dropout',0.1),('pool',[2,2],[2,2]),('flatten',),('ip',90),('relu',),('dropout',0.7)],'base_lr':0.0005, 'optimizer':'adadelta','val_split':0.2,'monitor': 'val_loss','patience':15, 'stop': True}
Keras TF start  cnn_pfa_bottles_1
Train DNN with Keras
Train on 3124 samples, validate on 781 samples
Epoch 1/200
 - 16s - loss: 0.2654 - acc: 0.9654 - val_loss: 0.2408 - val_acc: 0.9667
Epoch 2/200
 - 14s - loss: 0.2188 - acc: 0.9770 - val_loss: 0.2283 - val_acc: 0.9667
Epoch 3/200
 - 14s - loss: 0.1664 - acc: 0.9776 - val_loss: 0.1447 - val_acc: 0.9706
Epoch 4/200
 - 14s - loss: 0.1265 - acc: 0.9869 - val_loss: 0.1293 - val_acc: 0.9808
Epoch 5/200
 - 16s - loss: 0.0914 - acc: 0.9930 - val_loss: 0.1079 - val_acc: 0.9910
Epoch 6/200
 - 14s - loss: 0.0886 - acc: 0.9936 - val_loss: 0.0746 - val_acc: 0.9962
Epoch 7/200
 - 14s - loss: 0.0717 - acc: 0.9968 - val_loss: 0.0631 - val_acc: 0.9987
Epoch 8/200
 - 14s - loss: 0.0685 - acc: 0.9965 - val_loss: 0.0578 - val_acc: 0.9974
Epoch 9/200
 - 14s - loss: 0.0569 - acc: 0.9984 - val_loss: 0.0744 - val_acc: 0.9936
Epoch 10/200
 - 16s - loss: 0.0536 - acc: 0.9971 - val_loss: 0.0458 - val_acc: 0.9987
Epoch 11/200
 - 14s - loss: 0.0494 - acc: 0.9974 - val_loss: 0.0608 - val_acc: 0.9962
Epoch 12/200
 - 14s - loss: 0.0507 - acc: 0.9955 - val_loss: 0.0742 - val_acc: 0.9910
Epoch 13/200
 - 17s - loss: 0.0401 - acc: 0.9981 - val_loss: 0.0388 - val_acc: 0.9974
Epoch 14/200
 - 22s - loss: 0.0364 - acc: 0.9990 - val_loss: 0.0344 - val_acc: 0.9974
Epoch 15/200
 - 31s - loss: 0.0313 - acc: 0.9997 - val_loss: 0.0326 - val_acc: 0.9974
Epoch 16/200
 - 22s - loss: 0.0289 - acc: 0.9987 - val_loss: 0.0825 - val_acc: 0.9782
Epoch 17/200
 - 24s - loss: 0.0259 - acc: 0.9987 - val_loss: 0.0389 - val_acc: 0.9949
Epoch 18/200
 - 25s - loss: 0.0232 - acc: 0.9994 - val_loss: 0.0489 - val_acc: 0.9949
Epoch 19/200
 - 31s - loss: 0.0244 - acc: 0.9984 - val_loss: 0.0238 - val_acc: 0.9987
Epoch 20/200
 - 28s - loss: 0.0203 - acc: 0.9987 - val_loss: 0.0264 - val_acc: 0.9962
Epoch 21/200
 - 30s - loss: 0.0184 - acc: 0.9994 - val_loss: 0.0606 - val_acc: 0.9923
Epoch 22/200
 - 16s - loss: 0.0186 - acc: 0.9990 - val_loss: 0.0216 - val_acc: 0.9974
Epoch 23/200
 - 14s - loss: 0.0199 - acc: 0.9987 - val_loss: 0.0165 - val_acc: 1.0000
Epoch 24/200
 - 14s - loss: 0.0162 - acc: 0.9990 - val_loss: 0.0216 - val_acc: 0.9962
Epoch 25/200
 - 14s - loss: 0.0189 - acc: 0.9978 - val_loss: 0.0151 - val_acc: 0.9987
Epoch 26/200
 - 18s - loss: 0.0158 - acc: 0.9981 - val_loss: 0.0231 - val_acc: 0.9974
Epoch 27/200
 - 23s - loss: 0.0123 - acc: 0.9997 - val_loss: 0.0217 - val_acc: 0.9962
Epoch 28/200
 - 20s - loss: 0.0143 - acc: 0.9981 - val_loss: 0.0113 - val_acc: 1.0000
Epoch 29/200
 - 19s - loss: 0.0126 - acc: 0.9981 - val_loss: 0.0195 - val_acc: 0.9949
Epoch 30/200
 - 14s - loss: 0.0158 - acc: 0.9971 - val_loss: 0.0248 - val_acc: 0.9949
Epoch 31/200
 - 16s - loss: 0.0118 - acc: 0.9990 - val_loss: 0.0098 - val_acc: 1.0000
Epoch 32/200
 - 16s - loss: 0.0114 - acc: 0.9987 - val_loss: 0.0316 - val_acc: 0.9936
Epoch 33/200
 - 15s - loss: 0.0094 - acc: 0.9997 - val_loss: 0.0270 - val_acc: 0.9949
Epoch 34/200
 - 16s - loss: 0.0090 - acc: 0.9997 - val_loss: 0.0150 - val_acc: 0.9974
Epoch 35/200
 - 15s - loss: 0.0103 - acc: 0.9990 - val_loss: 0.0076 - val_acc: 1.0000
Epoch 36/200
 - 15s - loss: 0.0132 - acc: 0.9987 - val_loss: 0.0238 - val_acc: 0.9949
Epoch 37/200
 - 16s - loss: 0.0085 - acc: 0.9994 - val_loss: 0.0133 - val_acc: 0.9974
Epoch 38/200
 - 16s - loss: 0.0064 - acc: 1.0000 - val_loss: 0.0112 - val_acc: 0.9974
Epoch 39/200
 - 15s - loss: 0.0067 - acc: 0.9997 - val_loss: 0.0238 - val_acc: 0.9949
Epoch 40/200
 - 16s - loss: 0.0075 - acc: 0.9990 - val_loss: 0.0177 - val_acc: 0.9974
Epoch 41/200
 - 16s - loss: 0.0126 - acc: 0.9984 - val_loss: 0.0187 - val_acc: 0.9974
Epoch 42/200
 - 15s - loss: 0.0090 - acc: 0.9990 - val_loss: 0.0138 - val_acc: 0.9974
Epoch 43/200
 - 15s - loss: 0.0101 - acc: 0.9990 - val_loss: 0.0076 - val_acc: 1.0000
Epoch 44/200
 - 15s - loss: 0.0056 - acc: 1.0000 - val_loss: 0.0167 - val_acc: 0.9949
Epoch 45/200
 - 15s - loss: 0.0056 - acc: 0.9997 - val_loss: 0.0369 - val_acc: 0.9949
Epoch 46/200
 - 15s - loss: 0.0050 - acc: 1.0000 - val_loss: 0.0149 - val_acc: 0.9974
Epoch 47/200
 - 15s - loss: 0.0054 - acc: 0.9994 - val_loss: 0.0125 - val_acc: 0.9949
Epoch 48/200
 - 15s - loss: 0.0080 - acc: 0.9987 - val_loss: 0.0254 - val_acc: 0.9949
Epoch 49/200
 - 16s - loss: 0.0048 - acc: 1.0000 - val_loss: 0.0423 - val_acc: 0.9923
Epoch 50/200
 - 17s - loss: 0.0063 - acc: 0.9994 - val_loss: 0.0135 - val_acc: 0.9974
Restoring model weights from the end of the best epoch
Epoch 00050: early stopping
End-train DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Keras TF Training pfa_bottles_1: 3905/3905 100.0%
              precision    recall  f1-score   support

           B       1.00      1.00      1.00        96
           V       1.00      1.00      1.00      3809

    accuracy                           1.00      3905
   macro avg       1.00      1.00      1.00      3905
weighted avg       1.00      1.00      1.00      3905

Keras TF Testing pfa_bottles_1: 976/976 100.0%
              precision    recall  f1-score   support

           B       1.00      1.00      1.00        24
           V       1.00      1.00      1.00       952

    accuracy                           1.00       976
   macro avg       1.00      1.00      1.00       976
weighted avg       1.00      1.00      1.00       976

Keras TF CV pfa_bottles_1: 2510/2519 99.6%
              precision    recall  f1-score   support

           B       0.96      0.89      0.92        61
           V       1.00      1.00      1.00      2458

    accuracy                           1.00      2519
   macro avg       0.98      0.94      0.96      2519
weighted avg       1.00      1.00      1.00      2519

Keras TF stop cnn_pfa_bottles_1
trnargs = {'batch_size':32,'max_iter':200,'lay':[('conv2d',32,[5,5],[2,2]),('elu',),('batch',),('dropout',0.1),('pool',[2,2],[2,2]),('conv2d',32,[5,5],[2,2]),('elu',),('batch',),('dropout',0.1),('pool',[2,2],[2,2]),('flatten',),('ip',90),('relu',),('dropout',0.7)],'base_lr':0.0005, 'optimizer':'adadelta','val_split':0.2,'monitor': 'val_loss','patience':15, 'stop': True}
Keras TF start  cnn_sfa_bottles_1
Train DNN with Keras
Train on 3124 samples, validate on 781 samples
Epoch 1/200
 - 14s - loss: 0.2676 - acc: 0.9661 - val_loss: 0.2427 - val_acc: 0.9667
Epoch 2/200
 - 11s - loss: 0.1880 - acc: 0.9792 - val_loss: 0.2165 - val_acc: 0.9667
Epoch 3/200
 - 11s - loss: 0.1254 - acc: 0.9901 - val_loss: 0.1889 - val_acc: 0.9680
Epoch 4/200
 - 12s - loss: 0.0962 - acc: 0.9962 - val_loss: 0.1199 - val_acc: 0.9859
Epoch 5/200
 - 11s - loss: 0.0825 - acc: 0.9968 - val_loss: 0.0987 - val_acc: 0.9885
Epoch 6/200
 - 11s - loss: 0.0731 - acc: 0.9974 - val_loss: 0.0665 - val_acc: 0.9987
Epoch 7/200
 - 12s - loss: 0.0692 - acc: 0.9974 - val_loss: 0.0653 - val_acc: 0.9974
Epoch 8/200
 - 12s - loss: 0.0622 - acc: 0.9984 - val_loss: 0.0717 - val_acc: 0.9949
Epoch 9/200
 - 12s - loss: 0.0534 - acc: 0.9990 - val_loss: 0.0582 - val_acc: 0.9962
Epoch 10/200
 - 12s - loss: 0.0464 - acc: 0.9997 - val_loss: 0.0588 - val_acc: 0.9923
Epoch 11/200
 - 12s - loss: 0.0433 - acc: 0.9994 - val_loss: 0.0415 - val_acc: 0.9987
Epoch 12/200
 - 12s - loss: 0.0400 - acc: 0.9990 - val_loss: 0.0365 - val_acc: 0.9987
Epoch 13/200
 - 12s - loss: 0.0338 - acc: 0.9994 - val_loss: 0.0346 - val_acc: 0.9974
Epoch 14/200
 - 13s - loss: 0.0291 - acc: 1.0000 - val_loss: 0.0319 - val_acc: 0.9987
Epoch 15/200
 - 13s - loss: 0.0273 - acc: 0.9994 - val_loss: 0.0307 - val_acc: 0.9987
Epoch 16/200
 - 12s - loss: 0.0227 - acc: 1.0000 - val_loss: 0.0308 - val_acc: 0.9974
Epoch 17/200
 - 12s - loss: 0.0224 - acc: 0.9987 - val_loss: 0.0207 - val_acc: 0.9987
Epoch 18/200
 - 11s - loss: 0.0187 - acc: 0.9997 - val_loss: 0.0212 - val_acc: 0.9987
Epoch 19/200
 - 11s - loss: 0.0173 - acc: 0.9997 - val_loss: 0.0238 - val_acc: 0.9974
Epoch 20/200
 - 11s - loss: 0.0147 - acc: 1.0000 - val_loss: 0.0173 - val_acc: 0.9987
Epoch 21/200
 - 12s - loss: 0.0133 - acc: 0.9997 - val_loss: 0.0153 - val_acc: 0.9987
Epoch 22/200
 - 13s - loss: 0.0141 - acc: 0.9987 - val_loss: 0.0226 - val_acc: 0.9962
Epoch 23/200
 - 13s - loss: 0.0113 - acc: 1.0000 - val_loss: 0.0459 - val_acc: 0.9923
Epoch 24/200
 - 13s - loss: 0.0103 - acc: 0.9997 - val_loss: 0.0294 - val_acc: 0.9949
Epoch 25/200
 - 11s - loss: 0.0093 - acc: 0.9997 - val_loss: 0.0121 - val_acc: 0.9987
Epoch 26/200
 - 13s - loss: 0.0095 - acc: 0.9990 - val_loss: 0.0140 - val_acc: 0.9974
Epoch 27/200
 - 13s - loss: 0.0109 - acc: 0.9987 - val_loss: 0.0110 - val_acc: 0.9974
Epoch 28/200
 - 13s - loss: 0.0077 - acc: 1.0000 - val_loss: 0.0462 - val_acc: 0.9910
Epoch 29/200
 - 14s - loss: 0.0069 - acc: 1.0000 - val_loss: 0.0206 - val_acc: 0.9962
Epoch 30/200
 - 13s - loss: 0.0063 - acc: 1.0000 - val_loss: 0.0120 - val_acc: 0.9974
Epoch 31/200
 - 12s - loss: 0.0069 - acc: 0.9994 - val_loss: 0.0250 - val_acc: 0.9949
Epoch 32/200
 - 12s - loss: 0.0054 - acc: 1.0000 - val_loss: 0.0262 - val_acc: 0.9949
Epoch 33/200
 - 17s - loss: 0.0058 - acc: 0.9997 - val_loss: 0.0194 - val_acc: 0.9949
Epoch 34/200
 - 20s - loss: 0.0053 - acc: 1.0000 - val_loss: 0.0055 - val_acc: 1.0000
Epoch 35/200
 - 20s - loss: 0.0049 - acc: 0.9997 - val_loss: 0.0336 - val_acc: 0.9949
Epoch 36/200
 - 21s - loss: 0.0047 - acc: 0.9997 - val_loss: 0.0056 - val_acc: 0.9987
Epoch 37/200
 - 27s - loss: 0.0049 - acc: 0.9997 - val_loss: 0.0194 - val_acc: 0.9949
Epoch 38/200
 - 24s - loss: 0.0043 - acc: 0.9997 - val_loss: 0.0498 - val_acc: 0.9923
Epoch 39/200
 - 27s - loss: 0.0040 - acc: 0.9997 - val_loss: 0.0040 - val_acc: 1.0000
Epoch 40/200
 - 30s - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 0.9987
Epoch 41/200
 - 19s - loss: 0.0036 - acc: 0.9997 - val_loss: 0.0045 - val_acc: 1.0000
Epoch 42/200
 - 19s - loss: 0.0059 - acc: 0.9994 - val_loss: 0.0608 - val_acc: 0.9885
Epoch 43/200
 - 18s - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0042 - val_acc: 1.0000
Epoch 44/200
 - 18s - loss: 0.0044 - acc: 0.9990 - val_loss: 0.0051 - val_acc: 0.9987
Epoch 45/200
 - 16s - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0181 - val_acc: 0.9962
Epoch 46/200
 - 16s - loss: 0.0035 - acc: 0.9997 - val_loss: 0.0344 - val_acc: 0.9936
Epoch 47/200
 - 16s - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0069 - val_acc: 0.9987
Epoch 48/200
 - 13s - loss: 0.0031 - acc: 0.9994 - val_loss: 0.0047 - val_acc: 0.9974
Epoch 49/200
 - 11s - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0096 - val_acc: 0.9987
Epoch 50/200
 - 12s - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0242 - val_acc: 0.9949
Epoch 51/200
 - 11s - loss: 0.0052 - acc: 0.9990 - val_loss: 0.0091 - val_acc: 0.9987
Epoch 52/200
 - 12s - loss: 0.0026 - acc: 0.9997 - val_loss: 0.0074 - val_acc: 0.9974
Epoch 53/200
 - 11s - loss: 0.0038 - acc: 0.9994 - val_loss: 0.0119 - val_acc: 0.9962
Epoch 54/200
 - 11s - loss: 0.0026 - acc: 0.9997 - val_loss: 0.0107 - val_acc: 0.9962
Restoring model weights from the end of the best epoch
Epoch 00054: early stopping
End-train DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Keras TF Training sfa_bottles_1: 3905/3905 100.0%
              precision    recall  f1-score   support

           B       1.00      1.00      1.00        96
           V       1.00      1.00      1.00      3809

    accuracy                           1.00      3905
   macro avg       1.00      1.00      1.00      3905
weighted avg       1.00      1.00      1.00      3905

Keras TF Testing sfa_bottles_1: 976/976 100.0%
              precision    recall  f1-score   support

           B       1.00      1.00      1.00        24
           V       1.00      1.00      1.00       952

    accuracy                           1.00       976
   macro avg       1.00      1.00      1.00       976
weighted avg       1.00      1.00      1.00       976

Keras TF CV sfa_bottles_1: 2502/2519 99.3%
              precision    recall  f1-score   support

           B       0.85      0.87      0.86        61
           V       1.00      1.00      1.00      2458

    accuracy                           0.99      2519
   macro avg       0.93      0.93      0.93      2519
weighted avg       0.99      0.99      0.99      2519

Keras TF stop cnn_sfa_bottles_1
svm start  sig_bottles_1
SVM Training sig_bottles_1: 3900/3905 99.9%
              precision    recall  f1-score   support

           B       0.95      1.00      0.97        96
           V       1.00      1.00      1.00      3809

    accuracy                           1.00      3905
   macro avg       0.98      1.00      0.99      3905
weighted avg       1.00      1.00      1.00      3905

SVM Testing sig_bottles_1: 970/976 99.4%
              precision    recall  f1-score   support

           B       0.80      1.00      0.89        24
           V       1.00      0.99      1.00       952

    accuracy                           0.99       976
   macro avg       0.90      1.00      0.94       976
weighted avg       1.00      0.99      0.99       976

SVM CV sig_bottles_1: 2396/2519 95.1%
              precision    recall  f1-score   support

           B       0.08      0.10      0.09        61
           V       0.98      0.97      0.97      2458

    accuracy                           0.95      2519
   macro avg       0.53      0.54      0.53      2519
weighted avg       0.96      0.95      0.95      2519

svm finish sig_bottles_1
svm start  pfa_bottles_1
SVM Training pfa_bottles_1: 3905/3905 100.0%
              precision    recall  f1-score   support

           B       1.00      1.00      1.00        96
           V       1.00      1.00      1.00      3809

    accuracy                           1.00      3905
   macro avg       1.00      1.00      1.00      3905
weighted avg       1.00      1.00      1.00      3905

SVM Testing pfa_bottles_1: 976/976 100.0%
              precision    recall  f1-score   support

           B       1.00      1.00      1.00        24
           V       1.00      1.00      1.00       952

    accuracy                           1.00       976
   macro avg       1.00      1.00      1.00       976
weighted avg       1.00      1.00      1.00       976

SVM CV pfa_bottles_1: 2494/2519 99.0%
              precision    recall  f1-score   support

           B       0.97      0.61      0.75        61
           V       0.99      1.00      0.99      2458

    accuracy                           0.99      2519
   macro avg       0.98      0.80      0.87      2519
weighted avg       0.99      0.99      0.99      2519

svm finish pfa_bottles_1
svm start  sfa_bottles_1
SVM Training sfa_bottles_1: 3905/3905 100.0%
              precision    recall  f1-score   support

           B       1.00      1.00      1.00        96
           V       1.00      1.00      1.00      3809

    accuracy                           1.00      3905
   macro avg       1.00      1.00      1.00      3905
weighted avg       1.00      1.00      1.00      3905

SVM Testing sfa_bottles_1: 968/976 99.2%
              precision    recall  f1-score   support

           B       1.00      0.67      0.80        24
           V       0.99      1.00      1.00       952

    accuracy                           0.99       976
   macro avg       1.00      0.83      0.90       976
weighted avg       0.99      0.99      0.99       976

SVM CV sfa_bottles_1: 2463/2519 97.8%
              precision    recall  f1-score   support

           B       0.86      0.10      0.18        61
           V       0.98      1.00      0.99      2458

    accuracy                           0.98      2519
   macro avg       0.92      0.55      0.58      2519
weighted avg       0.98      0.98      0.97      2519

svm finish sfa_bottles_1
trnargs = {'states':1, 'its': [0]}
hmm start  pfa_bottles_1
spl 0
CMP: 969/976 99.3%
HMM Training pfa_bottles_1: 3861/3905 98.9%
              precision    recall  f1-score   support

           B       0.69      1.00      0.81        96
           V       1.00      0.99      0.99      3809

    accuracy                           0.99      3905
   macro avg       0.84      0.99      0.90      3905
weighted avg       0.99      0.99      0.99      3905

HMM Testing pfa_bottles_1: 969/976 99.3%
              precision    recall  f1-score   support

           B       0.77      1.00      0.87        24
           V       1.00      0.99      1.00       952

    accuracy                           0.99       976
   macro avg       0.89      1.00      0.93       976
weighted avg       0.99      0.99      0.99       976

HMM CV pfa_bottles_1: 2485/2519 98.7%
              precision    recall  f1-score   support

           B       0.69      0.80      0.74        61
           V       1.00      0.99      0.99      2458

    accuracy                           0.99      2519
   macro avg       0.84      0.90      0.87      2519
weighted avg       0.99      0.99      0.99      2519

hmm start  sfa_bottles_1
spl 0
CMP: 787/976 80.6%
spl 0 ite 1
CMP: 943/976 96.6%
spl 0 ite 2
CMP: 954/976 97.7%
spl 0 ite 3
CMP: 961/976 98.5%
spl 1
CMP: 960/976 98.4%
spl 1 ite 1
CMP: 969/976 99.3%
spl 1 ite 2
CMP: 969/976 99.3%
spl 1 ite 3
CMP: 969/976 99.3%
spl 1 ite 4
CMP: 971/976 99.5%
spl 1 ite 5
CMP: 972/976 99.6%
spl 2
CMP: 972/976 99.6%
spl 2 ite 1
CMP: 974/976 99.8%
spl 2 ite 2
CMP: 974/976 99.8%
spl 2 ite 3
CMP: 974/976 99.8%
spl 2 ite 4
CMP: 974/976 99.8%
spl 2 ite 5
CMP: 974/976 99.8%
spl 2 ite 6
CMP: 974/976 99.8%
spl 2 ite 7
CMP: 974/976 99.8%
spl 3
CMP: 974/976 99.8%
spl 3 ite 1
CMP: 975/976 99.9%
spl 3 ite 2
CMP: 975/976 99.9%
spl 3 ite 3
CMP: 975/976 99.9%
spl 3 ite 4
CMP: 975/976 99.9%
spl 3 ite 5
CMP: 975/976 99.9%
spl 3 ite 6
CMP: 975/976 99.9%
spl 3 ite 7
CMP: 975/976 99.9%
spl 3 ite 8
CMP: 975/976 99.9%
spl 3 ite 9
CMP: 975/976 99.9%
spl 4
CMP: 975/976 99.9%
spl 4 ite 1
CMP: 975/976 99.9%
spl 4 ite 2
CMP: 975/976 99.9%
spl 4 ite 3
CMP: 975/976 99.9%
spl 4 ite 4
CMP: 975/976 99.9%
spl 4 ite 5
CMP: 975/976 99.9%
spl 4 ite 6
CMP: 975/976 99.9%
spl 4 ite 7
CMP: 975/976 99.9%
spl 4 ite 8
CMP: 975/976 99.9%
spl 4 ite 9
CMP: 975/976 99.9%
spl 4 ite 10
CMP: 975/976 99.9%
spl 4 ite 11
CMP: 975/976 99.9%
spl 5
CMP: 975/976 99.9%
spl 5 ite 1
CMP: 976/976 100.0%
spl 5 ite 2
CMP: 976/976 100.0%
spl 5 ite 3
CMP: 976/976 100.0%
spl 5 ite 4
CMP: 976/976 100.0%
spl 5 ite 5
CMP: 976/976 100.0%
spl 5 ite 6
CMP: 976/976 100.0%
spl 5 ite 7
CMP: 976/976 100.0%
spl 5 ite 8
CMP: 976/976 100.0%
spl 5 ite 9
CMP: 976/976 100.0%
spl 5 ite 10
CMP: 976/976 100.0%
spl 5 ite 11
CMP: 976/976 100.0%
spl 5 ite 12
CMP: 975/976 99.9%
spl 5 ite 13
CMP: 975/976 99.9%
HMM Training sfa_bottles_1: 3905/3905 100.0%
              precision    recall  f1-score   support

           B       1.00      1.00      1.00        96
           V       1.00      1.00      1.00      3809

    accuracy                           1.00      3905
   macro avg       1.00      1.00      1.00      3905
weighted avg       1.00      1.00      1.00      3905

HMM Testing sfa_bottles_1: 975/976 99.9%
              precision    recall  f1-score   support

           B       1.00      0.96      0.98        24
           V       1.00      1.00      1.00       952

    accuracy                           1.00       976
   macro avg       1.00      0.98      0.99       976
weighted avg       1.00      1.00      1.00       976

HMM CV sfa_bottles_1: 2486/2519 98.7%
              precision    recall  f1-score   support

           B       1.00      0.46      0.63        61
           V       0.99      1.00      0.99      2458

    accuracy                           0.99      2519
   macro avg       0.99      0.73      0.81      2519
weighted avg       0.99      0.99      0.98      2519

flst [bottles]
load fdb /home/kraljiva/Projects/uasr-data/bottles/Versuch004_E/log/fdb
trnargs = {'batch_size':32,'max_iter':200,'lay':[('ip',256),('lrelu',),('batch',),('dropout',0.6), ('ip',128),('lrelu',),('batch',),('dropout',0.6)],'base_lr':0.0005,'optimizer':'adagrad','val_split':0.2,'monitor': 'val_loss','patience':10, 'stop': True}
Keras TF start  snn_sig_bottles_2
Train DNN with Keras
Train on 3124 samples, validate on 781 samples
Epoch 1/200
 - 28s - loss: 1.4398 - acc: 0.7497 - val_loss: 0.9563 - val_acc: 0.9654
Epoch 2/200
 - 25s - loss: 0.9458 - acc: 0.9017 - val_loss: 0.7210 - val_acc: 0.9654
Epoch 3/200
 - 25s - loss: 0.7285 - acc: 0.9385 - val_loss: 0.6269 - val_acc: 0.9654
Epoch 4/200
 - 24s - loss: 0.6081 - acc: 0.9542 - val_loss: 0.5742 - val_acc: 0.9654
Epoch 5/200
 - 24s - loss: 0.5452 - acc: 0.9603 - val_loss: 0.5191 - val_acc: 0.9654
Epoch 6/200
 - 24s - loss: 0.4802 - acc: 0.9645 - val_loss: 0.5259 - val_acc: 0.9654
Epoch 7/200
 - 24s - loss: 0.4359 - acc: 0.9673 - val_loss: 0.4468 - val_acc: 0.9654
Epoch 8/200
 - 24s - loss: 0.4100 - acc: 0.9677 - val_loss: 0.4172 - val_acc: 0.9654
Epoch 9/200
 - 24s - loss: 0.3787 - acc: 0.9677 - val_loss: 0.3983 - val_acc: 0.9654
Epoch 10/200
 - 25s - loss: 0.3651 - acc: 0.9690 - val_loss: 0.4219 - val_acc: 0.9693
Epoch 11/200
 - 24s - loss: 0.3411 - acc: 0.9722 - val_loss: 0.4071 - val_acc: 0.9654
Epoch 12/200
 - 24s - loss: 0.3240 - acc: 0.9734 - val_loss: 0.3955 - val_acc: 0.9654
Epoch 13/200
 - 24s - loss: 0.2991 - acc: 0.9786 - val_loss: 0.4064 - val_acc: 0.9654
Epoch 14/200
 - 24s - loss: 0.2899 - acc: 0.9776 - val_loss: 0.3485 - val_acc: 0.9654
Epoch 15/200
 - 24s - loss: 0.2806 - acc: 0.9773 - val_loss: 0.3374 - val_acc: 0.9667
Epoch 16/200
 - 24s - loss: 0.2721 - acc: 0.9792 - val_loss: 0.3034 - val_acc: 0.9667
Epoch 17/200
 - 22s - loss: 0.2669 - acc: 0.9782 - val_loss: 0.3151 - val_acc: 0.9654
Epoch 18/200
 - 22s - loss: 0.2560 - acc: 0.9779 - val_loss: 0.2857 - val_acc: 0.9680
Epoch 19/200
 - 22s - loss: 0.2420 - acc: 0.9850 - val_loss: 0.3186 - val_acc: 0.9667
Epoch 20/200
 - 22s - loss: 0.2392 - acc: 0.9834 - val_loss: 0.4052 - val_acc: 0.9667
Epoch 21/200
 - 24s - loss: 0.2316 - acc: 0.9850 - val_loss: 0.2703 - val_acc: 0.9667
Epoch 22/200
 - 23s - loss: 0.2221 - acc: 0.9866 - val_loss: 0.2653 - val_acc: 0.9680
Epoch 23/200
 - 24s - loss: 0.2312 - acc: 0.9821 - val_loss: 0.2704 - val_acc: 0.9680
Epoch 24/200
 - 24s - loss: 0.2098 - acc: 0.9869 - val_loss: 0.3558 - val_acc: 0.9667
Epoch 25/200
 - 24s - loss: 0.2135 - acc: 0.9834 - val_loss: 0.5828 - val_acc: 0.9667
Epoch 26/200
 - 24s - loss: 0.2024 - acc: 0.9846 - val_loss: 0.3935 - val_acc: 0.9667
Epoch 27/200
 - 24s - loss: 0.1944 - acc: 0.9869 - val_loss: 0.3055 - val_acc: 0.9667
Epoch 28/200
 - 24s - loss: 0.2045 - acc: 0.9846 - val_loss: 0.2971 - val_acc: 0.9667
Epoch 29/200
 - 23s - loss: 0.2033 - acc: 0.9808 - val_loss: 0.2815 - val_acc: 0.9590
Epoch 30/200
 - 24s - loss: 0.1989 - acc: 0.9846 - val_loss: 0.3943 - val_acc: 0.9142
Epoch 31/200
 - 23s - loss: 0.1901 - acc: 0.9885 - val_loss: 0.2739 - val_acc: 0.9667
Epoch 32/200
 - 24s - loss: 0.1923 - acc: 0.9866 - val_loss: 0.3388 - val_acc: 0.9667
Restoring model weights from the end of the best epoch
Epoch 00032: early stopping
End-train DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Keras TF Training sig_bottles_2: 3841/3905 98.4%
              precision    recall  f1-score   support

           B       0.97      0.34      0.51        96
           V       0.98      1.00      0.99      3809

    accuracy                           0.98      3905
   macro avg       0.98      0.67      0.75      3905
weighted avg       0.98      0.98      0.98      3905

Keras TF Testing sig_bottles_2: 952/976 97.5%
              precision    recall  f1-score   support

           B       0.50      0.04      0.08        24
           V       0.98      1.00      0.99       952

    accuracy                           0.98       976
   macro avg       0.74      0.52      0.53       976
weighted avg       0.96      0.98      0.97       976

Keras TF CV sig_bottles_2: 2456/2519 97.5%
              precision    recall  f1-score   support

           B       0.25      0.02      0.03        61
           V       0.98      1.00      0.99      2458

    accuracy                           0.97      2519
   macro avg       0.61      0.51      0.51      2519
weighted avg       0.96      0.97      0.96      2519

Keras TF stop snn_sig_bottles_2
trnargs = {'batch_size':32,'max_iter':200,'lay':[('ip',256),('lrelu',),('batch',),('dropout',0.7), ('ip',128),('lrelu',),('batch',),('dropout',0.7)],'base_lr':0.0005,'optimizer':'adagrad','val_split':0.2,'monitor': 'val_loss','patience':10, 'stop': True}
Keras TF start  snn_pfa_bottles_2
Train DNN with Keras
Train on 3124 samples, validate on 781 samples
Epoch 1/200
 - 7s - loss: 1.1070 - acc: 0.7266 - val_loss: 0.6242 - val_acc: 0.9667
Epoch 2/200
 - 4s - loss: 0.7132 - acc: 0.8796 - val_loss: 0.4842 - val_acc: 0.9667
Epoch 3/200
 - 4s - loss: 0.5666 - acc: 0.9289 - val_loss: 0.4450 - val_acc: 0.9667
Epoch 4/200
 - 4s - loss: 0.4793 - acc: 0.9472 - val_loss: 0.3925 - val_acc: 0.9667
Epoch 5/200
 - 4s - loss: 0.4165 - acc: 0.9574 - val_loss: 0.3633 - val_acc: 0.9667
Epoch 6/200
 - 4s - loss: 0.3717 - acc: 0.9635 - val_loss: 0.3257 - val_acc: 0.9667
Epoch 7/200
 - 4s - loss: 0.3294 - acc: 0.9744 - val_loss: 0.3147 - val_acc: 0.9667
Epoch 8/200
 - 4s - loss: 0.3135 - acc: 0.9725 - val_loss: 0.3316 - val_acc: 0.9667
Epoch 9/200
 - 4s - loss: 0.2879 - acc: 0.9770 - val_loss: 0.2511 - val_acc: 0.9782
Epoch 10/200
 - 4s - loss: 0.2705 - acc: 0.9782 - val_loss: 0.2949 - val_acc: 0.9667
Epoch 11/200
 - 4s - loss: 0.2500 - acc: 0.9834 - val_loss: 0.2416 - val_acc: 0.9693
Epoch 12/200
 - 4s - loss: 0.2435 - acc: 0.9821 - val_loss: 0.2235 - val_acc: 0.9834
Epoch 13/200
 - 4s - loss: 0.2321 - acc: 0.9837 - val_loss: 0.2436 - val_acc: 0.9693
Epoch 14/200
 - 4s - loss: 0.2200 - acc: 0.9827 - val_loss: 0.2199 - val_acc: 0.9731
Epoch 15/200
 - 4s - loss: 0.2113 - acc: 0.9853 - val_loss: 0.1944 - val_acc: 0.9859
Epoch 16/200
 - 4s - loss: 0.2007 - acc: 0.9888 - val_loss: 0.1972 - val_acc: 0.9821
Epoch 17/200
 - 4s - loss: 0.2006 - acc: 0.9850 - val_loss: 0.2079 - val_acc: 0.9731
Epoch 18/200
 - 4s - loss: 0.1835 - acc: 0.9888 - val_loss: 0.2391 - val_acc: 0.9680
Epoch 19/200
 - 4s - loss: 0.1848 - acc: 0.9875 - val_loss: 0.1996 - val_acc: 0.9782
Epoch 20/200
 - 4s - loss: 0.1862 - acc: 0.9882 - val_loss: 0.5755 - val_acc: 0.7734
Epoch 21/200
 - 4s - loss: 0.1769 - acc: 0.9904 - val_loss: 0.1649 - val_acc: 0.9898
Epoch 22/200
 - 4s - loss: 0.1729 - acc: 0.9882 - val_loss: 0.4028 - val_acc: 0.9155
Epoch 23/200
 - 4s - loss: 0.1631 - acc: 0.9917 - val_loss: 0.4170 - val_acc: 0.8873
Epoch 24/200
 - 4s - loss: 0.1615 - acc: 0.9901 - val_loss: 0.2007 - val_acc: 0.9706
Epoch 25/200
 - 4s - loss: 0.1543 - acc: 0.9923 - val_loss: 0.1581 - val_acc: 0.9846
Epoch 26/200
 - 4s - loss: 0.1497 - acc: 0.9920 - val_loss: 0.1444 - val_acc: 0.9962
Epoch 27/200
 - 4s - loss: 0.1492 - acc: 0.9923 - val_loss: 0.1825 - val_acc: 0.9731
Epoch 28/200
 - 4s - loss: 0.1437 - acc: 0.9923 - val_loss: 0.1376 - val_acc: 0.9962
Epoch 29/200
 - 4s - loss: 0.1477 - acc: 0.9914 - val_loss: 0.1343 - val_acc: 0.9949
Epoch 30/200
 - 4s - loss: 0.1376 - acc: 0.9942 - val_loss: 0.2071 - val_acc: 0.9706
Epoch 31/200
 - 4s - loss: 0.1400 - acc: 0.9901 - val_loss: 0.1531 - val_acc: 0.9846
Epoch 32/200
 - 4s - loss: 0.1425 - acc: 0.9920 - val_loss: 0.1550 - val_acc: 0.9834
Epoch 33/200
 - 4s - loss: 0.1377 - acc: 0.9926 - val_loss: 0.1735 - val_acc: 0.9744
Epoch 34/200
 - 4s - loss: 0.1318 - acc: 0.9936 - val_loss: 0.2421 - val_acc: 0.9680
Epoch 35/200
 - 4s - loss: 0.1315 - acc: 0.9936 - val_loss: 0.1614 - val_acc: 0.9795
Epoch 36/200
 - 4s - loss: 0.1290 - acc: 0.9949 - val_loss: 0.1277 - val_acc: 0.9936
Epoch 37/200
 - 4s - loss: 0.1283 - acc: 0.9939 - val_loss: 0.1323 - val_acc: 0.9885
Epoch 38/200
 - 4s - loss: 0.1228 - acc: 0.9955 - val_loss: 0.1202 - val_acc: 0.9949
Epoch 39/200
 - 4s - loss: 0.1163 - acc: 0.9965 - val_loss: 0.1230 - val_acc: 0.9923
Epoch 40/200
 - 4s - loss: 0.1214 - acc: 0.9933 - val_loss: 0.1227 - val_acc: 0.9987
Epoch 41/200
 - 4s - loss: 0.1142 - acc: 0.9971 - val_loss: 0.1141 - val_acc: 0.9974
Epoch 42/200
 - 4s - loss: 0.1168 - acc: 0.9958 - val_loss: 0.1280 - val_acc: 0.9859
Epoch 43/200
 - 4s - loss: 0.1132 - acc: 0.9949 - val_loss: 0.1312 - val_acc: 0.9846
Epoch 44/200
 - 4s - loss: 0.1101 - acc: 0.9952 - val_loss: 0.1848 - val_acc: 0.9795
Epoch 45/200
 - 4s - loss: 0.1129 - acc: 0.9939 - val_loss: 0.1946 - val_acc: 0.9770
Epoch 46/200
 - 4s - loss: 0.1069 - acc: 0.9974 - val_loss: 0.1292 - val_acc: 0.9846
Epoch 47/200
 - 4s - loss: 0.1056 - acc: 0.9958 - val_loss: 0.1585 - val_acc: 0.9770
Epoch 48/200
 - 4s - loss: 0.1076 - acc: 0.9958 - val_loss: 0.2019 - val_acc: 0.9693
Epoch 49/200
 - 4s - loss: 0.1113 - acc: 0.9933 - val_loss: 0.1473 - val_acc: 0.9782
Epoch 50/200
 - 4s - loss: 0.1032 - acc: 0.9962 - val_loss: 0.1009 - val_acc: 0.9974
Epoch 51/200
 - 4s - loss: 0.0997 - acc: 0.9971 - val_loss: 0.1173 - val_acc: 0.9910
Epoch 52/200
 - 4s - loss: 0.1012 - acc: 0.9962 - val_loss: 0.1156 - val_acc: 0.9872
Epoch 53/200
 - 4s - loss: 0.1008 - acc: 0.9958 - val_loss: 0.1837 - val_acc: 0.9718
Epoch 54/200
 - 4s - loss: 0.1022 - acc: 0.9955 - val_loss: 0.1036 - val_acc: 0.9923
Epoch 55/200
 - 4s - loss: 0.0983 - acc: 0.9965 - val_loss: 0.1022 - val_acc: 0.9936
Epoch 56/200
 - 4s - loss: 0.0968 - acc: 0.9965 - val_loss: 0.1363 - val_acc: 0.9808
Epoch 57/200
 - 4s - loss: 0.0945 - acc: 0.9968 - val_loss: 0.0985 - val_acc: 0.9974
Epoch 58/200
 - 4s - loss: 0.0935 - acc: 0.9978 - val_loss: 0.0948 - val_acc: 0.9987
Epoch 59/200
 - 4s - loss: 0.0942 - acc: 0.9958 - val_loss: 0.0917 - val_acc: 0.9974
Epoch 60/200
 - 4s - loss: 0.0958 - acc: 0.9958 - val_loss: 0.3756 - val_acc: 0.8707
Epoch 61/200
 - 4s - loss: 0.0928 - acc: 0.9965 - val_loss: 0.0940 - val_acc: 0.9962
Epoch 62/200
 - 4s - loss: 0.0936 - acc: 0.9965 - val_loss: 0.2218 - val_acc: 0.9680
Epoch 63/200
 - 4s - loss: 0.0913 - acc: 0.9968 - val_loss: 0.1153 - val_acc: 0.9885
Epoch 64/200
 - 4s - loss: 0.0904 - acc: 0.9971 - val_loss: 0.0916 - val_acc: 0.9962
Epoch 65/200
 - 4s - loss: 0.0905 - acc: 0.9971 - val_loss: 0.0912 - val_acc: 0.9949
Epoch 66/200
 - 4s - loss: 0.0902 - acc: 0.9965 - val_loss: 0.1373 - val_acc: 0.9808
Epoch 67/200
 - 4s - loss: 0.0891 - acc: 0.9968 - val_loss: 0.0877 - val_acc: 0.9974
Epoch 68/200
 - 4s - loss: 0.0889 - acc: 0.9965 - val_loss: 0.0876 - val_acc: 0.9974
Epoch 69/200
 - 4s - loss: 0.0840 - acc: 0.9984 - val_loss: 0.0878 - val_acc: 0.9987
Epoch 70/200
 - 4s - loss: 0.0887 - acc: 0.9962 - val_loss: 0.1414 - val_acc: 0.9885
Epoch 71/200
 - 4s - loss: 0.0885 - acc: 0.9958 - val_loss: 0.0839 - val_acc: 0.9974
Epoch 72/200
 - 4s - loss: 0.0910 - acc: 0.9946 - val_loss: 0.1280 - val_acc: 0.9923
Epoch 73/200
 - 4s - loss: 0.0908 - acc: 0.9958 - val_loss: 0.0987 - val_acc: 0.9910
Epoch 74/200
 - 4s - loss: 0.0863 - acc: 0.9962 - val_loss: 0.1085 - val_acc: 0.9885
Epoch 75/200
 - 4s - loss: 0.0876 - acc: 0.9968 - val_loss: 0.0898 - val_acc: 0.9949
Epoch 76/200
 - 4s - loss: 0.0837 - acc: 0.9981 - val_loss: 0.1117 - val_acc: 0.9872
Epoch 77/200
 - 4s - loss: 0.0839 - acc: 0.9968 - val_loss: 0.0921 - val_acc: 0.9962
Epoch 78/200
 - 4s - loss: 0.0848 - acc: 0.9974 - val_loss: 0.0883 - val_acc: 0.9949
Epoch 79/200
 - 4s - loss: 0.0847 - acc: 0.9958 - val_loss: 0.0802 - val_acc: 0.9987
Epoch 80/200
 - 4s - loss: 0.0840 - acc: 0.9974 - val_loss: 0.0825 - val_acc: 0.9974
Epoch 81/200
 - 4s - loss: 0.0822 - acc: 0.9981 - val_loss: 0.0953 - val_acc: 0.9936
Epoch 82/200
 - 4s - loss: 0.0820 - acc: 0.9974 - val_loss: 0.0871 - val_acc: 0.9949
Epoch 83/200
 - 4s - loss: 0.0802 - acc: 0.9987 - val_loss: 0.1080 - val_acc: 0.9859
Epoch 84/200
 - 4s - loss: 0.0812 - acc: 0.9971 - val_loss: 0.0934 - val_acc: 0.9923
Epoch 85/200
 - 4s - loss: 0.0831 - acc: 0.9955 - val_loss: 0.4379 - val_acc: 0.8143
Epoch 86/200
 - 4s - loss: 0.0777 - acc: 0.9984 - val_loss: 0.0833 - val_acc: 0.9962
Epoch 87/200
 - 4s - loss: 0.0764 - acc: 0.9984 - val_loss: 0.0832 - val_acc: 0.9949
Epoch 88/200
 - 4s - loss: 0.0750 - acc: 0.9981 - val_loss: 0.0796 - val_acc: 0.9974
Epoch 89/200
 - 4s - loss: 0.0765 - acc: 0.9981 - val_loss: 0.0749 - val_acc: 0.9974
Epoch 90/200
 - 4s - loss: 0.0727 - acc: 0.9994 - val_loss: 0.0898 - val_acc: 0.9923
Epoch 91/200
 - 4s - loss: 0.0718 - acc: 0.9990 - val_loss: 0.0902 - val_acc: 0.9910
Epoch 92/200
 - 4s - loss: 0.0736 - acc: 0.9974 - val_loss: 0.1217 - val_acc: 0.9821
Epoch 93/200
 - 4s - loss: 0.0720 - acc: 0.9978 - val_loss: 0.0732 - val_acc: 0.9974
Epoch 94/200
 - 4s - loss: 0.0743 - acc: 0.9974 - val_loss: 0.2035 - val_acc: 0.9565
Epoch 95/200
 - 4s - loss: 0.0744 - acc: 0.9978 - val_loss: 0.0850 - val_acc: 0.9936
Epoch 96/200
 - 4s - loss: 0.0720 - acc: 0.9974 - val_loss: 0.0768 - val_acc: 0.9949
Epoch 97/200
 - 4s - loss: 0.0739 - acc: 0.9962 - val_loss: 0.0811 - val_acc: 0.9962
Epoch 98/200
 - 4s - loss: 0.0722 - acc: 0.9981 - val_loss: 0.0989 - val_acc: 0.9898
Epoch 99/200
 - 4s - loss: 0.0730 - acc: 0.9971 - val_loss: 0.1995 - val_acc: 0.9641
Epoch 100/200
 - 4s - loss: 0.0716 - acc: 0.9981 - val_loss: 0.0960 - val_acc: 0.9872
Epoch 101/200
 - 4s - loss: 0.0705 - acc: 0.9978 - val_loss: 0.1211 - val_acc: 0.9808
Epoch 102/200
 - 4s - loss: 0.0756 - acc: 0.9962 - val_loss: 0.1529 - val_acc: 0.9770
Epoch 103/200
 - 4s - loss: 0.0741 - acc: 0.9965 - val_loss: 0.0722 - val_acc: 0.9974
Epoch 104/200
 - 4s - loss: 0.0721 - acc: 0.9974 - val_loss: 2.2130 - val_acc: 0.2471
Epoch 105/200
 - 4s - loss: 0.0697 - acc: 0.9987 - val_loss: 0.0753 - val_acc: 0.9974
Epoch 106/200
 - 4s - loss: 0.0678 - acc: 0.9984 - val_loss: 0.1075 - val_acc: 0.9872
Epoch 107/200
 - 4s - loss: 0.0665 - acc: 0.9987 - val_loss: 0.0671 - val_acc: 0.9974
Epoch 108/200
 - 4s - loss: 0.0694 - acc: 0.9962 - val_loss: 0.0757 - val_acc: 0.9987
Epoch 109/200
 - 4s - loss: 0.0696 - acc: 0.9965 - val_loss: 0.0751 - val_acc: 0.9974
Epoch 110/200
 - 4s - loss: 0.0715 - acc: 0.9971 - val_loss: 0.0801 - val_acc: 0.9974
Epoch 111/200
 - 4s - loss: 0.0677 - acc: 0.9978 - val_loss: 0.1115 - val_acc: 0.9834
Epoch 112/200
 - 4s - loss: 0.0652 - acc: 0.9984 - val_loss: 0.0987 - val_acc: 0.9885
Epoch 113/200
 - 4s - loss: 0.0668 - acc: 0.9981 - val_loss: 0.1462 - val_acc: 0.9757
Epoch 114/200
 - 4s - loss: 0.0689 - acc: 0.9965 - val_loss: 0.1433 - val_acc: 0.9770
Epoch 115/200
 - 4s - loss: 0.0639 - acc: 0.9994 - val_loss: 0.1112 - val_acc: 0.9821
Epoch 116/200
 - 4s - loss: 0.0647 - acc: 0.9968 - val_loss: 0.1270 - val_acc: 0.9795
Epoch 117/200
 - 4s - loss: 0.0631 - acc: 0.9978 - val_loss: 0.0655 - val_acc: 0.9974
Epoch 118/200
 - 4s - loss: 0.0615 - acc: 0.9990 - val_loss: 0.0814 - val_acc: 0.9923
Epoch 119/200
 - 4s - loss: 0.0638 - acc: 0.9978 - val_loss: 0.0693 - val_acc: 0.9987
Epoch 120/200
 - 4s - loss: 0.0610 - acc: 0.9997 - val_loss: 0.0872 - val_acc: 0.9885
Epoch 121/200
 - 4s - loss: 0.0652 - acc: 0.9962 - val_loss: 0.0712 - val_acc: 0.9949
Epoch 122/200
 - 4s - loss: 0.0650 - acc: 0.9974 - val_loss: 0.0848 - val_acc: 0.9910
Epoch 123/200
 - 4s - loss: 0.0684 - acc: 0.9962 - val_loss: 0.0734 - val_acc: 0.9974
Epoch 124/200
 - 4s - loss: 0.0655 - acc: 0.9971 - val_loss: 0.0731 - val_acc: 0.9962
Epoch 125/200
 - 4s - loss: 0.0620 - acc: 0.9984 - val_loss: 0.0745 - val_acc: 0.9936
Epoch 126/200
 - 4s - loss: 0.0626 - acc: 0.9978 - val_loss: 0.0732 - val_acc: 0.9936
Epoch 127/200
 - 4s - loss: 0.0605 - acc: 0.9994 - val_loss: 0.0723 - val_acc: 0.9974
Restoring model weights from the end of the best epoch
Epoch 00127: early stopping
End-train DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Keras TF Training pfa_bottles_2: 3903/3905 99.9%
              precision    recall  f1-score   support

           B       1.00      0.98      0.99        96
           V       1.00      1.00      1.00      3809

    accuracy                           1.00      3905
   macro avg       1.00      0.99      0.99      3905
weighted avg       1.00      1.00      1.00      3905

Keras TF Testing pfa_bottles_2: 974/976 99.8%
              precision    recall  f1-score   support

           B       1.00      0.92      0.96        24
           V       1.00      1.00      1.00       952

    accuracy                           1.00       976
   macro avg       1.00      0.96      0.98       976
weighted avg       1.00      1.00      1.00       976

Keras TF CV pfa_bottles_2: 2507/2519 99.5%
              precision    recall  f1-score   support

           B       1.00      0.80      0.89        61
           V       1.00      1.00      1.00      2458

    accuracy                           1.00      2519
   macro avg       1.00      0.90      0.94      2519
weighted avg       1.00      1.00      0.99      2519

Keras TF stop snn_pfa_bottles_2
trnargs = {'batch_size':32,'max_iter':200,'lay':[('ip',128),('lrelu',),('batch',),('dropout',0.7), ('ip',64),('lrelu',),('batch',),('dropout',0.7)],'base_lr':0.0005,'optimizer':'adagrad','val_split':0.2,'monitor': 'val_loss','patience':10, 'stop': True}
Keras TF start  snn_sfa_bottles_2
Train DNN with Keras
Train on 3124 samples, validate on 781 samples
Epoch 1/200
 - 4s - loss: 1.0774 - acc: 0.6408 - val_loss: 0.7360 - val_acc: 0.9014
Epoch 2/200
 - 2s - loss: 0.7526 - acc: 0.8019 - val_loss: 0.5140 - val_acc: 0.9654
Epoch 3/200
 - 2s - loss: 0.6336 - acc: 0.8611 - val_loss: 0.4649 - val_acc: 0.9667
Epoch 4/200
 - 2s - loss: 0.5593 - acc: 0.9043 - val_loss: 0.4233 - val_acc: 0.9667
Epoch 5/200
 - 2s - loss: 0.5032 - acc: 0.9264 - val_loss: 0.3975 - val_acc: 0.9667
Epoch 6/200
 - 2s - loss: 0.4711 - acc: 0.9363 - val_loss: 0.3813 - val_acc: 0.9667
Epoch 7/200
 - 2s - loss: 0.4339 - acc: 0.9491 - val_loss: 0.3692 - val_acc: 0.9667
Epoch 8/200
 - 2s - loss: 0.4037 - acc: 0.9593 - val_loss: 0.3542 - val_acc: 0.9667
Epoch 9/200
 - 2s - loss: 0.3863 - acc: 0.9641 - val_loss: 0.3422 - val_acc: 0.9667
Epoch 10/200
 - 2s - loss: 0.3744 - acc: 0.9638 - val_loss: 0.3290 - val_acc: 0.9680
Epoch 11/200
 - 2s - loss: 0.3592 - acc: 0.9661 - val_loss: 0.3225 - val_acc: 0.9680
Epoch 12/200
 - 2s - loss: 0.3384 - acc: 0.9706 - val_loss: 0.3146 - val_acc: 0.9693
Epoch 13/200
 - 2s - loss: 0.3214 - acc: 0.9760 - val_loss: 0.3044 - val_acc: 0.9693
Epoch 14/200
 - 2s - loss: 0.3218 - acc: 0.9744 - val_loss: 0.2867 - val_acc: 0.9782
Epoch 15/200
 - 2s - loss: 0.3069 - acc: 0.9786 - val_loss: 0.2829 - val_acc: 0.9782
Epoch 16/200
 - 2s - loss: 0.3013 - acc: 0.9776 - val_loss: 0.2723 - val_acc: 0.9795
Epoch 17/200
 - 2s - loss: 0.2794 - acc: 0.9850 - val_loss: 0.2775 - val_acc: 0.9731
Epoch 18/200
 - 2s - loss: 0.2798 - acc: 0.9821 - val_loss: 0.2665 - val_acc: 0.9770
Epoch 19/200
 - 2s - loss: 0.2701 - acc: 0.9830 - val_loss: 0.2634 - val_acc: 0.9757
Epoch 20/200
 - 2s - loss: 0.2636 - acc: 0.9834 - val_loss: 0.2478 - val_acc: 0.9821
Epoch 21/200
 - 2s - loss: 0.2555 - acc: 0.9853 - val_loss: 0.2506 - val_acc: 0.9782
Epoch 22/200
 - 2s - loss: 0.2418 - acc: 0.9885 - val_loss: 0.2528 - val_acc: 0.9757
Epoch 23/200
 - 2s - loss: 0.2390 - acc: 0.9882 - val_loss: 0.2446 - val_acc: 0.9770
Epoch 24/200
 - 2s - loss: 0.2363 - acc: 0.9891 - val_loss: 0.2352 - val_acc: 0.9808
Epoch 25/200
 - 2s - loss: 0.2309 - acc: 0.9878 - val_loss: 0.2266 - val_acc: 0.9846
Epoch 26/200
 - 2s - loss: 0.2260 - acc: 0.9882 - val_loss: 0.2256 - val_acc: 0.9834
Epoch 27/200
 - 2s - loss: 0.2219 - acc: 0.9917 - val_loss: 0.2202 - val_acc: 0.9846
Epoch 28/200
 - 2s - loss: 0.2109 - acc: 0.9920 - val_loss: 0.2156 - val_acc: 0.9846
Epoch 29/200
 - 2s - loss: 0.2057 - acc: 0.9939 - val_loss: 0.2083 - val_acc: 0.9859
Epoch 30/200
 - 2s - loss: 0.2049 - acc: 0.9891 - val_loss: 0.2168 - val_acc: 0.9795
Epoch 31/200
 - 2s - loss: 0.2007 - acc: 0.9930 - val_loss: 0.2118 - val_acc: 0.9821
Epoch 32/200
 - 2s - loss: 0.1950 - acc: 0.9939 - val_loss: 0.2090 - val_acc: 0.9834
Epoch 33/200
 - 2s - loss: 0.1912 - acc: 0.9933 - val_loss: 0.2070 - val_acc: 0.9821
Epoch 34/200
 - 2s - loss: 0.1921 - acc: 0.9920 - val_loss: 0.2033 - val_acc: 0.9821
Epoch 35/200
 - 2s - loss: 0.1848 - acc: 0.9942 - val_loss: 0.1921 - val_acc: 0.9885
Epoch 36/200
 - 2s - loss: 0.1800 - acc: 0.9942 - val_loss: 0.1917 - val_acc: 0.9859
Epoch 37/200
 - 2s - loss: 0.1854 - acc: 0.9917 - val_loss: 0.1909 - val_acc: 0.9834
Epoch 38/200
 - 2s - loss: 0.1759 - acc: 0.9939 - val_loss: 0.1852 - val_acc: 0.9846
Epoch 39/200
 - 2s - loss: 0.1703 - acc: 0.9949 - val_loss: 0.1811 - val_acc: 0.9872
Epoch 40/200
 - 2s - loss: 0.1746 - acc: 0.9914 - val_loss: 0.1782 - val_acc: 0.9872
Epoch 41/200
 - 2s - loss: 0.1655 - acc: 0.9955 - val_loss: 0.1723 - val_acc: 0.9898
Epoch 42/200
 - 2s - loss: 0.1632 - acc: 0.9952 - val_loss: 0.1721 - val_acc: 0.9872
Epoch 43/200
 - 2s - loss: 0.1585 - acc: 0.9952 - val_loss: 0.1739 - val_acc: 0.9872
Epoch 44/200
 - 2s - loss: 0.1581 - acc: 0.9939 - val_loss: 0.1686 - val_acc: 0.9885
Epoch 45/200
 - 2s - loss: 0.1536 - acc: 0.9946 - val_loss: 0.1679 - val_acc: 0.9872
Epoch 46/200
 - 2s - loss: 0.1534 - acc: 0.9946 - val_loss: 0.1684 - val_acc: 0.9846
Epoch 47/200
 - 2s - loss: 0.1524 - acc: 0.9936 - val_loss: 0.1649 - val_acc: 0.9885
Epoch 48/200
 - 2s - loss: 0.1458 - acc: 0.9965 - val_loss: 0.1641 - val_acc: 0.9885
Epoch 49/200
 - 2s - loss: 0.1477 - acc: 0.9958 - val_loss: 0.1538 - val_acc: 0.9910
Epoch 50/200
 - 2s - loss: 0.1420 - acc: 0.9958 - val_loss: 0.1581 - val_acc: 0.9872
Epoch 51/200
 - 2s - loss: 0.1416 - acc: 0.9949 - val_loss: 0.1602 - val_acc: 0.9859
Epoch 52/200
 - 2s - loss: 0.1349 - acc: 0.9971 - val_loss: 0.1590 - val_acc: 0.9859
Epoch 53/200
 - 2s - loss: 0.1368 - acc: 0.9971 - val_loss: 0.1515 - val_acc: 0.9872
Epoch 54/200
 - 2s - loss: 0.1357 - acc: 0.9965 - val_loss: 0.1490 - val_acc: 0.9885
Epoch 55/200
 - 2s - loss: 0.1325 - acc: 0.9958 - val_loss: 0.1526 - val_acc: 0.9872
Epoch 56/200
 - 2s - loss: 0.1344 - acc: 0.9946 - val_loss: 0.1444 - val_acc: 0.9885
Epoch 57/200
 - 2s - loss: 0.1317 - acc: 0.9962 - val_loss: 0.1451 - val_acc: 0.9872
Epoch 58/200
 - 2s - loss: 0.1297 - acc: 0.9949 - val_loss: 0.1434 - val_acc: 0.9885
Epoch 59/200
 - 2s - loss: 0.1246 - acc: 0.9974 - val_loss: 0.1427 - val_acc: 0.9885
Epoch 60/200
 - 2s - loss: 0.1289 - acc: 0.9952 - val_loss: 0.1402 - val_acc: 0.9872
Epoch 61/200
 - 2s - loss: 0.1223 - acc: 0.9974 - val_loss: 0.1372 - val_acc: 0.9885
Epoch 62/200
 - 2s - loss: 0.1222 - acc: 0.9965 - val_loss: 0.1358 - val_acc: 0.9898
Epoch 63/200
 - 2s - loss: 0.1195 - acc: 0.9978 - val_loss: 0.1328 - val_acc: 0.9910
Epoch 64/200
 - 2s - loss: 0.1173 - acc: 0.9974 - val_loss: 0.1316 - val_acc: 0.9910
Epoch 65/200
 - 2s - loss: 0.1142 - acc: 0.9974 - val_loss: 0.1265 - val_acc: 0.9910
Epoch 66/200
 - 2s - loss: 0.1162 - acc: 0.9971 - val_loss: 0.1260 - val_acc: 0.9910
Epoch 67/200
 - 2s - loss: 0.1111 - acc: 0.9981 - val_loss: 0.1261 - val_acc: 0.9910
Epoch 68/200
 - 2s - loss: 0.1118 - acc: 0.9971 - val_loss: 0.1285 - val_acc: 0.9885
Epoch 69/200
 - 2s - loss: 0.1149 - acc: 0.9955 - val_loss: 0.1288 - val_acc: 0.9859
Epoch 70/200
 - 2s - loss: 0.1095 - acc: 0.9958 - val_loss: 0.1276 - val_acc: 0.9859
Epoch 71/200
 - 2s - loss: 0.1080 - acc: 0.9978 - val_loss: 0.1182 - val_acc: 0.9923
Epoch 72/200
 - 2s - loss: 0.1056 - acc: 0.9978 - val_loss: 0.1172 - val_acc: 0.9910
Epoch 73/200
 - 2s - loss: 0.1104 - acc: 0.9968 - val_loss: 0.1173 - val_acc: 0.9910
Epoch 74/200
 - 2s - loss: 0.1041 - acc: 0.9971 - val_loss: 0.1221 - val_acc: 0.9898
Epoch 75/200
 - 2s - loss: 0.1010 - acc: 0.9978 - val_loss: 0.1246 - val_acc: 0.9859
Epoch 76/200
 - 2s - loss: 0.0999 - acc: 0.9978 - val_loss: 0.1222 - val_acc: 0.9872
Epoch 77/200
 - 2s - loss: 0.1005 - acc: 0.9974 - val_loss: 0.1144 - val_acc: 0.9910
Epoch 78/200
 - 2s - loss: 0.1005 - acc: 0.9974 - val_loss: 0.1124 - val_acc: 0.9910
Epoch 79/200
 - 2s - loss: 0.0967 - acc: 0.9984 - val_loss: 0.1136 - val_acc: 0.9910
Epoch 80/200
 - 2s - loss: 0.0960 - acc: 0.9984 - val_loss: 0.1203 - val_acc: 0.9872
Epoch 81/200
 - 2s - loss: 0.0969 - acc: 0.9978 - val_loss: 0.1242 - val_acc: 0.9846
Epoch 82/200
 - 2s - loss: 0.0924 - acc: 0.9990 - val_loss: 0.1181 - val_acc: 0.9872
Epoch 83/200
 - 2s - loss: 0.0926 - acc: 0.9981 - val_loss: 0.1168 - val_acc: 0.9885
Epoch 84/200
 - 2s - loss: 0.0903 - acc: 0.9987 - val_loss: 0.1156 - val_acc: 0.9872
Epoch 85/200
 - 2s - loss: 0.0906 - acc: 0.9990 - val_loss: 0.1094 - val_acc: 0.9898
Epoch 86/200
 - 2s - loss: 0.0896 - acc: 0.9981 - val_loss: 0.1161 - val_acc: 0.9885
Epoch 87/200
 - 2s - loss: 0.0877 - acc: 0.9987 - val_loss: 0.1130 - val_acc: 0.9885
Epoch 88/200
 - 2s - loss: 0.0857 - acc: 0.9987 - val_loss: 0.1106 - val_acc: 0.9885
Epoch 89/200
 - 2s - loss: 0.0859 - acc: 0.9978 - val_loss: 0.1069 - val_acc: 0.9898
Epoch 90/200
 - 2s - loss: 0.0875 - acc: 0.9981 - val_loss: 0.1069 - val_acc: 0.9898
Epoch 91/200
 - 2s - loss: 0.0852 - acc: 0.9981 - val_loss: 0.1057 - val_acc: 0.9910
Epoch 92/200
 - 2s - loss: 0.0849 - acc: 0.9984 - val_loss: 0.1057 - val_acc: 0.9910
Epoch 93/200
 - 2s - loss: 0.0843 - acc: 0.9978 - val_loss: 0.1066 - val_acc: 0.9898
Epoch 94/200
 - 2s - loss: 0.0816 - acc: 0.9978 - val_loss: 0.1055 - val_acc: 0.9910
Epoch 95/200
 - 2s - loss: 0.0817 - acc: 0.9987 - val_loss: 0.1062 - val_acc: 0.9885
Epoch 96/200
 - 2s - loss: 0.0794 - acc: 0.9997 - val_loss: 0.1048 - val_acc: 0.9898
Epoch 97/200
 - 2s - loss: 0.0801 - acc: 0.9981 - val_loss: 0.0991 - val_acc: 0.9910
Epoch 98/200
 - 2s - loss: 0.0784 - acc: 0.9994 - val_loss: 0.1028 - val_acc: 0.9910
Epoch 99/200
 - 2s - loss: 0.0779 - acc: 0.9987 - val_loss: 0.1068 - val_acc: 0.9885
Epoch 100/200
 - 2s - loss: 0.0767 - acc: 0.9981 - val_loss: 0.1026 - val_acc: 0.9910
Epoch 101/200
 - 2s - loss: 0.0749 - acc: 0.9990 - val_loss: 0.0980 - val_acc: 0.9910
Epoch 102/200
 - 2s - loss: 0.0763 - acc: 0.9981 - val_loss: 0.0973 - val_acc: 0.9910
Epoch 103/200
 - 2s - loss: 0.0757 - acc: 0.9984 - val_loss: 0.0914 - val_acc: 0.9910
Epoch 104/200
 - 2s - loss: 0.0745 - acc: 0.9987 - val_loss: 0.0923 - val_acc: 0.9910
Epoch 105/200
 - 2s - loss: 0.0726 - acc: 0.9994 - val_loss: 0.0951 - val_acc: 0.9910
Epoch 106/200
 - 2s - loss: 0.0716 - acc: 0.9994 - val_loss: 0.0979 - val_acc: 0.9885
Epoch 107/200
 - 2s - loss: 0.0733 - acc: 0.9978 - val_loss: 0.0968 - val_acc: 0.9885
Epoch 108/200
 - 2s - loss: 0.0738 - acc: 0.9971 - val_loss: 0.1001 - val_acc: 0.9872
Epoch 109/200
 - 2s - loss: 0.0710 - acc: 0.9984 - val_loss: 0.0950 - val_acc: 0.9898
Epoch 110/200
 - 2s - loss: 0.0702 - acc: 0.9990 - val_loss: 0.0856 - val_acc: 0.9910
Epoch 111/200
 - 2s - loss: 0.0714 - acc: 0.9974 - val_loss: 0.0951 - val_acc: 0.9885
Epoch 112/200
 - 2s - loss: 0.0681 - acc: 0.9990 - val_loss: 0.0912 - val_acc: 0.9923
Epoch 113/200
 - 2s - loss: 0.0707 - acc: 0.9987 - val_loss: 0.0890 - val_acc: 0.9923
Epoch 114/200
 - 2s - loss: 0.0679 - acc: 0.9990 - val_loss: 0.0836 - val_acc: 0.9910
Epoch 115/200
 - 2s - loss: 0.0716 - acc: 0.9981 - val_loss: 0.0867 - val_acc: 0.9910
Epoch 116/200
 - 2s - loss: 0.0665 - acc: 0.9987 - val_loss: 0.0856 - val_acc: 0.9910
Epoch 117/200
 - 2s - loss: 0.0658 - acc: 0.9994 - val_loss: 0.0866 - val_acc: 0.9910
Epoch 118/200
 - 2s - loss: 0.0661 - acc: 0.9984 - val_loss: 0.0907 - val_acc: 0.9898
Epoch 119/200
 - 2s - loss: 0.0650 - acc: 0.9990 - val_loss: 0.0859 - val_acc: 0.9910
Epoch 120/200
 - 2s - loss: 0.0651 - acc: 0.9984 - val_loss: 0.0862 - val_acc: 0.9923
Epoch 121/200
 - 2s - loss: 0.0632 - acc: 0.9994 - val_loss: 0.0872 - val_acc: 0.9923
Epoch 122/200
 - 2s - loss: 0.0629 - acc: 0.9990 - val_loss: 0.0872 - val_acc: 0.9898
Epoch 123/200
 - 2s - loss: 0.0653 - acc: 0.9978 - val_loss: 0.0776 - val_acc: 0.9923
Epoch 124/200
 - 2s - loss: 0.0631 - acc: 0.9981 - val_loss: 0.0819 - val_acc: 0.9910
Epoch 125/200
 - 2s - loss: 0.0644 - acc: 0.9981 - val_loss: 0.0817 - val_acc: 0.9910
Epoch 126/200
 - 2s - loss: 0.0636 - acc: 0.9974 - val_loss: 0.0887 - val_acc: 0.9859
Epoch 127/200
 - 2s - loss: 0.0646 - acc: 0.9981 - val_loss: 0.0793 - val_acc: 0.9936
Epoch 128/200
 - 2s - loss: 0.0601 - acc: 0.9997 - val_loss: 0.0858 - val_acc: 0.9885
Epoch 129/200
 - 2s - loss: 0.0611 - acc: 0.9984 - val_loss: 0.0801 - val_acc: 0.9910
Epoch 130/200
 - 2s - loss: 0.0601 - acc: 0.9990 - val_loss: 0.0854 - val_acc: 0.9885
Epoch 131/200
 - 2s - loss: 0.0596 - acc: 0.9990 - val_loss: 0.0864 - val_acc: 0.9898
Epoch 132/200
 - 2s - loss: 0.0599 - acc: 0.9984 - val_loss: 0.0843 - val_acc: 0.9910
Epoch 133/200
 - 2s - loss: 0.0604 - acc: 0.9978 - val_loss: 0.0912 - val_acc: 0.9872
Restoring model weights from the end of the best epoch
Epoch 00133: early stopping
End-train DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Keras TF Training sfa_bottles_2: 3899/3905 99.8%
              precision    recall  f1-score   support

           B       0.99      0.95      0.97        96
           V       1.00      1.00      1.00      3809

    accuracy                           1.00      3905
   macro avg       0.99      0.97      0.98      3905
weighted avg       1.00      1.00      1.00      3905

Keras TF Testing sfa_bottles_2: 970/976 99.4%
              precision    recall  f1-score   support

           B       1.00      0.75      0.86        24
           V       0.99      1.00      1.00       952

    accuracy                           0.99       976
   macro avg       1.00      0.88      0.93       976
weighted avg       0.99      0.99      0.99       976

Keras TF CV sfa_bottles_2: 2481/2519 98.5%
              precision    recall  f1-score   support

           B       0.90      0.43      0.58        61
           V       0.99      1.00      0.99      2458

    accuracy                           0.98      2519
   macro avg       0.94      0.71      0.79      2519
weighted avg       0.98      0.98      0.98      2519

Keras TF stop snn_sfa_bottles_2
trnargs = {'batch_size':64,'max_iter':200,'lay':[('conv1d',16,64,2),('relu',),('batch',),('pool',8,8),('conv1d',32,32,2),('relu',),('batch',),('pool',8,8),('conv1d',64,16,8),('relu',),('batch',),('conv1d',128,8,2),('relu',),('batch',),('conv1d',256,4,2),('relu',),('batch',),('pool',4,4),('flatten',),('ip',64),('relu',),('dropout',0.25),('ip',32),('relu',),('dropout',0.25)],'base_lr':0.0005, 'optimizer':'adadelta','val_split':0.2,'monitor': 'val_loss','patience':15, 'stop': True}
Keras TF start  cnn_sig_bottles_2
Train DNN with Keras
Train on 3124 samples, validate on 781 samples
Epoch 1/200
 - 146s - loss: 0.3987 - acc: 0.9587 - val_loss: 0.4050 - val_acc: 0.9667
Epoch 2/200
 - 137s - loss: 0.3400 - acc: 0.9766 - val_loss: 0.4354 - val_acc: 0.9667
Epoch 3/200
 - 137s - loss: 0.3244 - acc: 0.9763 - val_loss: 0.3903 - val_acc: 0.9667
Epoch 4/200
 - 140s - loss: 0.3084 - acc: 0.9773 - val_loss: 0.4759 - val_acc: 0.9667
Epoch 5/200
 - 139s - loss: 0.2908 - acc: 0.9773 - val_loss: 0.3656 - val_acc: 0.9667
Epoch 6/200
 - 137s - loss: 0.2717 - acc: 0.9773 - val_loss: 0.3985 - val_acc: 0.9667
Epoch 7/200
 - 137s - loss: 0.2436 - acc: 0.9827 - val_loss: 0.3857 - val_acc: 0.9667
Epoch 8/200
 - 133s - loss: 0.2240 - acc: 0.9888 - val_loss: 0.3409 - val_acc: 0.9680
Epoch 9/200
 - 135s - loss: 0.2149 - acc: 0.9878 - val_loss: 0.4800 - val_acc: 0.9667
Epoch 10/200
 - 137s - loss: 0.1858 - acc: 0.9926 - val_loss: 0.2014 - val_acc: 0.9898
Epoch 11/200
 - 137s - loss: 0.1734 - acc: 0.9952 - val_loss: 0.3123 - val_acc: 0.9731
Epoch 12/200
 - 141s - loss: 0.1619 - acc: 0.9971 - val_loss: 0.2066 - val_acc: 0.9846
Epoch 13/200
 - 137s - loss: 0.1493 - acc: 0.9987 - val_loss: 0.1960 - val_acc: 0.9782
Epoch 14/200
 - 138s - loss: 0.1431 - acc: 0.9958 - val_loss: 0.2412 - val_acc: 0.9782
Epoch 15/200
 - 136s - loss: 0.1383 - acc: 0.9955 - val_loss: 0.1508 - val_acc: 0.9936
Epoch 16/200
 - 135s - loss: 0.1269 - acc: 0.9971 - val_loss: 0.5556 - val_acc: 0.8310
Epoch 17/200
 - 138s - loss: 0.1227 - acc: 0.9965 - val_loss: 0.1514 - val_acc: 0.9936
Epoch 18/200
 - 139s - loss: 0.1202 - acc: 0.9965 - val_loss: 0.1502 - val_acc: 0.9872
Epoch 19/200
 - 138s - loss: 0.1068 - acc: 0.9984 - val_loss: 0.1364 - val_acc: 0.9923
Epoch 20/200
 - 137s - loss: 0.1068 - acc: 0.9965 - val_loss: 0.2365 - val_acc: 0.9424
Epoch 21/200
 - 140s - loss: 0.0948 - acc: 0.9990 - val_loss: 0.1485 - val_acc: 0.9770
Epoch 22/200
 - 144s - loss: 0.0872 - acc: 1.0000 - val_loss: 0.1267 - val_acc: 0.9910
Epoch 23/200
 - 143s - loss: 0.0878 - acc: 0.9990 - val_loss: 0.1133 - val_acc: 0.9885
Epoch 24/200
 - 143s - loss: 0.0785 - acc: 0.9987 - val_loss: 0.1725 - val_acc: 0.9834
Epoch 25/200
 - 144s - loss: 0.0719 - acc: 0.9997 - val_loss: 0.0944 - val_acc: 0.9949
Epoch 26/200
 - 135s - loss: 0.0673 - acc: 0.9997 - val_loss: 0.0873 - val_acc: 0.9962
Epoch 27/200
 - 134s - loss: 0.0648 - acc: 0.9990 - val_loss: 0.1172 - val_acc: 0.9770
Epoch 28/200
 - 151s - loss: 0.0665 - acc: 0.9981 - val_loss: 0.0858 - val_acc: 0.9949
Epoch 29/200
 - 145s - loss: 0.0618 - acc: 0.9971 - val_loss: 0.0897 - val_acc: 0.9962
Epoch 30/200
 - 135s - loss: 0.0624 - acc: 0.9984 - val_loss: 0.1017 - val_acc: 0.9834
Epoch 31/200
 - 139s - loss: 0.0552 - acc: 0.9990 - val_loss: 0.0925 - val_acc: 0.9923
Epoch 32/200
 - 135s - loss: 0.0495 - acc: 1.0000 - val_loss: 0.0722 - val_acc: 0.9962
Epoch 33/200
 - 134s - loss: 0.0459 - acc: 1.0000 - val_loss: 0.0624 - val_acc: 0.9974
Epoch 34/200
 - 134s - loss: 0.0421 - acc: 1.0000 - val_loss: 0.0695 - val_acc: 0.9910
Epoch 35/200
 - 143s - loss: 0.0385 - acc: 1.0000 - val_loss: 0.2249 - val_acc: 0.9283
Epoch 36/200
 - 143s - loss: 0.0351 - acc: 1.0000 - val_loss: 2.4594 - val_acc: 0.4251
Epoch 37/200
 - 143s - loss: 0.0319 - acc: 1.0000 - val_loss: 0.0474 - val_acc: 0.9974
Epoch 38/200
 - 144s - loss: 0.0290 - acc: 1.0000 - val_loss: 0.0461 - val_acc: 0.9974
Epoch 39/200
 - 145s - loss: 0.0283 - acc: 0.9994 - val_loss: 0.2637 - val_acc: 0.9104
Epoch 40/200
 - 148s - loss: 0.0263 - acc: 0.9997 - val_loss: 0.0445 - val_acc: 0.9974
Epoch 41/200
 - 143s - loss: 0.0360 - acc: 0.9968 - val_loss: 0.2013 - val_acc: 0.9398
Epoch 42/200
 - 145s - loss: 0.0398 - acc: 0.9965 - val_loss: 0.0955 - val_acc: 0.9910
Epoch 43/200
 - 150s - loss: 0.0235 - acc: 1.0000 - val_loss: 0.0602 - val_acc: 0.9936
Epoch 44/200
 - 154s - loss: 0.0222 - acc: 1.0000 - val_loss: 0.0584 - val_acc: 0.9923
Epoch 45/200
 - 148s - loss: 0.0403 - acc: 0.9958 - val_loss: 0.4423 - val_acc: 0.8387
Epoch 46/200
 - 144s - loss: 0.0281 - acc: 0.9981 - val_loss: 0.0610 - val_acc: 0.9846
Epoch 47/200
 - 143s - loss: 0.0316 - acc: 0.9968 - val_loss: 0.1242 - val_acc: 0.9808
Epoch 48/200
 - 143s - loss: 0.0222 - acc: 0.9990 - val_loss: 0.0954 - val_acc: 0.9872
Epoch 49/200
 - 139s - loss: 0.0195 - acc: 1.0000 - val_loss: 0.0402 - val_acc: 0.9936
Epoch 50/200
 - 146s - loss: 0.0208 - acc: 0.9994 - val_loss: 0.0485 - val_acc: 0.9898
Epoch 51/200
 - 141s - loss: 0.0175 - acc: 1.0000 - val_loss: 0.0389 - val_acc: 0.9949
Epoch 52/200
 - 141s - loss: 0.0162 - acc: 1.0000 - val_loss: 0.0405 - val_acc: 0.9974
Epoch 53/200
 - 143s - loss: 0.0160 - acc: 0.9997 - val_loss: 0.1404 - val_acc: 0.9834
Epoch 54/200
 - 146s - loss: 0.0562 - acc: 0.9862 - val_loss: 0.0455 - val_acc: 0.9974
Epoch 55/200
 - 145s - loss: 0.0180 - acc: 0.9994 - val_loss: 0.0452 - val_acc: 0.9962
Epoch 56/200
 - 143s - loss: 0.0303 - acc: 0.9958 - val_loss: 0.0756 - val_acc: 0.9731
Epoch 57/200
 - 137s - loss: 0.0328 - acc: 0.9955 - val_loss: 0.1019 - val_acc: 0.9834
Epoch 58/200
 - 144s - loss: 0.0188 - acc: 0.9987 - val_loss: 0.0413 - val_acc: 0.9949
Epoch 59/200
 - 143s - loss: 0.0152 - acc: 1.0000 - val_loss: 0.0355 - val_acc: 0.9962
Epoch 60/200
 - 147s - loss: 0.0139 - acc: 1.0000 - val_loss: 0.0341 - val_acc: 0.9962
Epoch 61/200
 - 146s - loss: 0.0129 - acc: 1.0000 - val_loss: 0.0296 - val_acc: 0.9949
Epoch 62/200
 - 147s - loss: 0.0265 - acc: 0.9965 - val_loss: 0.0417 - val_acc: 0.9936
Epoch 63/200
 - 145s - loss: 0.0138 - acc: 0.9997 - val_loss: 0.0555 - val_acc: 0.9949
Epoch 64/200
 - 144s - loss: 0.0138 - acc: 0.9994 - val_loss: 0.0263 - val_acc: 0.9962
Epoch 65/200
 - 142s - loss: 0.0117 - acc: 1.0000 - val_loss: 0.0306 - val_acc: 0.9962
Epoch 66/200
 - 143s - loss: 0.0121 - acc: 0.9994 - val_loss: 0.0840 - val_acc: 0.9795
Epoch 67/200
 - 143s - loss: 0.0148 - acc: 0.9987 - val_loss: 0.0329 - val_acc: 0.9949
Epoch 68/200
 - 143s - loss: 0.0202 - acc: 0.9968 - val_loss: 2.4314 - val_acc: 0.5096
Epoch 69/200
 - 144s - loss: 0.0117 - acc: 0.9997 - val_loss: 0.0241 - val_acc: 0.9987
Epoch 70/200
 - 146s - loss: 0.0136 - acc: 0.9990 - val_loss: 0.0687 - val_acc: 0.9936
Epoch 71/200
 - 142s - loss: 0.0175 - acc: 0.9987 - val_loss: 0.0295 - val_acc: 0.9962
Epoch 72/200
 - 140s - loss: 0.0104 - acc: 1.0000 - val_loss: 0.0311 - val_acc: 0.9974
Epoch 73/200
 - 141s - loss: 0.0202 - acc: 0.9965 - val_loss: 2.2573 - val_acc: 0.5058
Epoch 74/200
 - 142s - loss: 0.0104 - acc: 1.0000 - val_loss: 0.0631 - val_acc: 0.9808
Epoch 75/200
 - 143s - loss: 0.0095 - acc: 1.0000 - val_loss: 0.0292 - val_acc: 0.9962
Epoch 76/200
 - 143s - loss: 0.0103 - acc: 0.9997 - val_loss: 0.0827 - val_acc: 0.9923
Epoch 77/200
 - 144s - loss: 0.0321 - acc: 0.9942 - val_loss: 0.3950 - val_acc: 0.9680
Epoch 78/200
 - 146s - loss: 0.0103 - acc: 1.0000 - val_loss: 0.1829 - val_acc: 0.9770
Epoch 79/200
 - 141s - loss: 0.0091 - acc: 1.0000 - val_loss: 0.0562 - val_acc: 0.9936
Epoch 80/200
 - 141s - loss: 0.0086 - acc: 1.0000 - val_loss: 0.0523 - val_acc: 0.9923
Epoch 81/200
 - 148s - loss: 0.0174 - acc: 0.9965 - val_loss: 0.0657 - val_acc: 0.9910
Epoch 82/200
 - 145s - loss: 0.0105 - acc: 0.9994 - val_loss: 0.0609 - val_acc: 0.9923
Epoch 83/200
 - 146s - loss: 0.0116 - acc: 0.9990 - val_loss: 0.0414 - val_acc: 0.9923
Epoch 84/200
 - 145s - loss: 0.0097 - acc: 0.9994 - val_loss: 0.0416 - val_acc: 0.9898
Restoring model weights from the end of the best epoch
Epoch 00084: early stopping
End-train DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Keras TF Training sig_bottles_2: 3898/3905 99.8%
              precision    recall  f1-score   support

           B       0.94      0.99      0.96        96
           V       1.00      1.00      1.00      3809

    accuracy                           1.00      3905
   macro avg       0.97      0.99      0.98      3905
weighted avg       1.00      1.00      1.00      3905

Keras TF Testing sig_bottles_2: 968/976 99.2%
              precision    recall  f1-score   support

           B       0.77      0.96      0.85        24
           V       1.00      0.99      1.00       952

    accuracy                           0.99       976
   macro avg       0.88      0.98      0.92       976
weighted avg       0.99      0.99      0.99       976

Keras TF CV sig_bottles_2: 2494/2519 99.0%
              precision    recall  f1-score   support

           B       0.75      0.89      0.81        61
           V       1.00      0.99      0.99      2458

    accuracy                           0.99      2519
   macro avg       0.87      0.94      0.90      2519
weighted avg       0.99      0.99      0.99      2519

Keras TF stop cnn_sig_bottles_2
trnargs = {'batch_size':32,'max_iter':200,'lay':[('conv2d',32,[5,5],[2,2]),('elu',),('batch',),('dropout',0.1),('pool',[2,2],[2,2]),('conv2d',32,[5,5],[2,2]),('elu',),('batch',),('dropout',0.1),('pool',[2,2],[2,2]),('flatten',),('ip',90),('relu',),('dropout',0.7)],'base_lr':0.0005, 'optimizer':'adadelta','val_split':0.2,'monitor': 'val_loss','patience':15, 'stop': True}
Keras TF start  cnn_pfa_bottles_2
Train DNN with Keras
Train on 3124 samples, validate on 781 samples
Epoch 1/200
 - 24s - loss: 0.2681 - acc: 0.9673 - val_loss: 0.2903 - val_acc: 0.9667
Epoch 2/200
 - 21s - loss: 0.2171 - acc: 0.9773 - val_loss: 0.2292 - val_acc: 0.9667
Epoch 3/200
 - 20s - loss: 0.1684 - acc: 0.9792 - val_loss: 0.1405 - val_acc: 0.9693
Epoch 4/200
 - 21s - loss: 0.1183 - acc: 0.9850 - val_loss: 0.1008 - val_acc: 0.9846
Epoch 5/200
 - 22s - loss: 0.0966 - acc: 0.9923 - val_loss: 0.0738 - val_acc: 0.9974
Epoch 6/200
 - 27s - loss: 0.0821 - acc: 0.9946 - val_loss: 0.0669 - val_acc: 0.9974
Epoch 7/200
 - 28s - loss: 0.0738 - acc: 0.9952 - val_loss: 0.0581 - val_acc: 0.9987
Epoch 8/200
 - 33s - loss: 0.0691 - acc: 0.9952 - val_loss: 0.0548 - val_acc: 0.9987
Epoch 9/200
 - 27s - loss: 0.0597 - acc: 0.9965 - val_loss: 0.0521 - val_acc: 0.9974
Epoch 10/200
 - 23s - loss: 0.0569 - acc: 0.9962 - val_loss: 0.0469 - val_acc: 0.9987
Epoch 11/200
 - 23s - loss: 0.0494 - acc: 0.9981 - val_loss: 0.0404 - val_acc: 1.0000
Epoch 12/200
 - 22s - loss: 0.0494 - acc: 0.9962 - val_loss: 0.0389 - val_acc: 1.0000
Epoch 13/200
 - 22s - loss: 0.0441 - acc: 0.9981 - val_loss: 0.0363 - val_acc: 0.9987
Epoch 14/200
 - 22s - loss: 0.0366 - acc: 0.9984 - val_loss: 0.0322 - val_acc: 1.0000
Epoch 15/200
 - 26s - loss: 0.0361 - acc: 0.9981 - val_loss: 0.0297 - val_acc: 1.0000
Epoch 16/200
 - 17s - loss: 0.0303 - acc: 0.9990 - val_loss: 0.0271 - val_acc: 1.0000
Epoch 17/200
 - 20s - loss: 0.0291 - acc: 0.9984 - val_loss: 0.0249 - val_acc: 1.0000
Epoch 18/200
 - 19s - loss: 0.0271 - acc: 0.9984 - val_loss: 0.0229 - val_acc: 1.0000
Epoch 19/200
 - 13s - loss: 0.0283 - acc: 0.9981 - val_loss: 0.0279 - val_acc: 0.9974
Epoch 20/200
 - 13s - loss: 0.0231 - acc: 0.9987 - val_loss: 0.0218 - val_acc: 0.9987
Epoch 21/200
 - 13s - loss: 0.0237 - acc: 0.9981 - val_loss: 0.1220 - val_acc: 0.9706
Epoch 22/200
 - 13s - loss: 0.0220 - acc: 0.9984 - val_loss: 0.0184 - val_acc: 1.0000
Epoch 23/200
 - 13s - loss: 0.0179 - acc: 0.9997 - val_loss: 0.0165 - val_acc: 1.0000
Epoch 24/200
 - 13s - loss: 0.0163 - acc: 0.9997 - val_loss: 0.0144 - val_acc: 1.0000
Epoch 25/200
 - 13s - loss: 0.0194 - acc: 0.9987 - val_loss: 0.0176 - val_acc: 0.9974
Epoch 26/200
 - 13s - loss: 0.0143 - acc: 0.9997 - val_loss: 0.0177 - val_acc: 0.9974
Epoch 27/200
 - 13s - loss: 0.0136 - acc: 0.9994 - val_loss: 0.0118 - val_acc: 1.0000
Epoch 28/200
 - 13s - loss: 0.0160 - acc: 0.9978 - val_loss: 0.0137 - val_acc: 0.9987
Epoch 29/200
 - 13s - loss: 0.0149 - acc: 0.9984 - val_loss: 0.0118 - val_acc: 0.9987
Epoch 30/200
 - 13s - loss: 0.0122 - acc: 0.9994 - val_loss: 0.0103 - val_acc: 1.0000
Epoch 31/200
 - 13s - loss: 0.0144 - acc: 0.9984 - val_loss: 0.0139 - val_acc: 0.9987
Epoch 32/200
 - 13s - loss: 0.0131 - acc: 0.9987 - val_loss: 0.0116 - val_acc: 0.9987
Epoch 33/200
 - 13s - loss: 0.0113 - acc: 0.9994 - val_loss: 0.2114 - val_acc: 0.9795
Epoch 34/200
 - 13s - loss: 0.0095 - acc: 0.9997 - val_loss: 0.0090 - val_acc: 1.0000
Epoch 35/200
 - 13s - loss: 0.0157 - acc: 0.9978 - val_loss: 0.0194 - val_acc: 0.9974
Epoch 36/200
 - 13s - loss: 0.0099 - acc: 0.9994 - val_loss: 0.0153 - val_acc: 0.9962
Epoch 37/200
 - 13s - loss: 0.0094 - acc: 0.9997 - val_loss: 0.0097 - val_acc: 0.9987
Epoch 38/200
 - 13s - loss: 0.0119 - acc: 0.9984 - val_loss: 0.0081 - val_acc: 1.0000
Epoch 39/200
 - 13s - loss: 0.0087 - acc: 0.9997 - val_loss: 0.0075 - val_acc: 1.0000
Epoch 40/200
 - 13s - loss: 0.0076 - acc: 0.9997 - val_loss: 0.0069 - val_acc: 1.0000
Epoch 41/200
 - 13s - loss: 0.0125 - acc: 0.9981 - val_loss: 0.0084 - val_acc: 0.9987
Epoch 42/200
 - 13s - loss: 0.0070 - acc: 0.9997 - val_loss: 0.0108 - val_acc: 0.9987
Epoch 43/200
 - 13s - loss: 0.0096 - acc: 0.9981 - val_loss: 0.0064 - val_acc: 1.0000
Epoch 44/200
 - 13s - loss: 0.0065 - acc: 1.0000 - val_loss: 0.0132 - val_acc: 0.9962
Epoch 45/200
 - 13s - loss: 0.0094 - acc: 0.9994 - val_loss: 0.0586 - val_acc: 0.9872
Epoch 46/200
 - 13s - loss: 0.0090 - acc: 0.9984 - val_loss: 0.0065 - val_acc: 1.0000
Epoch 47/200
 - 13s - loss: 0.0058 - acc: 1.0000 - val_loss: 0.0057 - val_acc: 1.0000
Epoch 48/200
 - 13s - loss: 0.0072 - acc: 0.9994 - val_loss: 0.0181 - val_acc: 0.9962
Epoch 49/200
 - 13s - loss: 0.0060 - acc: 0.9997 - val_loss: 0.0057 - val_acc: 1.0000
Epoch 50/200
 - 13s - loss: 0.0145 - acc: 0.9987 - val_loss: 0.0160 - val_acc: 0.9962
Epoch 51/200
 - 13s - loss: 0.0097 - acc: 0.9981 - val_loss: 0.0252 - val_acc: 0.9962
Epoch 52/200
 - 13s - loss: 0.0055 - acc: 0.9997 - val_loss: 0.0069 - val_acc: 0.9987
Epoch 53/200
 - 14s - loss: 0.0089 - acc: 0.9990 - val_loss: 0.0743 - val_acc: 0.9757
Epoch 54/200
 - 13s - loss: 0.0084 - acc: 0.9990 - val_loss: 0.0050 - val_acc: 1.0000
Epoch 55/200
 - 13s - loss: 0.0050 - acc: 1.0000 - val_loss: 0.0046 - val_acc: 1.0000
Epoch 56/200
 - 13s - loss: 0.0101 - acc: 0.9978 - val_loss: 0.0084 - val_acc: 0.9987
Epoch 57/200
 - 13s - loss: 0.0089 - acc: 0.9984 - val_loss: 0.0117 - val_acc: 0.9987
Epoch 58/200
 - 13s - loss: 0.0065 - acc: 0.9994 - val_loss: 0.0241 - val_acc: 0.9936
Epoch 59/200
 - 13s - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0135 - val_acc: 0.9974
Epoch 60/200
 - 13s - loss: 0.0108 - acc: 0.9978 - val_loss: 0.0217 - val_acc: 0.9962
Epoch 61/200
 - 14s - loss: 0.0058 - acc: 0.9997 - val_loss: 0.0230 - val_acc: 0.9962
Epoch 62/200
 - 14s - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0117 - val_acc: 0.9974
Epoch 63/200
 - 13s - loss: 0.0065 - acc: 0.9994 - val_loss: 0.0042 - val_acc: 1.0000
Epoch 64/200
 - 14s - loss: 0.0051 - acc: 0.9997 - val_loss: 0.0331 - val_acc: 0.9936
Epoch 65/200
 - 16s - loss: 0.0076 - acc: 0.9981 - val_loss: 0.0087 - val_acc: 0.9987
Epoch 66/200
 - 17s - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000
Epoch 67/200
 - 13s - loss: 0.0042 - acc: 0.9997 - val_loss: 0.0055 - val_acc: 0.9987
Epoch 68/200
 - 15s - loss: 0.0123 - acc: 0.9978 - val_loss: 0.1119 - val_acc: 0.9885
Epoch 69/200
 - 14s - loss: 0.0051 - acc: 0.9994 - val_loss: 0.0042 - val_acc: 1.0000
Epoch 70/200
 - 20s - loss: 0.0077 - acc: 0.9984 - val_loss: 0.0110 - val_acc: 0.9974
Epoch 71/200
 - 26s - loss: 0.0050 - acc: 0.9994 - val_loss: 0.0040 - val_acc: 1.0000
Epoch 72/200
 - 22s - loss: 0.0066 - acc: 0.9994 - val_loss: 0.0043 - val_acc: 1.0000
Epoch 73/200
 - 25s - loss: 0.0069 - acc: 0.9990 - val_loss: 0.1040 - val_acc: 0.9693
Epoch 74/200
 - 21s - loss: 0.0050 - acc: 0.9994 - val_loss: 0.0072 - val_acc: 0.9987
Epoch 75/200
 - 22s - loss: 0.0039 - acc: 1.0000 - val_loss: 0.0037 - val_acc: 1.0000
Epoch 76/200
 - 23s - loss: 0.0228 - acc: 0.9962 - val_loss: 0.0060 - val_acc: 0.9987
Epoch 77/200
 - 25s - loss: 0.0051 - acc: 0.9997 - val_loss: 0.0041 - val_acc: 1.0000
Epoch 78/200
 - 30s - loss: 0.0040 - acc: 1.0000 - val_loss: 0.0111 - val_acc: 0.9987
Epoch 79/200
 - 37s - loss: 0.0065 - acc: 0.9990 - val_loss: 0.0039 - val_acc: 1.0000
Epoch 80/200
 - 13s - loss: 0.0043 - acc: 0.9997 - val_loss: 0.0086 - val_acc: 0.9962
Epoch 81/200
 - 13s - loss: 0.0045 - acc: 0.9997 - val_loss: 0.0143 - val_acc: 0.9949
Epoch 82/200
 - 13s - loss: 0.0047 - acc: 0.9997 - val_loss: 0.0035 - val_acc: 1.0000
Epoch 83/200
 - 13s - loss: 0.0046 - acc: 0.9990 - val_loss: 0.0080 - val_acc: 0.9974
Epoch 84/200
 - 13s - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0256 - val_acc: 0.9949
Epoch 85/200
 - 13s - loss: 0.0201 - acc: 0.9971 - val_loss: 0.0044 - val_acc: 1.0000
Epoch 86/200
 - 13s - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0076 - val_acc: 0.9987
Epoch 87/200
 - 13s - loss: 0.0041 - acc: 0.9994 - val_loss: 0.1104 - val_acc: 0.9885
Epoch 88/200
 - 13s - loss: 0.0144 - acc: 0.9971 - val_loss: 0.0144 - val_acc: 0.9974
Epoch 89/200
 - 14s - loss: 0.0091 - acc: 0.9978 - val_loss: 0.0060 - val_acc: 0.9987
Epoch 90/200
 - 13s - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0130 - val_acc: 0.9987
Epoch 91/200
 - 13s - loss: 0.0058 - acc: 0.9987 - val_loss: 0.0054 - val_acc: 0.9987
Epoch 92/200
 - 14s - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0050 - val_acc: 0.9987
Epoch 93/200
 - 14s - loss: 0.0054 - acc: 0.9990 - val_loss: 0.0180 - val_acc: 0.9949
Epoch 94/200
 - 13s - loss: 0.0040 - acc: 0.9997 - val_loss: 0.0032 - val_acc: 1.0000
Epoch 95/200
 - 13s - loss: 0.0071 - acc: 0.9987 - val_loss: 0.0055 - val_acc: 0.9974
Epoch 96/200
 - 13s - loss: 0.0033 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000
Epoch 97/200
 - 15s - loss: 0.0035 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 1.0000
Epoch 98/200
 - 14s - loss: 0.0046 - acc: 0.9990 - val_loss: 0.0055 - val_acc: 0.9987
Epoch 99/200
 - 13s - loss: 0.0114 - acc: 0.9971 - val_loss: 0.0166 - val_acc: 0.9974
Epoch 100/200
 - 13s - loss: 0.0080 - acc: 0.9984 - val_loss: 0.0109 - val_acc: 0.9974
Epoch 101/200
 - 13s - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 0.9987
Epoch 102/200
 - 13s - loss: 0.0045 - acc: 0.9994 - val_loss: 0.0088 - val_acc: 0.9987
Epoch 103/200
 - 13s - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0193 - val_acc: 0.9962
Epoch 104/200
 - 13s - loss: 0.0037 - acc: 0.9997 - val_loss: 0.0038 - val_acc: 0.9987
Epoch 105/200
 - 13s - loss: 0.0262 - acc: 0.9955 - val_loss: 0.0060 - val_acc: 0.9987
Epoch 106/200
 - 13s - loss: 0.0070 - acc: 0.9990 - val_loss: 0.0055 - val_acc: 0.9987
Epoch 107/200
 - 13s - loss: 0.0043 - acc: 0.9997 - val_loss: 0.0091 - val_acc: 0.9974
Epoch 108/200
 - 13s - loss: 0.0039 - acc: 0.9997 - val_loss: 0.0096 - val_acc: 0.9987
Epoch 109/200
 - 13s - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0115 - val_acc: 0.9974
Epoch 110/200
 - 13s - loss: 0.0121 - acc: 0.9978 - val_loss: 0.0105 - val_acc: 0.9987
Epoch 111/200
 - 13s - loss: 0.0056 - acc: 0.9990 - val_loss: 0.0119 - val_acc: 0.9974
Restoring model weights from the end of the best epoch
Epoch 00111: early stopping
End-train DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Keras TF Training pfa_bottles_2: 3905/3905 100.0%
              precision    recall  f1-score   support

           B       1.00      1.00      1.00        96
           V       1.00      1.00      1.00      3809

    accuracy                           1.00      3905
   macro avg       1.00      1.00      1.00      3905
weighted avg       1.00      1.00      1.00      3905

Keras TF Testing pfa_bottles_2: 975/976 99.9%
              precision    recall  f1-score   support

           B       1.00      0.96      0.98        24
           V       1.00      1.00      1.00       952

    accuracy                           1.00       976
   macro avg       1.00      0.98      0.99       976
weighted avg       1.00      1.00      1.00       976

Keras TF CV pfa_bottles_2: 2495/2519 99.0%
              precision    recall  f1-score   support

           B       0.95      0.64      0.76        61
           V       0.99      1.00      1.00      2458

    accuracy                           0.99      2519
   macro avg       0.97      0.82      0.88      2519
weighted avg       0.99      0.99      0.99      2519

Keras TF stop cnn_pfa_bottles_2
trnargs = {'batch_size':32,'max_iter':200,'lay':[('conv2d',32,[5,5],[2,2]),('elu',),('batch',),('dropout',0.1),('pool',[2,2],[2,2]),('conv2d',32,[5,5],[2,2]),('elu',),('batch',),('dropout',0.1),('pool',[2,2],[2,2]),('flatten',),('ip',90),('relu',),('dropout',0.7)],'base_lr':0.0005, 'optimizer':'adadelta','val_split':0.2,'monitor': 'val_loss','patience':15, 'stop': True}
Keras TF start  cnn_sfa_bottles_2
Train DNN with Keras
Train on 3124 samples, validate on 781 samples
Epoch 1/200
 - 13s - loss: 0.2678 - acc: 0.9699 - val_loss: 0.2511 - val_acc: 0.9667
Epoch 2/200
 - 10s - loss: 0.1841 - acc: 0.9782 - val_loss: 0.1611 - val_acc: 0.9667
Epoch 3/200
 - 10s - loss: 0.1265 - acc: 0.9875 - val_loss: 0.0977 - val_acc: 0.9949
Epoch 4/200
 - 10s - loss: 0.0975 - acc: 0.9949 - val_loss: 0.1007 - val_acc: 0.9898
Epoch 5/200
 - 11s - loss: 0.0872 - acc: 0.9942 - val_loss: 0.0735 - val_acc: 0.9987
Epoch 6/200
 - 10s - loss: 0.0745 - acc: 0.9974 - val_loss: 0.0658 - val_acc: 1.0000
Epoch 7/200
 - 10s - loss: 0.0666 - acc: 0.9981 - val_loss: 0.0599 - val_acc: 0.9987
Epoch 8/200
 - 10s - loss: 0.0602 - acc: 0.9987 - val_loss: 0.0529 - val_acc: 1.0000
Epoch 9/200
 - 10s - loss: 0.0554 - acc: 0.9984 - val_loss: 0.0491 - val_acc: 1.0000
Epoch 10/200
 - 11s - loss: 0.0465 - acc: 0.9994 - val_loss: 0.0437 - val_acc: 1.0000
Epoch 11/200
 - 10s - loss: 0.0443 - acc: 0.9981 - val_loss: 0.0390 - val_acc: 1.0000
Epoch 12/200
 - 11s - loss: 0.0389 - acc: 0.9990 - val_loss: 0.0387 - val_acc: 0.9987
Epoch 13/200
 - 10s - loss: 0.0365 - acc: 0.9990 - val_loss: 0.0321 - val_acc: 1.0000
Epoch 14/200
 - 10s - loss: 0.0310 - acc: 0.9997 - val_loss: 0.0287 - val_acc: 1.0000
Epoch 15/200
 - 10s - loss: 0.0313 - acc: 0.9984 - val_loss: 0.0383 - val_acc: 0.9962
Epoch 16/200
 - 10s - loss: 0.0254 - acc: 0.9994 - val_loss: 0.0323 - val_acc: 0.9974
Epoch 17/200
 - 11s - loss: 0.0222 - acc: 1.0000 - val_loss: 0.0212 - val_acc: 1.0000
Epoch 18/200
 - 11s - loss: 0.0252 - acc: 0.9987 - val_loss: 0.0196 - val_acc: 1.0000
Epoch 19/200
 - 15s - loss: 0.0209 - acc: 0.9987 - val_loss: 0.0183 - val_acc: 1.0000
Epoch 20/200
 - 11s - loss: 0.0180 - acc: 0.9994 - val_loss: 0.0194 - val_acc: 0.9987
Epoch 21/200
 - 11s - loss: 0.0157 - acc: 0.9997 - val_loss: 0.0145 - val_acc: 1.0000
Epoch 22/200
 - 14s - loss: 0.0133 - acc: 1.0000 - val_loss: 0.0145 - val_acc: 0.9987
Epoch 23/200
 - 12s - loss: 0.0118 - acc: 0.9997 - val_loss: 0.0113 - val_acc: 1.0000
Epoch 24/200
 - 14s - loss: 0.0105 - acc: 1.0000 - val_loss: 0.0140 - val_acc: 0.9987
Epoch 25/200
 - 12s - loss: 0.0096 - acc: 1.0000 - val_loss: 0.0094 - val_acc: 1.0000
Epoch 26/200
 - 14s - loss: 0.0082 - acc: 1.0000 - val_loss: 0.0093 - val_acc: 1.0000
Epoch 27/200
 - 28s - loss: 0.0081 - acc: 0.9994 - val_loss: 0.0077 - val_acc: 1.0000
Epoch 28/200
 - 18s - loss: 0.0074 - acc: 0.9997 - val_loss: 0.0084 - val_acc: 0.9987
Epoch 29/200
 - 20s - loss: 0.0068 - acc: 0.9997 - val_loss: 0.0089 - val_acc: 0.9987
Epoch 30/200
 - 16s - loss: 0.0069 - acc: 0.9994 - val_loss: 0.0058 - val_acc: 1.0000
Epoch 31/200
 - 16s - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0070 - val_acc: 0.9987
Epoch 32/200
 - 15s - loss: 0.0078 - acc: 0.9981 - val_loss: 0.0051 - val_acc: 1.0000
Epoch 33/200
 - 23s - loss: 0.0056 - acc: 0.9997 - val_loss: 0.0064 - val_acc: 0.9987
Epoch 34/200
 - 17s - loss: 0.0048 - acc: 1.0000 - val_loss: 0.0044 - val_acc: 1.0000
Epoch 35/200
 - 12s - loss: 0.0049 - acc: 0.9997 - val_loss: 0.0092 - val_acc: 0.9974
Epoch 36/200
 - 12s - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 1.0000
Epoch 37/200
 - 13s - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 1.0000
Epoch 38/200
 - 13s - loss: 0.0039 - acc: 0.9997 - val_loss: 0.0038 - val_acc: 1.0000
Epoch 39/200
 - 18s - loss: 0.0035 - acc: 1.0000 - val_loss: 0.0063 - val_acc: 0.9974
Epoch 40/200
 - 18s - loss: 0.0031 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000
Epoch 41/200
 - 15s - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 1.0000
Epoch 42/200
 - 16s - loss: 0.0028 - acc: 0.9997 - val_loss: 0.0109 - val_acc: 0.9962
Epoch 43/200
 - 11s - loss: 0.0045 - acc: 0.9987 - val_loss: 0.0068 - val_acc: 0.9987
Epoch 44/200
 - 12s - loss: 0.0035 - acc: 0.9997 - val_loss: 0.1130 - val_acc: 0.9795
Epoch 45/200
 - 11s - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000
Epoch 46/200
 - 10s - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0251 - val_acc: 0.9936
Epoch 47/200
 - 11s - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 0.9987
Epoch 48/200
 - 11s - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0048 - val_acc: 0.9987
Epoch 49/200
 - 10s - loss: 0.0049 - acc: 0.9994 - val_loss: 0.0147 - val_acc: 0.9949
Epoch 50/200
 - 11s - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0024 - val_acc: 1.0000
Epoch 51/200
 - 11s - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 1.0000
Epoch 52/200
 - 10s - loss: 0.0035 - acc: 0.9997 - val_loss: 0.0046 - val_acc: 0.9987
Epoch 53/200
 - 10s - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0022 - val_acc: 1.0000
Epoch 54/200
 - 10s - loss: 0.0028 - acc: 0.9997 - val_loss: 0.0021 - val_acc: 1.0000
Epoch 55/200
 - 10s - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 0.9987
Epoch 56/200
 - 10s - loss: 0.0037 - acc: 0.9997 - val_loss: 0.0033 - val_acc: 1.0000
Epoch 57/200
 - 10s - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0102 - val_acc: 0.9962
Epoch 58/200
 - 11s - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0501 - val_acc: 0.9923
Epoch 59/200
 - 10s - loss: 0.0034 - acc: 0.9994 - val_loss: 0.0033 - val_acc: 1.0000
Epoch 60/200
 - 10s - loss: 0.0075 - acc: 0.9974 - val_loss: 0.0096 - val_acc: 0.9974
Epoch 61/200
 - 10s - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000
Epoch 62/200
 - 10s - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000
Epoch 63/200
 - 10s - loss: 0.0042 - acc: 0.9990 - val_loss: 0.0495 - val_acc: 0.9910
Epoch 64/200
 - 10s - loss: 0.0049 - acc: 0.9994 - val_loss: 0.0028 - val_acc: 1.0000
Epoch 65/200
 - 10s - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000
Epoch 66/200
 - 10s - loss: 0.0023 - acc: 0.9997 - val_loss: 0.0019 - val_acc: 1.0000
Epoch 67/200
 - 10s - loss: 0.0042 - acc: 0.9994 - val_loss: 0.0068 - val_acc: 0.9974
Epoch 68/200
 - 11s - loss: 0.0023 - acc: 1.0000 - val_loss: 0.1053 - val_acc: 0.9821
Epoch 69/200
 - 10s - loss: 0.0039 - acc: 0.9990 - val_loss: 0.0026 - val_acc: 1.0000
Epoch 70/200
 - 10s - loss: 0.0056 - acc: 0.9984 - val_loss: 0.0029 - val_acc: 1.0000
Epoch 71/200
 - 11s - loss: 0.0045 - acc: 0.9987 - val_loss: 0.0041 - val_acc: 1.0000
Epoch 72/200
 - 11s - loss: 0.0028 - acc: 0.9997 - val_loss: 0.0075 - val_acc: 0.9987
Epoch 73/200
 - 11s - loss: 0.0039 - acc: 0.9997 - val_loss: 0.0024 - val_acc: 1.0000
Epoch 74/200
 - 11s - loss: 0.0027 - acc: 0.9997 - val_loss: 0.0034 - val_acc: 1.0000
Epoch 75/200
 - 10s - loss: 0.0034 - acc: 0.9994 - val_loss: 0.0022 - val_acc: 1.0000
Epoch 76/200
 - 11s - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000
Epoch 77/200
 - 10s - loss: 0.0035 - acc: 0.9994 - val_loss: 0.0021 - val_acc: 1.0000
Epoch 78/200
 - 10s - loss: 0.0032 - acc: 0.9997 - val_loss: 0.0084 - val_acc: 0.9974
Epoch 79/200
 - 10s - loss: 0.0067 - acc: 0.9990 - val_loss: 0.0020 - val_acc: 1.0000
Epoch 80/200
 - 10s - loss: 0.0042 - acc: 0.9994 - val_loss: 0.0021 - val_acc: 1.0000
Epoch 81/200
 - 10s - loss: 0.0073 - acc: 0.9987 - val_loss: 0.0022 - val_acc: 1.0000
Epoch 82/200
 - 10s - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000
Epoch 83/200
 - 10s - loss: 0.0023 - acc: 0.9997 - val_loss: 0.0030 - val_acc: 1.0000
Epoch 84/200
 - 10s - loss: 0.0031 - acc: 0.9994 - val_loss: 0.0022 - val_acc: 1.0000
Epoch 85/200
 - 11s - loss: 0.0063 - acc: 0.9981 - val_loss: 0.0242 - val_acc: 0.9936
Epoch 86/200
 - 11s - loss: 0.0078 - acc: 0.9994 - val_loss: 0.0219 - val_acc: 0.9949
Epoch 87/200
 - 11s - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0043 - val_acc: 0.9987
Epoch 88/200
 - 10s - loss: 0.0043 - acc: 0.9994 - val_loss: 0.0025 - val_acc: 1.0000
Epoch 89/200
 - 10s - loss: 0.0038 - acc: 0.9994 - val_loss: 0.0024 - val_acc: 1.0000
Epoch 90/200
 - 14s - loss: 0.0029 - acc: 0.9994 - val_loss: 0.0038 - val_acc: 1.0000
Epoch 91/200
 - 12s - loss: 0.0036 - acc: 0.9997 - val_loss: 0.0023 - val_acc: 1.0000
Restoring model weights from the end of the best epoch
Epoch 00091: early stopping
End-train DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Keras TF Training sfa_bottles_2: 3905/3905 100.0%
              precision    recall  f1-score   support

           B       1.00      1.00      1.00        96
           V       1.00      1.00      1.00      3809

    accuracy                           1.00      3905
   macro avg       1.00      1.00      1.00      3905
weighted avg       1.00      1.00      1.00      3905

Keras TF Testing sfa_bottles_2: 974/976 99.8%
              precision    recall  f1-score   support

           B       1.00      0.92      0.96        24
           V       1.00      1.00      1.00       952

    accuracy                           1.00       976
   macro avg       1.00      0.96      0.98       976
weighted avg       1.00      1.00      1.00       976

Keras TF CV sfa_bottles_2: 2506/2519 99.5%
              precision    recall  f1-score   support

           B       0.94      0.84      0.89        61
           V       1.00      1.00      1.00      2458

    accuracy                           0.99      2519
   macro avg       0.97      0.92      0.94      2519
weighted avg       0.99      0.99      0.99      2519

Keras TF stop cnn_sfa_bottles_2
svm start  sig_bottles_2
SVM Training sig_bottles_2: 3902/3905 99.9%
              precision    recall  f1-score   support

           B       0.97      1.00      0.98        96
           V       1.00      1.00      1.00      3809

    accuracy                           1.00      3905
   macro avg       0.98      1.00      0.99      3905
weighted avg       1.00      1.00      1.00      3905

SVM Testing sig_bottles_2: 966/976 99.0%
              precision    recall  f1-score   support

           B       0.77      0.83      0.80        24
           V       1.00      0.99      0.99       952

    accuracy                           0.99       976
   macro avg       0.88      0.91      0.90       976
weighted avg       0.99      0.99      0.99       976

SVM CV sig_bottles_2: 2411/2519 95.7%
              precision    recall  f1-score   support

           B       0.13      0.13      0.13        61
           V       0.98      0.98      0.98      2458

    accuracy                           0.96      2519
   macro avg       0.55      0.55      0.55      2519
weighted avg       0.96      0.96      0.96      2519

svm finish sig_bottles_2
svm start  pfa_bottles_2
SVM Training pfa_bottles_2: 3905/3905 100.0%
              precision    recall  f1-score   support

           B       1.00      1.00      1.00        96
           V       1.00      1.00      1.00      3809

    accuracy                           1.00      3905
   macro avg       1.00      1.00      1.00      3905
weighted avg       1.00      1.00      1.00      3905

SVM Testing pfa_bottles_2: 974/976 99.8%
              precision    recall  f1-score   support

           B       1.00      0.92      0.96        24
           V       1.00      1.00      1.00       952

    accuracy                           1.00       976
   macro avg       1.00      0.96      0.98       976
weighted avg       1.00      1.00      1.00       976

SVM CV pfa_bottles_2: 2496/2519 99.1%
              precision    recall  f1-score   support

           B       0.97      0.64      0.77        61
           V       0.99      1.00      1.00      2458

    accuracy                           0.99      2519
   macro avg       0.98      0.82      0.88      2519
weighted avg       0.99      0.99      0.99      2519

svm finish pfa_bottles_2
svm start  sfa_bottles_2
SVM Training sfa_bottles_2: 3905/3905 100.0%
              precision    recall  f1-score   support

           B       1.00      1.00      1.00        96
           V       1.00      1.00      1.00      3809

    accuracy                           1.00      3905
   macro avg       1.00      1.00      1.00      3905
weighted avg       1.00      1.00      1.00      3905

SVM Testing sfa_bottles_2: 969/976 99.3%
              precision    recall  f1-score   support

           B       1.00      0.71      0.83        24
           V       0.99      1.00      1.00       952

    accuracy                           0.99       976
   macro avg       1.00      0.85      0.91       976
weighted avg       0.99      0.99      0.99       976

SVM CV sfa_bottles_2: 2468/2519 98.0%
              precision    recall  f1-score   support

           B       0.92      0.18      0.30        61
           V       0.98      1.00      0.99      2458

    accuracy                           0.98      2519
   macro avg       0.95      0.59      0.65      2519
weighted avg       0.98      0.98      0.97      2519

svm finish sfa_bottles_2
trnargs = {'states':1, 'its': [0]}
hmm start  pfa_bottles_2
spl 0
CMP: 967/976 99.1%
HMM Training pfa_bottles_2: 3861/3905 98.9%
              precision    recall  f1-score   support

           B       0.69      1.00      0.81        96
           V       1.00      0.99      0.99      3809

    accuracy                           0.99      3905
   macro avg       0.84      0.99      0.90      3905
weighted avg       0.99      0.99      0.99      3905

HMM Testing pfa_bottles_2: 967/976 99.1%
              precision    recall  f1-score   support

           B       0.73      1.00      0.84        24
           V       1.00      0.99      1.00       952

    accuracy                           0.99       976
   macro avg       0.86      1.00      0.92       976
weighted avg       0.99      0.99      0.99       976

HMM CV pfa_bottles_2: 2483/2519 98.6%
              precision    recall  f1-score   support

           B       0.67      0.80      0.73        61
           V       1.00      0.99      0.99      2458

    accuracy                           0.99      2519
   macro avg       0.83      0.90      0.86      2519
weighted avg       0.99      0.99      0.99      2519

hmm start  sfa_bottles_2
spl 0
CMP: 784/976 80.3%
spl 0 ite 1
CMP: 931/976 95.4%
spl 0 ite 2
CMP: 950/976 97.3%
spl 0 ite 3
CMP: 958/976 98.2%
spl 1
CMP: 955/976 97.8%
spl 1 ite 1
CMP: 967/976 99.1%
spl 1 ite 2
CMP: 968/976 99.2%
spl 1 ite 3
CMP: 971/976 99.5%
spl 1 ite 4
CMP: 972/976 99.6%
spl 1 ite 5
CMP: 972/976 99.6%
spl 2
CMP: 971/976 99.5%
spl 2 ite 1
CMP: 971/976 99.5%
spl 2 ite 2
CMP: 973/976 99.7%
spl 2 ite 3
CMP: 973/976 99.7%
spl 2 ite 4
CMP: 973/976 99.7%
spl 2 ite 5
CMP: 973/976 99.7%
spl 2 ite 6
CMP: 973/976 99.7%
spl 2 ite 7
CMP: 973/976 99.7%
spl 3
CMP: 973/976 99.7%
spl 3 ite 1
CMP: 972/976 99.6%
spl 3 ite 2
CMP: 972/976 99.6%
spl 3 ite 3
CMP: 972/976 99.6%
spl 3 ite 4
CMP: 972/976 99.6%
spl 3 ite 5
CMP: 973/976 99.7%
spl 3 ite 6
CMP: 974/976 99.8%
spl 3 ite 7
CMP: 974/976 99.8%
spl 3 ite 8
CMP: 974/976 99.8%
spl 3 ite 9
CMP: 974/976 99.8%
spl 4
CMP: 973/976 99.7%
spl 4 ite 1
CMP: 974/976 99.8%
spl 4 ite 2
CMP: 975/976 99.9%
spl 4 ite 3
CMP: 975/976 99.9%
spl 4 ite 4
CMP: 975/976 99.9%
spl 4 ite 5
CMP: 975/976 99.9%
spl 4 ite 6
CMP: 975/976 99.9%
spl 4 ite 7
CMP: 975/976 99.9%
spl 4 ite 8
CMP: 975/976 99.9%
spl 4 ite 9
CMP: 975/976 99.9%
spl 4 ite 10
CMP: 975/976 99.9%
spl 4 ite 11
CMP: 974/976 99.8%
spl 5
CMP: 973/976 99.7%
spl 5 ite 1
CMP: 972/976 99.6%
spl 5 ite 2
CMP: 972/976 99.6%
spl 5 ite 3
CMP: 972/976 99.6%
spl 5 ite 4
CMP: 972/976 99.6%
spl 5 ite 5
CMP: 972/976 99.6%
spl 5 ite 6
CMP: 972/976 99.6%
spl 5 ite 7
CMP: 972/976 99.6%
spl 5 ite 8
CMP: 972/976 99.6%
spl 5 ite 9
CMP: 972/976 99.6%
spl 5 ite 10
CMP: 972/976 99.6%
spl 5 ite 11
CMP: 972/976 99.6%
spl 5 ite 12
CMP: 972/976 99.6%
spl 5 ite 13
CMP: 972/976 99.6%
HMM Training sfa_bottles_2: 3905/3905 100.0%
              precision    recall  f1-score   support

           B       1.00      1.00      1.00        96
           V       1.00      1.00      1.00      3809

    accuracy                           1.00      3905
   macro avg       1.00      1.00      1.00      3905
weighted avg       1.00      1.00      1.00      3905

HMM Testing sfa_bottles_2: 972/976 99.6%
              precision    recall  f1-score   support

           B       1.00      0.83      0.91        24
           V       1.00      1.00      1.00       952

    accuracy                           1.00       976
   macro avg       1.00      0.92      0.95       976
weighted avg       1.00      1.00      1.00       976

HMM CV sfa_bottles_2: 2488/2519 98.8%
              precision    recall  f1-score   support

           B       1.00      0.49      0.66        61
           V       0.99      1.00      0.99      2458

    accuracy                           0.99      2519
   macro avg       0.99      0.75      0.83      2519
weighted avg       0.99      0.99      0.99      2519

flst [bottles]
load fdb /home/kraljiva/Projects/uasr-data/bottles/Versuch004_E/log/fdb
trnargs = {'batch_size':32,'max_iter':200,'lay':[('ip',256),('lrelu',),('batch',),('dropout',0.6), ('ip',128),('lrelu',),('batch',),('dropout',0.6)],'base_lr':0.0005,'optimizer':'adagrad','val_split':0.2,'monitor': 'val_loss','patience':10, 'stop': True}
Keras TF start  snn_sig_bottles_3
Train DNN with Keras
Train on 3124 samples, validate on 781 samples
Epoch 1/200
 - 28s - loss: 1.4282 - acc: 0.7660 - val_loss: 0.8852 - val_acc: 0.9667
Epoch 2/200
 - 25s - loss: 0.9019 - acc: 0.9075 - val_loss: 0.7410 - val_acc: 0.9654
Epoch 3/200
 - 24s - loss: 0.6919 - acc: 0.9488 - val_loss: 0.5911 - val_acc: 0.9667
Epoch 4/200
 - 24s - loss: 0.5838 - acc: 0.9561 - val_loss: 0.5342 - val_acc: 0.9667
Epoch 5/200
 - 24s - loss: 0.5046 - acc: 0.9616 - val_loss: 0.4791 - val_acc: 0.9667
Epoch 6/200
 - 24s - loss: 0.4568 - acc: 0.9593 - val_loss: 0.4435 - val_acc: 0.9667
Epoch 7/200
 - 24s - loss: 0.4187 - acc: 0.9651 - val_loss: 0.4300 - val_acc: 0.9667
Epoch 8/200
 - 24s - loss: 0.3690 - acc: 0.9728 - val_loss: 0.4045 - val_acc: 0.9667
Epoch 9/200
 - 24s - loss: 0.3489 - acc: 0.9702 - val_loss: 0.3652 - val_acc: 0.9667
Epoch 10/200
 - 24s - loss: 0.3366 - acc: 0.9731 - val_loss: 0.3603 - val_acc: 0.9667
Epoch 11/200
 - 24s - loss: 0.3303 - acc: 0.9725 - val_loss: 0.3760 - val_acc: 0.9667
Epoch 12/200
 - 24s - loss: 0.3118 - acc: 0.9741 - val_loss: 0.3788 - val_acc: 0.9667
Epoch 13/200
 - 24s - loss: 0.3012 - acc: 0.9776 - val_loss: 0.3607 - val_acc: 0.9667
Epoch 14/200
 - 24s - loss: 0.2829 - acc: 0.9798 - val_loss: 0.3986 - val_acc: 0.9667
Epoch 15/200
 - 23s - loss: 0.2571 - acc: 0.9811 - val_loss: 0.3306 - val_acc: 0.9667
Epoch 16/200
 - 24s - loss: 0.2610 - acc: 0.9802 - val_loss: 0.3714 - val_acc: 0.9667
Epoch 17/200
 - 25s - loss: 0.2455 - acc: 0.9827 - val_loss: 0.3612 - val_acc: 0.9667
Epoch 18/200
 - 23s - loss: 0.2390 - acc: 0.9789 - val_loss: 0.3657 - val_acc: 0.9667
Epoch 19/200
 - 25s - loss: 0.2306 - acc: 0.9834 - val_loss: 0.3968 - val_acc: 0.9667
Epoch 20/200
 - 24s - loss: 0.2271 - acc: 0.9821 - val_loss: 0.2880 - val_acc: 0.9680
Epoch 21/200
 - 24s - loss: 0.2190 - acc: 0.9840 - val_loss: 0.2720 - val_acc: 0.9731
Epoch 22/200
 - 24s - loss: 0.2188 - acc: 0.9830 - val_loss: 0.3236 - val_acc: 0.9680
Epoch 23/200
 - 24s - loss: 0.2139 - acc: 0.9850 - val_loss: 0.3142 - val_acc: 0.9680
Epoch 24/200
 - 25s - loss: 0.2186 - acc: 0.9814 - val_loss: 0.2843 - val_acc: 0.9731
Epoch 25/200
 - 24s - loss: 0.2161 - acc: 0.9830 - val_loss: 0.4553 - val_acc: 0.9667
Epoch 26/200
 - 24s - loss: 0.2006 - acc: 0.9878 - val_loss: 0.2945 - val_acc: 0.9680
Epoch 27/200
 - 24s - loss: 0.1989 - acc: 0.9840 - val_loss: 0.2748 - val_acc: 0.9693
Epoch 28/200
 - 24s - loss: 0.1842 - acc: 0.9891 - val_loss: 0.3231 - val_acc: 0.9667
Epoch 29/200
 - 24s - loss: 0.1842 - acc: 0.9850 - val_loss: 0.3191 - val_acc: 0.9680
Epoch 30/200
 - 24s - loss: 0.1832 - acc: 0.9862 - val_loss: 0.3123 - val_acc: 0.9680
Epoch 31/200
 - 24s - loss: 0.1851 - acc: 0.9875 - val_loss: 0.2406 - val_acc: 0.9731
Epoch 32/200
 - 23s - loss: 0.1794 - acc: 0.9882 - val_loss: 0.2786 - val_acc: 0.9731
Epoch 33/200
 - 22s - loss: 0.1762 - acc: 0.9888 - val_loss: 0.2456 - val_acc: 0.9718
Epoch 34/200
 - 22s - loss: 0.1698 - acc: 0.9901 - val_loss: 0.2316 - val_acc: 0.9744
Epoch 35/200
 - 23s - loss: 0.1718 - acc: 0.9872 - val_loss: 0.2381 - val_acc: 0.9693
Epoch 36/200
 - 24s - loss: 0.1721 - acc: 0.9862 - val_loss: 0.2677 - val_acc: 0.9706
Epoch 37/200
 - 24s - loss: 0.1637 - acc: 0.9923 - val_loss: 0.3155 - val_acc: 0.9667
Epoch 38/200
 - 23s - loss: 0.1758 - acc: 0.9859 - val_loss: 0.2640 - val_acc: 0.9706
Epoch 39/200
 - 22s - loss: 0.1624 - acc: 0.9898 - val_loss: 0.2679 - val_acc: 0.9718
Epoch 40/200
 - 22s - loss: 0.1595 - acc: 0.9894 - val_loss: 0.2214 - val_acc: 0.9731
Epoch 41/200
 - 22s - loss: 0.1557 - acc: 0.9894 - val_loss: 0.3376 - val_acc: 0.9680
Epoch 42/200
 - 22s - loss: 0.1533 - acc: 0.9901 - val_loss: 0.2360 - val_acc: 0.9744
Epoch 43/200
 - 22s - loss: 0.1508 - acc: 0.9917 - val_loss: 0.2164 - val_acc: 0.9782
Epoch 44/200
 - 22s - loss: 0.1455 - acc: 0.9917 - val_loss: 0.2348 - val_acc: 0.9706
Epoch 45/200
 - 22s - loss: 0.1489 - acc: 0.9907 - val_loss: 0.2332 - val_acc: 0.9731
Epoch 46/200
 - 22s - loss: 0.1493 - acc: 0.9898 - val_loss: 0.2251 - val_acc: 0.9744
Epoch 47/200
 - 22s - loss: 0.1457 - acc: 0.9917 - val_loss: 0.2512 - val_acc: 0.9706
Epoch 48/200
 - 22s - loss: 0.1328 - acc: 0.9946 - val_loss: 0.2685 - val_acc: 0.9718
Epoch 49/200
 - 22s - loss: 0.1333 - acc: 0.9930 - val_loss: 0.2385 - val_acc: 0.9718
Epoch 50/200
 - 23s - loss: 0.1319 - acc: 0.9920 - val_loss: 0.2215 - val_acc: 0.9757
Epoch 51/200
 - 24s - loss: 0.1283 - acc: 0.9946 - val_loss: 0.2341 - val_acc: 0.9744
Epoch 52/200
 - 24s - loss: 0.1416 - acc: 0.9901 - val_loss: 0.2591 - val_acc: 0.9693
Epoch 53/200
 - 25s - loss: 0.1331 - acc: 0.9930 - val_loss: 0.2439 - val_acc: 0.9718
Restoring model weights from the end of the best epoch
Epoch 00053: early stopping
End-train DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Keras TF Training sig_bottles_3: 3884/3905 99.5%
              precision    recall  f1-score   support

           B       0.99      0.79      0.88        96
           V       0.99      1.00      1.00      3809

    accuracy                           0.99      3905
   macro avg       0.99      0.90      0.94      3905
weighted avg       0.99      0.99      0.99      3905

Keras TF Testing sig_bottles_3: 954/976 97.7%
              precision    recall  f1-score   support

           B       0.60      0.25      0.35        24
           V       0.98      1.00      0.99       952

    accuracy                           0.98       976
   macro avg       0.79      0.62      0.67       976
weighted avg       0.97      0.98      0.97       976

Keras TF CV sig_bottles_3: 2456/2519 97.5%
              precision    recall  f1-score   support

           B       0.42      0.08      0.14        61
           V       0.98      1.00      0.99      2458

    accuracy                           0.97      2519
   macro avg       0.70      0.54      0.56      2519
weighted avg       0.96      0.97      0.97      2519

Keras TF stop snn_sig_bottles_3
trnargs = {'batch_size':32,'max_iter':200,'lay':[('ip',256),('lrelu',),('batch',),('dropout',0.7), ('ip',128),('lrelu',),('batch',),('dropout',0.7)],'base_lr':0.0005,'optimizer':'adagrad','val_split':0.2,'monitor': 'val_loss','patience':10, 'stop': True}
Keras TF start  snn_pfa_bottles_3
Train DNN with Keras
Train on 3124 samples, validate on 781 samples
Epoch 1/200
 - 7s - loss: 1.1057 - acc: 0.7289 - val_loss: 0.6788 - val_acc: 0.9667
Epoch 2/200
 - 4s - loss: 0.7058 - acc: 0.8889 - val_loss: 0.4948 - val_acc: 0.9667
Epoch 3/200
 - 4s - loss: 0.5662 - acc: 0.9331 - val_loss: 0.4435 - val_acc: 0.9667
Epoch 4/200
 - 4s - loss: 0.4840 - acc: 0.9408 - val_loss: 0.3979 - val_acc: 0.9667
Epoch 5/200
 - 4s - loss: 0.4078 - acc: 0.9600 - val_loss: 0.3531 - val_acc: 0.9667
Epoch 6/200
 - 4s - loss: 0.3673 - acc: 0.9625 - val_loss: 0.3459 - val_acc: 0.9667
Epoch 7/200
 - 4s - loss: 0.3311 - acc: 0.9750 - val_loss: 0.2895 - val_acc: 0.9757
Epoch 8/200
 - 4s - loss: 0.3090 - acc: 0.9757 - val_loss: 0.3564 - val_acc: 0.9667
Epoch 9/200
 - 4s - loss: 0.2800 - acc: 0.9782 - val_loss: 0.2815 - val_acc: 0.9667
Epoch 10/200
 - 4s - loss: 0.2651 - acc: 0.9811 - val_loss: 0.2899 - val_acc: 0.9667
Epoch 11/200
 - 4s - loss: 0.2433 - acc: 0.9834 - val_loss: 0.2672 - val_acc: 0.9667
Epoch 12/200
 - 4s - loss: 0.2339 - acc: 0.9846 - val_loss: 0.2398 - val_acc: 0.9706
Epoch 13/200
 - 4s - loss: 0.2234 - acc: 0.9834 - val_loss: 0.2514 - val_acc: 0.9667
Epoch 14/200
 - 4s - loss: 0.2170 - acc: 0.9837 - val_loss: 0.2099 - val_acc: 0.9757
Epoch 15/200
 - 4s - loss: 0.1992 - acc: 0.9894 - val_loss: 0.2955 - val_acc: 0.9667
Epoch 16/200
 - 4s - loss: 0.1930 - acc: 0.9882 - val_loss: 0.2267 - val_acc: 0.9949
Epoch 17/200
 - 4s - loss: 0.1857 - acc: 0.9917 - val_loss: 0.1851 - val_acc: 0.9949
Epoch 18/200
 - 4s - loss: 0.1756 - acc: 0.9907 - val_loss: 0.2106 - val_acc: 0.9731
Epoch 19/200
 - 4s - loss: 0.1675 - acc: 0.9914 - val_loss: 0.2153 - val_acc: 0.9706
Epoch 20/200
 - 4s - loss: 0.1632 - acc: 0.9933 - val_loss: 0.1623 - val_acc: 0.9910
Epoch 21/200
 - 4s - loss: 0.1586 - acc: 0.9923 - val_loss: 0.1875 - val_acc: 0.9770
Epoch 22/200
 - 4s - loss: 0.1656 - acc: 0.9914 - val_loss: 0.1894 - val_acc: 0.9770
Epoch 23/200
 - 4s - loss: 0.1555 - acc: 0.9907 - val_loss: 0.1999 - val_acc: 0.9731
Epoch 24/200
 - 4s - loss: 0.1521 - acc: 0.9930 - val_loss: 0.1763 - val_acc: 0.9770
Epoch 25/200
 - 4s - loss: 0.1439 - acc: 0.9955 - val_loss: 0.1483 - val_acc: 0.9936
Epoch 26/200
 - 4s - loss: 0.1477 - acc: 0.9907 - val_loss: 0.1426 - val_acc: 0.9936
Epoch 27/200
 - 4s - loss: 0.1428 - acc: 0.9930 - val_loss: 0.1407 - val_acc: 0.9936
Epoch 28/200
 - 4s - loss: 0.1444 - acc: 0.9942 - val_loss: 0.1702 - val_acc: 0.9782
Epoch 29/200
 - 4s - loss: 0.1314 - acc: 0.9965 - val_loss: 0.2044 - val_acc: 0.9718
Epoch 30/200
 - 4s - loss: 0.1381 - acc: 0.9923 - val_loss: 0.1725 - val_acc: 0.9770
Epoch 31/200
 - 4s - loss: 0.1322 - acc: 0.9939 - val_loss: 0.1880 - val_acc: 0.9731
Epoch 32/200
 - 4s - loss: 0.1293 - acc: 0.9933 - val_loss: 0.1484 - val_acc: 0.9872
Epoch 33/200
 - 4s - loss: 0.1268 - acc: 0.9955 - val_loss: 0.1378 - val_acc: 0.9910
Epoch 34/200
 - 4s - loss: 0.1303 - acc: 0.9933 - val_loss: 0.1358 - val_acc: 0.9910
Epoch 35/200
 - 4s - loss: 0.1189 - acc: 0.9958 - val_loss: 0.1239 - val_acc: 0.9949
Epoch 36/200
 - 4s - loss: 0.1188 - acc: 0.9949 - val_loss: 0.2031 - val_acc: 0.9731
Epoch 37/200
 - 4s - loss: 0.1172 - acc: 0.9958 - val_loss: 0.1369 - val_acc: 0.9962
Epoch 38/200
 - 4s - loss: 0.1125 - acc: 0.9968 - val_loss: 0.1240 - val_acc: 0.9949
Epoch 39/200
 - 4s - loss: 0.1125 - acc: 0.9968 - val_loss: 0.1243 - val_acc: 0.9936
Epoch 40/200
 - 4s - loss: 0.1077 - acc: 0.9981 - val_loss: 0.1154 - val_acc: 0.9936
Epoch 41/200
 - 4s - loss: 0.1130 - acc: 0.9939 - val_loss: 0.2859 - val_acc: 0.9667
Epoch 42/200
 - 4s - loss: 0.1140 - acc: 0.9939 - val_loss: 0.2898 - val_acc: 0.9398
Epoch 43/200
 - 4s - loss: 0.1117 - acc: 0.9958 - val_loss: 0.2284 - val_acc: 0.9718
Epoch 44/200
 - 4s - loss: 0.1105 - acc: 0.9962 - val_loss: 0.1123 - val_acc: 0.9936
Epoch 45/200
 - 4s - loss: 0.1065 - acc: 0.9968 - val_loss: 0.1460 - val_acc: 0.9936
Epoch 46/200
 - 4s - loss: 0.1096 - acc: 0.9952 - val_loss: 0.1369 - val_acc: 0.9859
Epoch 47/200
 - 4s - loss: 0.1110 - acc: 0.9952 - val_loss: 0.1868 - val_acc: 0.9757
Epoch 48/200
 - 4s - loss: 0.1035 - acc: 0.9968 - val_loss: 0.1277 - val_acc: 0.9872
Epoch 49/200
 - 4s - loss: 0.1009 - acc: 0.9962 - val_loss: 0.1766 - val_acc: 0.9757
Epoch 50/200
 - 4s - loss: 0.1006 - acc: 0.9965 - val_loss: 0.1970 - val_acc: 0.9718
Epoch 51/200
 - 4s - loss: 0.0962 - acc: 0.9981 - val_loss: 0.1042 - val_acc: 0.9962
Epoch 52/200
 - 4s - loss: 0.0989 - acc: 0.9971 - val_loss: 0.1017 - val_acc: 0.9962
Epoch 53/200
 - 4s - loss: 0.1014 - acc: 0.9958 - val_loss: 0.1367 - val_acc: 0.9872
Epoch 54/200
 - 4s - loss: 0.0974 - acc: 0.9952 - val_loss: 0.1445 - val_acc: 0.9782
Epoch 55/200
 - 4s - loss: 0.0957 - acc: 0.9974 - val_loss: 0.1490 - val_acc: 0.9808
Epoch 56/200
 - 4s - loss: 0.0946 - acc: 0.9971 - val_loss: 0.0989 - val_acc: 0.9949
Epoch 57/200
 - 4s - loss: 0.0925 - acc: 0.9974 - val_loss: 0.1470 - val_acc: 0.9821
Epoch 58/200
 - 4s - loss: 0.0979 - acc: 0.9955 - val_loss: 0.0985 - val_acc: 0.9962
Epoch 59/200
 - 5s - loss: 0.0929 - acc: 0.9958 - val_loss: 0.1006 - val_acc: 0.9949
Epoch 60/200
 - 5s - loss: 0.0940 - acc: 0.9968 - val_loss: 0.1962 - val_acc: 0.9731
Epoch 61/200
 - 4s - loss: 0.0894 - acc: 0.9971 - val_loss: 0.1290 - val_acc: 0.9821
Epoch 62/200
 - 4s - loss: 0.0880 - acc: 0.9968 - val_loss: 0.0944 - val_acc: 0.9949
Epoch 63/200
 - 4s - loss: 0.0892 - acc: 0.9971 - val_loss: 0.1046 - val_acc: 0.9936
Epoch 64/200
 - 4s - loss: 0.0951 - acc: 0.9949 - val_loss: 0.1057 - val_acc: 0.9936
Epoch 65/200
 - 4s - loss: 0.0866 - acc: 0.9981 - val_loss: 0.1247 - val_acc: 0.9872
Epoch 66/200
 - 4s - loss: 0.0901 - acc: 0.9958 - val_loss: 0.0961 - val_acc: 0.9962
Epoch 67/200
 - 4s - loss: 0.0884 - acc: 0.9971 - val_loss: 0.0968 - val_acc: 0.9949
Epoch 68/200
 - 4s - loss: 0.0837 - acc: 0.9984 - val_loss: 0.1214 - val_acc: 0.9898
Epoch 69/200
 - 4s - loss: 0.0825 - acc: 0.9984 - val_loss: 0.1185 - val_acc: 0.9834
Epoch 70/200
 - 4s - loss: 0.0821 - acc: 0.9974 - val_loss: 0.1845 - val_acc: 0.9731
Epoch 71/200
 - 4s - loss: 0.0840 - acc: 0.9971 - val_loss: 0.1531 - val_acc: 0.9846
Epoch 72/200
 - 4s - loss: 0.0837 - acc: 0.9968 - val_loss: 0.0868 - val_acc: 0.9949
Epoch 73/200
 - 4s - loss: 0.0818 - acc: 0.9981 - val_loss: 0.1129 - val_acc: 0.9910
Epoch 74/200
 - 4s - loss: 0.0779 - acc: 0.9994 - val_loss: 0.1473 - val_acc: 0.9770
Epoch 75/200
 - 4s - loss: 0.0806 - acc: 0.9978 - val_loss: 0.0938 - val_acc: 0.9936
Epoch 76/200
 - 4s - loss: 0.0776 - acc: 0.9978 - val_loss: 0.1160 - val_acc: 0.9872
Epoch 77/200
 - 4s - loss: 0.0766 - acc: 0.9981 - val_loss: 0.0847 - val_acc: 0.9949
Epoch 78/200
 - 4s - loss: 0.0778 - acc: 0.9974 - val_loss: 0.0858 - val_acc: 0.9936
Epoch 79/200
 - 4s - loss: 0.0771 - acc: 0.9971 - val_loss: 0.1919 - val_acc: 0.9718
Epoch 80/200
 - 4s - loss: 0.0791 - acc: 0.9987 - val_loss: 0.0859 - val_acc: 0.9949
Epoch 81/200
 - 4s - loss: 0.0780 - acc: 0.9974 - val_loss: 0.0863 - val_acc: 0.9949
Epoch 82/200
 - 4s - loss: 0.0744 - acc: 0.9987 - val_loss: 0.1340 - val_acc: 0.9795
Epoch 83/200
 - 4s - loss: 0.0768 - acc: 0.9974 - val_loss: 0.2334 - val_acc: 0.9693
Epoch 84/200
 - 4s - loss: 0.0739 - acc: 0.9987 - val_loss: 0.0827 - val_acc: 0.9949
Epoch 85/200
 - 4s - loss: 0.0788 - acc: 0.9962 - val_loss: 0.1047 - val_acc: 0.9949
Epoch 86/200
 - 4s - loss: 0.0734 - acc: 0.9981 - val_loss: 0.0945 - val_acc: 0.9936
Epoch 87/200
 - 4s - loss: 0.0753 - acc: 0.9984 - val_loss: 0.1120 - val_acc: 0.9859
Epoch 88/200
 - 4s - loss: 0.0736 - acc: 0.9981 - val_loss: 0.0794 - val_acc: 0.9949
Epoch 89/200
 - 4s - loss: 0.0763 - acc: 0.9968 - val_loss: 0.0828 - val_acc: 0.9949
Epoch 90/200
 - 4s - loss: 0.0718 - acc: 0.9981 - val_loss: 0.1009 - val_acc: 0.9936
Epoch 91/200
 - 4s - loss: 0.0723 - acc: 0.9974 - val_loss: 0.0921 - val_acc: 0.9936
Epoch 92/200
 - 4s - loss: 0.0697 - acc: 0.9987 - val_loss: 0.0894 - val_acc: 0.9936
Epoch 93/200
 - 4s - loss: 0.0723 - acc: 0.9984 - val_loss: 0.0895 - val_acc: 0.9949
Epoch 94/200
 - 4s - loss: 0.0756 - acc: 0.9965 - val_loss: 0.0834 - val_acc: 0.9936
Epoch 95/200
 - 4s - loss: 0.0707 - acc: 0.9981 - val_loss: 0.1131 - val_acc: 0.9821
Epoch 96/200
 - 4s - loss: 0.0694 - acc: 0.9984 - val_loss: 0.1345 - val_acc: 0.9795
Epoch 97/200
 - 4s - loss: 0.0688 - acc: 0.9990 - val_loss: 0.1212 - val_acc: 0.9821
Epoch 98/200
 - 4s - loss: 0.0678 - acc: 0.9981 - val_loss: 0.1278 - val_acc: 0.9846
Restoring model weights from the end of the best epoch
Epoch 00098: early stopping
End-train DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Keras TF Training pfa_bottles_3: 3901/3905 99.9%
              precision    recall  f1-score   support

           B       1.00      0.96      0.98        96
           V       1.00      1.00      1.00      3809

    accuracy                           1.00      3905
   macro avg       1.00      0.98      0.99      3905
weighted avg       1.00      1.00      1.00      3905

Keras TF Testing pfa_bottles_3: 971/976 99.5%
              precision    recall  f1-score   support

           B       1.00      0.79      0.88        24
           V       0.99      1.00      1.00       952

    accuracy                           0.99       976
   macro avg       1.00      0.90      0.94       976
weighted avg       0.99      0.99      0.99       976

Keras TF CV pfa_bottles_3: 2507/2519 99.5%
              precision    recall  f1-score   support

           B       1.00      0.80      0.89        61
           V       1.00      1.00      1.00      2458

    accuracy                           1.00      2519
   macro avg       1.00      0.90      0.94      2519
weighted avg       1.00      1.00      0.99      2519

Keras TF stop snn_pfa_bottles_3
trnargs = {'batch_size':32,'max_iter':200,'lay':[('ip',128),('lrelu',),('batch',),('dropout',0.7), ('ip',64),('lrelu',),('batch',),('dropout',0.7)],'base_lr':0.0005,'optimizer':'adagrad','val_split':0.2,'monitor': 'val_loss','patience':10, 'stop': True}
Keras TF start  snn_sfa_bottles_3
Train DNN with Keras
Train on 3124 samples, validate on 781 samples
Epoch 1/200
 - 4s - loss: 1.0743 - acc: 0.6511 - val_loss: 0.6505 - val_acc: 0.9565
Epoch 2/200
 - 2s - loss: 0.7489 - acc: 0.8073 - val_loss: 0.4911 - val_acc: 0.9667
Epoch 3/200
 - 2s - loss: 0.6213 - acc: 0.8697 - val_loss: 0.4465 - val_acc: 0.9667
Epoch 4/200
 - 2s - loss: 0.5517 - acc: 0.9056 - val_loss: 0.4097 - val_acc: 0.9667
Epoch 5/200
 - 2s - loss: 0.5000 - acc: 0.9248 - val_loss: 0.3887 - val_acc: 0.9667
Epoch 6/200
 - 2s - loss: 0.4691 - acc: 0.9392 - val_loss: 0.3704 - val_acc: 0.9667
Epoch 7/200
 - 2s - loss: 0.4328 - acc: 0.9488 - val_loss: 0.3591 - val_acc: 0.9667
Epoch 8/200
 - 2s - loss: 0.4007 - acc: 0.9574 - val_loss: 0.3488 - val_acc: 0.9667
Epoch 9/200
 - 2s - loss: 0.3891 - acc: 0.9613 - val_loss: 0.3372 - val_acc: 0.9667
Epoch 10/200
 - 2s - loss: 0.3727 - acc: 0.9635 - val_loss: 0.3260 - val_acc: 0.9680
Epoch 11/200
 - 2s - loss: 0.3581 - acc: 0.9670 - val_loss: 0.3165 - val_acc: 0.9680
Epoch 12/200
 - 2s - loss: 0.3312 - acc: 0.9760 - val_loss: 0.3184 - val_acc: 0.9667
Epoch 13/200
 - 2s - loss: 0.3244 - acc: 0.9757 - val_loss: 0.3005 - val_acc: 0.9744
Epoch 14/200
 - 2s - loss: 0.3169 - acc: 0.9763 - val_loss: 0.2925 - val_acc: 0.9757
Epoch 15/200
 - 2s - loss: 0.2976 - acc: 0.9821 - val_loss: 0.2854 - val_acc: 0.9744
Epoch 16/200
 - 2s - loss: 0.2858 - acc: 0.9814 - val_loss: 0.2787 - val_acc: 0.9744
Epoch 17/200
 - 2s - loss: 0.2899 - acc: 0.9792 - val_loss: 0.2731 - val_acc: 0.9744
Epoch 18/200
 - 2s - loss: 0.2700 - acc: 0.9856 - val_loss: 0.2627 - val_acc: 0.9795
Epoch 19/200
 - 2s - loss: 0.2695 - acc: 0.9846 - val_loss: 0.2628 - val_acc: 0.9770
Epoch 20/200
 - 2s - loss: 0.2606 - acc: 0.9856 - val_loss: 0.2495 - val_acc: 0.9834
Epoch 21/200
 - 2s - loss: 0.2470 - acc: 0.9901 - val_loss: 0.2548 - val_acc: 0.9782
Epoch 22/200
 - 2s - loss: 0.2403 - acc: 0.9894 - val_loss: 0.2375 - val_acc: 0.9846
Epoch 23/200
 - 2s - loss: 0.2400 - acc: 0.9888 - val_loss: 0.2476 - val_acc: 0.9770
Epoch 24/200
 - 2s - loss: 0.2352 - acc: 0.9898 - val_loss: 0.2349 - val_acc: 0.9846
Epoch 25/200
 - 2s - loss: 0.2280 - acc: 0.9901 - val_loss: 0.2399 - val_acc: 0.9795
Epoch 26/200
 - 2s - loss: 0.2297 - acc: 0.9869 - val_loss: 0.2320 - val_acc: 0.9808
Epoch 27/200
 - 2s - loss: 0.2205 - acc: 0.9878 - val_loss: 0.2243 - val_acc: 0.9821
Epoch 28/200
 - 2s - loss: 0.2135 - acc: 0.9910 - val_loss: 0.2212 - val_acc: 0.9821
Epoch 29/200
 - 2s - loss: 0.2076 - acc: 0.9926 - val_loss: 0.2149 - val_acc: 0.9859
Epoch 30/200
 - 2s - loss: 0.2044 - acc: 0.9904 - val_loss: 0.2113 - val_acc: 0.9872
Epoch 31/200
 - 2s - loss: 0.2036 - acc: 0.9914 - val_loss: 0.2044 - val_acc: 0.9872
Epoch 32/200
 - 2s - loss: 0.1931 - acc: 0.9942 - val_loss: 0.2083 - val_acc: 0.9859
Epoch 33/200
 - 2s - loss: 0.1909 - acc: 0.9917 - val_loss: 0.2052 - val_acc: 0.9859
Epoch 34/200
 - 2s - loss: 0.1863 - acc: 0.9939 - val_loss: 0.1936 - val_acc: 0.9885
Epoch 35/200
 - 2s - loss: 0.1875 - acc: 0.9930 - val_loss: 0.2026 - val_acc: 0.9821
Epoch 36/200
 - 2s - loss: 0.1820 - acc: 0.9917 - val_loss: 0.1913 - val_acc: 0.9859
Epoch 37/200
 - 2s - loss: 0.1812 - acc: 0.9930 - val_loss: 0.1904 - val_acc: 0.9846
Epoch 38/200
 - 2s - loss: 0.1743 - acc: 0.9936 - val_loss: 0.1911 - val_acc: 0.9834
Epoch 39/200
 - 2s - loss: 0.1728 - acc: 0.9949 - val_loss: 0.1840 - val_acc: 0.9859
Epoch 40/200
 - 2s - loss: 0.1707 - acc: 0.9914 - val_loss: 0.1819 - val_acc: 0.9846
Epoch 41/200
 - 2s - loss: 0.1649 - acc: 0.9962 - val_loss: 0.1876 - val_acc: 0.9821
Epoch 42/200
 - 2s - loss: 0.1645 - acc: 0.9930 - val_loss: 0.1752 - val_acc: 0.9872
Epoch 43/200
 - 2s - loss: 0.1596 - acc: 0.9955 - val_loss: 0.1731 - val_acc: 0.9872
Epoch 44/200
 - 2s - loss: 0.1575 - acc: 0.9949 - val_loss: 0.1617 - val_acc: 0.9936
Epoch 45/200
 - 2s - loss: 0.1563 - acc: 0.9946 - val_loss: 0.1643 - val_acc: 0.9885
Epoch 46/200
 - 2s - loss: 0.1515 - acc: 0.9965 - val_loss: 0.1668 - val_acc: 0.9859
Epoch 47/200
 - 2s - loss: 0.1490 - acc: 0.9949 - val_loss: 0.1692 - val_acc: 0.9859
Epoch 48/200
 - 2s - loss: 0.1488 - acc: 0.9949 - val_loss: 0.1722 - val_acc: 0.9846
Epoch 49/200
 - 2s - loss: 0.1493 - acc: 0.9946 - val_loss: 0.1544 - val_acc: 0.9923
Epoch 50/200
 - 2s - loss: 0.1444 - acc: 0.9949 - val_loss: 0.1621 - val_acc: 0.9846
Epoch 51/200
 - 2s - loss: 0.1411 - acc: 0.9974 - val_loss: 0.1642 - val_acc: 0.9846
Epoch 52/200
 - 2s - loss: 0.1389 - acc: 0.9962 - val_loss: 0.1726 - val_acc: 0.9808
Epoch 53/200
 - 2s - loss: 0.1407 - acc: 0.9936 - val_loss: 0.1683 - val_acc: 0.9821
Epoch 54/200
 - 2s - loss: 0.1418 - acc: 0.9936 - val_loss: 0.1593 - val_acc: 0.9846
Epoch 55/200
 - 2s - loss: 0.1294 - acc: 0.9984 - val_loss: 0.1551 - val_acc: 0.9859
Epoch 56/200
 - 2s - loss: 0.1315 - acc: 0.9968 - val_loss: 0.1542 - val_acc: 0.9859
Epoch 57/200
 - 2s - loss: 0.1297 - acc: 0.9965 - val_loss: 0.1480 - val_acc: 0.9898
Epoch 58/200
 - 2s - loss: 0.1281 - acc: 0.9974 - val_loss: 0.1473 - val_acc: 0.9872
Epoch 59/200
 - 2s - loss: 0.1262 - acc: 0.9971 - val_loss: 0.1467 - val_acc: 0.9859
Epoch 60/200
 - 2s - loss: 0.1257 - acc: 0.9952 - val_loss: 0.1422 - val_acc: 0.9885
Epoch 61/200
 - 2s - loss: 0.1240 - acc: 0.9968 - val_loss: 0.1440 - val_acc: 0.9859
Epoch 62/200
 - 2s - loss: 0.1182 - acc: 0.9984 - val_loss: 0.1412 - val_acc: 0.9846
Epoch 63/200
 - 2s - loss: 0.1189 - acc: 0.9984 - val_loss: 0.1366 - val_acc: 0.9898
Epoch 64/200
 - 2s - loss: 0.1153 - acc: 0.9981 - val_loss: 0.1415 - val_acc: 0.9846
Epoch 65/200
 - 2s - loss: 0.1173 - acc: 0.9971 - val_loss: 0.1389 - val_acc: 0.9846
Epoch 66/200
 - 2s - loss: 0.1148 - acc: 0.9968 - val_loss: 0.1414 - val_acc: 0.9846
Epoch 67/200
 - 2s - loss: 0.1131 - acc: 0.9981 - val_loss: 0.1380 - val_acc: 0.9872
Epoch 68/200
 - 2s - loss: 0.1100 - acc: 0.9990 - val_loss: 0.1360 - val_acc: 0.9872
Epoch 69/200
 - 2s - loss: 0.1078 - acc: 0.9987 - val_loss: 0.1359 - val_acc: 0.9846
Epoch 70/200
 - 2s - loss: 0.1053 - acc: 0.9994 - val_loss: 0.1386 - val_acc: 0.9846
Epoch 71/200
 - 2s - loss: 0.1079 - acc: 0.9968 - val_loss: 0.1351 - val_acc: 0.9846
Epoch 72/200
 - 2s - loss: 0.1048 - acc: 0.9981 - val_loss: 0.1413 - val_acc: 0.9846
Epoch 73/200
 - 2s - loss: 0.1048 - acc: 0.9974 - val_loss: 0.1318 - val_acc: 0.9872
Epoch 74/200
 - 2s - loss: 0.1025 - acc: 0.9981 - val_loss: 0.1346 - val_acc: 0.9846
Epoch 75/200
 - 2s - loss: 0.1028 - acc: 0.9965 - val_loss: 0.1305 - val_acc: 0.9859
Epoch 76/200
 - 2s - loss: 0.1001 - acc: 0.9974 - val_loss: 0.1242 - val_acc: 0.9898
Epoch 77/200
 - 2s - loss: 0.1027 - acc: 0.9968 - val_loss: 0.1240 - val_acc: 0.9872
Epoch 78/200
 - 2s - loss: 0.1010 - acc: 0.9958 - val_loss: 0.1169 - val_acc: 0.9910
Epoch 79/200
 - 2s - loss: 0.0957 - acc: 0.9990 - val_loss: 0.1196 - val_acc: 0.9898
Epoch 80/200
 - 2s - loss: 0.0971 - acc: 0.9978 - val_loss: 0.1242 - val_acc: 0.9872
Epoch 81/200
 - 2s - loss: 0.0965 - acc: 0.9978 - val_loss: 0.1204 - val_acc: 0.9885
Epoch 82/200
 - 2s - loss: 0.0908 - acc: 0.9997 - val_loss: 0.1151 - val_acc: 0.9910
Epoch 83/200
 - 2s - loss: 0.0929 - acc: 0.9978 - val_loss: 0.1187 - val_acc: 0.9898
Epoch 84/200
 - 2s - loss: 0.0927 - acc: 0.9978 - val_loss: 0.1120 - val_acc: 0.9910
Epoch 85/200
 - 2s - loss: 0.0890 - acc: 0.9990 - val_loss: 0.1165 - val_acc: 0.9898
Epoch 86/200
 - 2s - loss: 0.0900 - acc: 0.9981 - val_loss: 0.1247 - val_acc: 0.9859
Epoch 87/200
 - 2s - loss: 0.0903 - acc: 0.9981 - val_loss: 0.1157 - val_acc: 0.9898
Epoch 88/200
 - 2s - loss: 0.0878 - acc: 0.9978 - val_loss: 0.1131 - val_acc: 0.9885
Epoch 89/200
 - 2s - loss: 0.0873 - acc: 0.9965 - val_loss: 0.1111 - val_acc: 0.9898
Epoch 90/200
 - 2s - loss: 0.0845 - acc: 0.9994 - val_loss: 0.1060 - val_acc: 0.9910
Epoch 91/200
 - 2s - loss: 0.0854 - acc: 0.9971 - val_loss: 0.1085 - val_acc: 0.9910
Epoch 92/200
 - 2s - loss: 0.0841 - acc: 0.9981 - val_loss: 0.1099 - val_acc: 0.9898
Epoch 93/200
 - 2s - loss: 0.0848 - acc: 0.9978 - val_loss: 0.1040 - val_acc: 0.9923
Epoch 94/200
 - 2s - loss: 0.0842 - acc: 0.9968 - val_loss: 0.1054 - val_acc: 0.9898
Epoch 95/200
 - 2s - loss: 0.0820 - acc: 0.9984 - val_loss: 0.1080 - val_acc: 0.9898
Epoch 96/200
 - 2s - loss: 0.0806 - acc: 0.9981 - val_loss: 0.1052 - val_acc: 0.9910
Epoch 97/200
 - 2s - loss: 0.0786 - acc: 0.9994 - val_loss: 0.1103 - val_acc: 0.9898
Epoch 98/200
 - 2s - loss: 0.0791 - acc: 0.9990 - val_loss: 0.1028 - val_acc: 0.9910
Epoch 99/200
 - 2s - loss: 0.0813 - acc: 0.9974 - val_loss: 0.0992 - val_acc: 0.9910
Epoch 100/200
 - 2s - loss: 0.0778 - acc: 0.9994 - val_loss: 0.1031 - val_acc: 0.9910
Epoch 101/200
 - 2s - loss: 0.0786 - acc: 0.9981 - val_loss: 0.1148 - val_acc: 0.9859
Epoch 102/200
 - 2s - loss: 0.0762 - acc: 0.9984 - val_loss: 0.1137 - val_acc: 0.9859
Epoch 103/200
 - 2s - loss: 0.0757 - acc: 0.9984 - val_loss: 0.1143 - val_acc: 0.9872
Epoch 104/200
 - 2s - loss: 0.0756 - acc: 0.9987 - val_loss: 0.1071 - val_acc: 0.9885
Epoch 105/200
 - 2s - loss: 0.0737 - acc: 0.9990 - val_loss: 0.1083 - val_acc: 0.9872
Epoch 106/200
 - 2s - loss: 0.0728 - acc: 0.9987 - val_loss: 0.0978 - val_acc: 0.9923
Epoch 107/200
 - 2s - loss: 0.0716 - acc: 0.9990 - val_loss: 0.1031 - val_acc: 0.9885
Epoch 108/200
 - 2s - loss: 0.0723 - acc: 0.9978 - val_loss: 0.1102 - val_acc: 0.9846
Epoch 109/200
 - 2s - loss: 0.0723 - acc: 0.9984 - val_loss: 0.1026 - val_acc: 0.9885
Epoch 110/200
 - 2s - loss: 0.0689 - acc: 0.9997 - val_loss: 0.0971 - val_acc: 0.9910
Epoch 111/200
 - 2s - loss: 0.0693 - acc: 0.9990 - val_loss: 0.0971 - val_acc: 0.9910
Epoch 112/200
 - 2s - loss: 0.0676 - acc: 0.9987 - val_loss: 0.0993 - val_acc: 0.9910
Epoch 113/200
 - 2s - loss: 0.0681 - acc: 0.9990 - val_loss: 0.1012 - val_acc: 0.9898
Epoch 114/200
 - 2s - loss: 0.0686 - acc: 0.9987 - val_loss: 0.0898 - val_acc: 0.9923
Epoch 115/200
 - 2s - loss: 0.0673 - acc: 0.9987 - val_loss: 0.0944 - val_acc: 0.9923
Epoch 116/200
 - 2s - loss: 0.0649 - acc: 0.9994 - val_loss: 0.0952 - val_acc: 0.9910
Epoch 117/200
 - 2s - loss: 0.0658 - acc: 0.9990 - val_loss: 0.0957 - val_acc: 0.9898
Epoch 118/200
 - 2s - loss: 0.0674 - acc: 0.9968 - val_loss: 0.0868 - val_acc: 0.9923
Epoch 119/200
 - 2s - loss: 0.0659 - acc: 0.9984 - val_loss: 0.0923 - val_acc: 0.9910
Epoch 120/200
 - 2s - loss: 0.0637 - acc: 0.9994 - val_loss: 0.0931 - val_acc: 0.9910
Epoch 121/200
 - 2s - loss: 0.0631 - acc: 0.9994 - val_loss: 0.0847 - val_acc: 0.9923
Epoch 122/200
 - 2s - loss: 0.0622 - acc: 1.0000 - val_loss: 0.0900 - val_acc: 0.9910
Epoch 123/200
 - 2s - loss: 0.0650 - acc: 0.9981 - val_loss: 0.0905 - val_acc: 0.9898
Epoch 124/200
 - 2s - loss: 0.0618 - acc: 0.9990 - val_loss: 0.0845 - val_acc: 0.9923
Epoch 125/200
 - 2s - loss: 0.0622 - acc: 0.9990 - val_loss: 0.0944 - val_acc: 0.9898
Epoch 126/200
 - 2s - loss: 0.0608 - acc: 0.9997 - val_loss: 0.0942 - val_acc: 0.9898
Epoch 127/200
 - 2s - loss: 0.0604 - acc: 0.9994 - val_loss: 0.0921 - val_acc: 0.9898
Epoch 128/200
 - 2s - loss: 0.0600 - acc: 0.9997 - val_loss: 0.0934 - val_acc: 0.9898
Epoch 129/200
 - 2s - loss: 0.0612 - acc: 0.9984 - val_loss: 0.0902 - val_acc: 0.9910
Epoch 130/200
 - 2s - loss: 0.0610 - acc: 0.9978 - val_loss: 0.1022 - val_acc: 0.9846
Epoch 131/200
 - 2s - loss: 0.0592 - acc: 0.9984 - val_loss: 0.0941 - val_acc: 0.9898
Epoch 132/200
 - 2s - loss: 0.0568 - acc: 0.9997 - val_loss: 0.0908 - val_acc: 0.9898
Epoch 133/200
 - 2s - loss: 0.0579 - acc: 0.9987 - val_loss: 0.0950 - val_acc: 0.9885
Epoch 134/200
 - 2s - loss: 0.0569 - acc: 0.9997 - val_loss: 0.0921 - val_acc: 0.9885
Restoring model weights from the end of the best epoch
Epoch 00134: early stopping
End-train DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Keras TF Training sfa_bottles_3: 3899/3905 99.8%
              precision    recall  f1-score   support

           B       1.00      0.94      0.97        96
           V       1.00      1.00      1.00      3809

    accuracy                           1.00      3905
   macro avg       1.00      0.97      0.98      3905
weighted avg       1.00      1.00      1.00      3905

Keras TF Testing sfa_bottles_3: 968/976 99.2%
              precision    recall  f1-score   support

           B       0.94      0.71      0.81        24
           V       0.99      1.00      1.00       952

    accuracy                           0.99       976
   macro avg       0.97      0.85      0.90       976
weighted avg       0.99      0.99      0.99       976

Keras TF CV sfa_bottles_3: 2486/2519 98.7%
              precision    recall  f1-score   support

           B       0.97      0.48      0.64        61
           V       0.99      1.00      0.99      2458

    accuracy                           0.99      2519
   macro avg       0.98      0.74      0.82      2519
weighted avg       0.99      0.99      0.98      2519

Keras TF stop snn_sfa_bottles_3
trnargs = {'batch_size':64,'max_iter':200,'lay':[('conv1d',16,64,2),('relu',),('batch',),('pool',8,8),('conv1d',32,32,2),('relu',),('batch',),('pool',8,8),('conv1d',64,16,8),('relu',),('batch',),('conv1d',128,8,2),('relu',),('batch',),('conv1d',256,4,2),('relu',),('batch',),('pool',4,4),('flatten',),('ip',64),('relu',),('dropout',0.25),('ip',32),('relu',),('dropout',0.25)],'base_lr':0.0005, 'optimizer':'adadelta','val_split':0.2,'monitor': 'val_loss','patience':15, 'stop': True}
Keras TF start  cnn_sig_bottles_3
Train DNN with Keras
Train on 3124 samples, validate on 781 samples
Epoch 1/200
 - 155s - loss: 0.3891 - acc: 0.9609 - val_loss: 0.4104 - val_acc: 0.9667
Epoch 2/200
 - 178s - loss: 0.3413 - acc: 0.9773 - val_loss: 0.4044 - val_acc: 0.9667
Epoch 3/200
 - 261s - loss: 0.3172 - acc: 0.9757 - val_loss: 0.3803 - val_acc: 0.9667
Epoch 4/200
 - 260s - loss: 0.2882 - acc: 0.9779 - val_loss: 0.4816 - val_acc: 0.9667
Epoch 5/200
 - 251s - loss: 0.2738 - acc: 0.9763 - val_loss: 0.5312 - val_acc: 0.9667
Epoch 6/200
 - 281s - loss: 0.2556 - acc: 0.9814 - val_loss: 0.4711 - val_acc: 0.9667
Epoch 7/200
 - 272s - loss: 0.2234 - acc: 0.9904 - val_loss: 0.4830 - val_acc: 0.9667
Epoch 8/200
 - 273s - loss: 0.2124 - acc: 0.9891 - val_loss: 0.3111 - val_acc: 0.9667
Epoch 9/200
 - 282s - loss: 0.1976 - acc: 0.9917 - val_loss: 0.3465 - val_acc: 0.9667
Epoch 10/200
 - 293s - loss: 0.1739 - acc: 0.9949 - val_loss: 0.3422 - val_acc: 0.9667
Epoch 11/200
 - 287s - loss: 0.1661 - acc: 0.9962 - val_loss: 0.2819 - val_acc: 0.9846
Epoch 12/200
 - 286s - loss: 0.1583 - acc: 0.9955 - val_loss: 0.2960 - val_acc: 0.9846
Epoch 13/200
 - 274s - loss: 0.1466 - acc: 0.9955 - val_loss: 0.2551 - val_acc: 0.9667
Epoch 14/200
 - 272s - loss: 0.1382 - acc: 0.9952 - val_loss: 0.1903 - val_acc: 0.9821
Epoch 15/200
 - 280s - loss: 0.1371 - acc: 0.9952 - val_loss: 0.4355 - val_acc: 0.9680
Epoch 16/200
 - 258s - loss: 0.1161 - acc: 0.9994 - val_loss: 0.2412 - val_acc: 0.9846
Epoch 17/200
 - 268s - loss: 0.1073 - acc: 0.9994 - val_loss: 0.2430 - val_acc: 0.9782
Epoch 18/200
 - 256s - loss: 0.1023 - acc: 0.9984 - val_loss: 0.2653 - val_acc: 0.9782
Epoch 19/200
 - 260s - loss: 0.0916 - acc: 0.9997 - val_loss: 0.2034 - val_acc: 0.9859
Epoch 20/200
 - 264s - loss: 0.0844 - acc: 1.0000 - val_loss: 0.2111 - val_acc: 0.9859
Epoch 21/200
 - 259s - loss: 0.1048 - acc: 0.9933 - val_loss: 0.2596 - val_acc: 0.9296
Epoch 22/200
 - 275s - loss: 0.0808 - acc: 0.9984 - val_loss: 0.2195 - val_acc: 0.9501
Epoch 23/200
 - 222s - loss: 0.0795 - acc: 0.9978 - val_loss: 0.1565 - val_acc: 0.9872
Epoch 24/200
 - 156s - loss: 0.0768 - acc: 0.9974 - val_loss: 0.1828 - val_acc: 0.9872
Epoch 25/200
 - 162s - loss: 0.0647 - acc: 1.0000 - val_loss: 0.1260 - val_acc: 0.9872
Epoch 26/200
 - 162s - loss: 0.0597 - acc: 1.0000 - val_loss: 0.1419 - val_acc: 0.9885
Epoch 27/200
 - 157s - loss: 0.0573 - acc: 0.9990 - val_loss: 0.1815 - val_acc: 0.9885
Epoch 28/200
 - 159s - loss: 0.0699 - acc: 0.9968 - val_loss: 0.3735 - val_acc: 0.9731
Epoch 29/200
 - 159s - loss: 0.0611 - acc: 0.9981 - val_loss: 0.1728 - val_acc: 0.9782
Epoch 30/200
 - 157s - loss: 0.0482 - acc: 1.0000 - val_loss: 0.1510 - val_acc: 0.9846
Epoch 31/200
 - 157s - loss: 0.0454 - acc: 0.9997 - val_loss: 0.1909 - val_acc: 0.9859
Epoch 32/200
 - 156s - loss: 0.0422 - acc: 1.0000 - val_loss: 0.1479 - val_acc: 0.9885
Epoch 33/200
 - 157s - loss: 0.0419 - acc: 0.9990 - val_loss: 0.2016 - val_acc: 0.9846
Epoch 34/200
 - 161s - loss: 0.0396 - acc: 0.9990 - val_loss: 0.2123 - val_acc: 0.9846
Epoch 35/200
 - 160s - loss: 0.0394 - acc: 0.9994 - val_loss: 0.1444 - val_acc: 0.9846
Epoch 36/200
 - 161s - loss: 0.0440 - acc: 0.9974 - val_loss: 0.1605 - val_acc: 0.9872
Epoch 37/200
 - 159s - loss: 0.0406 - acc: 0.9974 - val_loss: 0.1397 - val_acc: 0.9821
Epoch 38/200
 - 161s - loss: 0.0326 - acc: 1.0000 - val_loss: 0.1898 - val_acc: 0.9834
Epoch 39/200
 - 157s - loss: 0.0348 - acc: 0.9987 - val_loss: 0.1697 - val_acc: 0.9859
Epoch 40/200
 - 154s - loss: 0.0299 - acc: 0.9994 - val_loss: 0.1421 - val_acc: 0.9885
Restoring model weights from the end of the best epoch
Epoch 00040: early stopping
End-train DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Keras TF Training sig_bottles_3: 3895/3905 99.7%
              precision    recall  f1-score   support

           B       0.99      0.91      0.95        96
           V       1.00      1.00      1.00      3809

    accuracy                           1.00      3905
   macro avg       0.99      0.95      0.97      3905
weighted avg       1.00      1.00      1.00      3905

Keras TF Testing sig_bottles_3: 967/976 99.1%
              precision    recall  f1-score   support

           B       0.83      0.79      0.81        24
           V       0.99      1.00      1.00       952

    accuracy                           0.99       976
   macro avg       0.91      0.89      0.90       976
weighted avg       0.99      0.99      0.99       976

Keras TF CV sig_bottles_3: 2471/2519 98.1%
              precision    recall  f1-score   support

           B       0.62      0.56      0.59        61
           V       0.99      0.99      0.99      2458

    accuracy                           0.98      2519
   macro avg       0.80      0.77      0.79      2519
weighted avg       0.98      0.98      0.98      2519

Keras TF stop cnn_sig_bottles_3
trnargs = {'batch_size':32,'max_iter':200,'lay':[('conv2d',32,[5,5],[2,2]),('elu',),('batch',),('dropout',0.1),('pool',[2,2],[2,2]),('conv2d',32,[5,5],[2,2]),('elu',),('batch',),('dropout',0.1),('pool',[2,2],[2,2]),('flatten',),('ip',90),('relu',),('dropout',0.7)],'base_lr':0.0005, 'optimizer':'adadelta','val_split':0.2,'monitor': 'val_loss','patience':15, 'stop': True}
Keras TF start  cnn_pfa_bottles_3
Train DNN with Keras
Train on 3124 samples, validate on 781 samples
Epoch 1/200
 - 16s - loss: 0.2717 - acc: 0.9680 - val_loss: 0.3089 - val_acc: 0.9667
Epoch 2/200
 - 13s - loss: 0.2248 - acc: 0.9757 - val_loss: 0.2642 - val_acc: 0.9667
Epoch 3/200
 - 14s - loss: 0.1879 - acc: 0.9744 - val_loss: 0.1741 - val_acc: 0.9667
Epoch 4/200
 - 14s - loss: 0.1151 - acc: 0.9866 - val_loss: 0.1253 - val_acc: 0.9834
Epoch 5/200
 - 13s - loss: 0.0981 - acc: 0.9923 - val_loss: 0.0983 - val_acc: 0.9923
Epoch 6/200
 - 13s - loss: 0.0854 - acc: 0.9946 - val_loss: 0.0747 - val_acc: 0.9962
Epoch 7/200
 - 13s - loss: 0.0695 - acc: 0.9978 - val_loss: 0.0625 - val_acc: 0.9962
Epoch 8/200
 - 14s - loss: 0.0651 - acc: 0.9971 - val_loss: 0.0695 - val_acc: 0.9923
Epoch 9/200
 - 13s - loss: 0.0637 - acc: 0.9965 - val_loss: 0.0497 - val_acc: 0.9987
Epoch 10/200
 - 13s - loss: 0.0471 - acc: 0.9994 - val_loss: 0.0568 - val_acc: 0.9974
Epoch 11/200
 - 13s - loss: 0.0466 - acc: 0.9981 - val_loss: 0.0417 - val_acc: 0.9987
Epoch 12/200
 - 13s - loss: 0.0431 - acc: 0.9984 - val_loss: 0.3882 - val_acc: 0.9001
Epoch 13/200
 - 14s - loss: 0.0360 - acc: 0.9994 - val_loss: 0.0345 - val_acc: 0.9987
Epoch 14/200
 - 14s - loss: 0.0322 - acc: 0.9994 - val_loss: 0.0290 - val_acc: 1.0000
Epoch 15/200
 - 14s - loss: 0.0344 - acc: 0.9984 - val_loss: 0.0332 - val_acc: 0.9974
Epoch 16/200
 - 19s - loss: 0.0302 - acc: 0.9981 - val_loss: 0.0267 - val_acc: 0.9987
Epoch 17/200
 - 26s - loss: 0.0256 - acc: 0.9994 - val_loss: 0.0228 - val_acc: 1.0000
Epoch 18/200
 - 26s - loss: 0.0252 - acc: 0.9990 - val_loss: 0.4091 - val_acc: 0.9142
Epoch 19/200
 - 26s - loss: 0.0215 - acc: 0.9994 - val_loss: 0.0538 - val_acc: 0.9962
Epoch 20/200
 - 27s - loss: 0.0229 - acc: 0.9978 - val_loss: 0.0210 - val_acc: 0.9987
Epoch 21/200
 - 26s - loss: 0.0248 - acc: 0.9974 - val_loss: 0.0191 - val_acc: 0.9987
Epoch 22/200
 - 27s - loss: 0.0178 - acc: 0.9990 - val_loss: 0.0320 - val_acc: 0.9962
Epoch 23/200
 - 28s - loss: 0.0164 - acc: 0.9994 - val_loss: 0.0683 - val_acc: 0.9910
Epoch 24/200
 - 25s - loss: 0.0149 - acc: 0.9997 - val_loss: 0.0162 - val_acc: 0.9987
Epoch 25/200
 - 24s - loss: 0.0160 - acc: 0.9987 - val_loss: 0.0167 - val_acc: 0.9987
Epoch 26/200
 - 29s - loss: 0.0123 - acc: 1.0000 - val_loss: 0.0173 - val_acc: 0.9974
Epoch 27/200
 - 28s - loss: 0.0153 - acc: 0.9990 - val_loss: 0.0525 - val_acc: 0.9936
Epoch 28/200
 - 21s - loss: 0.0122 - acc: 0.9987 - val_loss: 0.0175 - val_acc: 0.9974
Epoch 29/200
 - 21s - loss: 0.0096 - acc: 1.0000 - val_loss: 0.0687 - val_acc: 0.9821
Epoch 30/200
 - 22s - loss: 0.0178 - acc: 0.9974 - val_loss: 0.0144 - val_acc: 0.9974
Epoch 31/200
 - 23s - loss: 0.0104 - acc: 0.9997 - val_loss: 0.0165 - val_acc: 0.9974
Epoch 32/200
 - 23s - loss: 0.0080 - acc: 1.0000 - val_loss: 0.0086 - val_acc: 0.9987
Epoch 33/200
 - 23s - loss: 0.0073 - acc: 1.0000 - val_loss: 0.0090 - val_acc: 0.9987
Epoch 34/200
 - 23s - loss: 0.0065 - acc: 1.0000 - val_loss: 0.0160 - val_acc: 0.9974
Epoch 35/200
 - 23s - loss: 0.0126 - acc: 0.9984 - val_loss: 0.0827 - val_acc: 0.9898
Epoch 36/200
 - 17s - loss: 0.0107 - acc: 0.9987 - val_loss: 0.0264 - val_acc: 0.9962
Epoch 37/200
 - 15s - loss: 0.0068 - acc: 0.9994 - val_loss: 0.0998 - val_acc: 0.9718
Epoch 38/200
 - 15s - loss: 0.0059 - acc: 1.0000 - val_loss: 0.0370 - val_acc: 0.9949
Epoch 39/200
 - 14s - loss: 0.0090 - acc: 0.9994 - val_loss: 0.0206 - val_acc: 0.9962
Epoch 40/200
 - 14s - loss: 0.0085 - acc: 0.9994 - val_loss: 0.0137 - val_acc: 0.9974
Epoch 41/200
 - 14s - loss: 0.0092 - acc: 0.9987 - val_loss: 0.0231 - val_acc: 0.9974
Epoch 42/200
 - 14s - loss: 0.0065 - acc: 0.9994 - val_loss: 0.0474 - val_acc: 0.9936
Epoch 43/200
 - 14s - loss: 0.0075 - acc: 0.9997 - val_loss: 0.0206 - val_acc: 0.9962
Epoch 44/200
 - 14s - loss: 0.0098 - acc: 0.9994 - val_loss: 0.0123 - val_acc: 0.9974
Epoch 45/200
 - 14s - loss: 0.0050 - acc: 0.9997 - val_loss: 0.0047 - val_acc: 1.0000
Epoch 46/200
 - 14s - loss: 0.0098 - acc: 0.9981 - val_loss: 0.0568 - val_acc: 0.9936
Epoch 47/200
 - 15s - loss: 0.0153 - acc: 0.9971 - val_loss: 0.0202 - val_acc: 0.9962
Epoch 48/200
 - 15s - loss: 0.0050 - acc: 0.9997 - val_loss: 0.0176 - val_acc: 0.9974
Epoch 49/200
 - 15s - loss: 0.0045 - acc: 0.9997 - val_loss: 0.0214 - val_acc: 0.9962
Epoch 50/200
 - 15s - loss: 0.0053 - acc: 0.9997 - val_loss: 0.0190 - val_acc: 0.9962
Epoch 51/200
 - 15s - loss: 0.0082 - acc: 0.9987 - val_loss: 0.0347 - val_acc: 0.9949
Epoch 52/200
 - 15s - loss: 0.0049 - acc: 0.9997 - val_loss: 0.0736 - val_acc: 0.9898
Epoch 53/200
 - 15s - loss: 0.0089 - acc: 0.9994 - val_loss: 0.0510 - val_acc: 0.9923
Epoch 54/200
 - 15s - loss: 0.0060 - acc: 0.9990 - val_loss: 0.0098 - val_acc: 0.9974
Epoch 55/200
 - 14s - loss: 0.0075 - acc: 0.9990 - val_loss: 0.0066 - val_acc: 0.9987
Epoch 56/200
 - 14s - loss: 0.0067 - acc: 0.9987 - val_loss: 0.0240 - val_acc: 0.9962
Epoch 57/200
 - 14s - loss: 0.0082 - acc: 0.9994 - val_loss: 0.0134 - val_acc: 0.9974
Epoch 58/200
 - 14s - loss: 0.0063 - acc: 0.9994 - val_loss: 0.0249 - val_acc: 0.9949
Epoch 59/200
 - 14s - loss: 0.0046 - acc: 0.9997 - val_loss: 0.0067 - val_acc: 1.0000
Epoch 60/200
 - 14s - loss: 0.0050 - acc: 0.9987 - val_loss: 0.0612 - val_acc: 0.9923
Restoring model weights from the end of the best epoch
Epoch 00060: early stopping
End-train DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Keras TF Training pfa_bottles_3: 3905/3905 100.0%
              precision    recall  f1-score   support

           B       1.00      1.00      1.00        96
           V       1.00      1.00      1.00      3809

    accuracy                           1.00      3905
   macro avg       1.00      1.00      1.00      3905
weighted avg       1.00      1.00      1.00      3905

Keras TF Testing pfa_bottles_3: 975/976 99.9%
              precision    recall  f1-score   support

           B       1.00      0.96      0.98        24
           V       1.00      1.00      1.00       952

    accuracy                           1.00       976
   macro avg       1.00      0.98      0.99       976
weighted avg       1.00      1.00      1.00       976

Keras TF CV pfa_bottles_3: 2509/2519 99.6%
              precision    recall  f1-score   support

           B       0.98      0.85      0.91        61
           V       1.00      1.00      1.00      2458

    accuracy                           1.00      2519
   macro avg       0.99      0.93      0.96      2519
weighted avg       1.00      1.00      1.00      2519

Keras TF stop cnn_pfa_bottles_3
trnargs = {'batch_size':32,'max_iter':200,'lay':[('conv2d',32,[5,5],[2,2]),('elu',),('batch',),('dropout',0.1),('pool',[2,2],[2,2]),('conv2d',32,[5,5],[2,2]),('elu',),('batch',),('dropout',0.1),('pool',[2,2],[2,2]),('flatten',),('ip',90),('relu',),('dropout',0.7)],'base_lr':0.0005, 'optimizer':'adadelta','val_split':0.2,'monitor': 'val_loss','patience':15, 'stop': True}
Keras TF start  cnn_sfa_bottles_3
Train DNN with Keras
Train on 3124 samples, validate on 781 samples
Epoch 1/200
 - 12s - loss: 0.2648 - acc: 0.9677 - val_loss: 0.2559 - val_acc: 0.9667
Epoch 2/200
 - 9s - loss: 0.1684 - acc: 0.9795 - val_loss: 0.1654 - val_acc: 0.9667
Epoch 3/200
 - 9s - loss: 0.1219 - acc: 0.9907 - val_loss: 0.1101 - val_acc: 0.9885
Epoch 4/200
 - 9s - loss: 0.0941 - acc: 0.9946 - val_loss: 0.0875 - val_acc: 0.9962
Epoch 5/200
 - 9s - loss: 0.0864 - acc: 0.9965 - val_loss: 0.0789 - val_acc: 0.9962
Epoch 6/200
 - 10s - loss: 0.0740 - acc: 0.9971 - val_loss: 0.0716 - val_acc: 0.9987
Epoch 7/200
 - 10s - loss: 0.0620 - acc: 0.9997 - val_loss: 0.0619 - val_acc: 0.9974
Epoch 8/200
 - 9s - loss: 0.0590 - acc: 0.9984 - val_loss: 0.0599 - val_acc: 0.9962
Epoch 9/200
 - 9s - loss: 0.0533 - acc: 0.9987 - val_loss: 0.0507 - val_acc: 0.9987
Epoch 10/200
 - 9s - loss: 0.0456 - acc: 0.9990 - val_loss: 0.0472 - val_acc: 0.9987
Epoch 11/200
 - 11s - loss: 0.0415 - acc: 0.9990 - val_loss: 0.0409 - val_acc: 0.9987
Epoch 12/200
 - 12s - loss: 0.0368 - acc: 0.9990 - val_loss: 0.0359 - val_acc: 0.9987
Epoch 13/200
 - 13s - loss: 0.0331 - acc: 0.9994 - val_loss: 0.0364 - val_acc: 0.9962
Epoch 14/200
 - 12s - loss: 0.0293 - acc: 0.9994 - val_loss: 0.0314 - val_acc: 0.9974
Epoch 15/200
 - 11s - loss: 0.0249 - acc: 1.0000 - val_loss: 0.0292 - val_acc: 0.9962
Epoch 16/200
 - 12s - loss: 0.0212 - acc: 1.0000 - val_loss: 0.0269 - val_acc: 0.9974
Epoch 17/200
 - 11s - loss: 0.0187 - acc: 0.9997 - val_loss: 0.0195 - val_acc: 0.9987
Epoch 18/200
 - 11s - loss: 0.0157 - acc: 1.0000 - val_loss: 0.0168 - val_acc: 0.9987
Epoch 19/200
 - 11s - loss: 0.0140 - acc: 0.9997 - val_loss: 0.0162 - val_acc: 0.9987
Epoch 20/200
 - 11s - loss: 0.0145 - acc: 0.9987 - val_loss: 0.0206 - val_acc: 0.9962
Epoch 21/200
 - 11s - loss: 0.0131 - acc: 0.9990 - val_loss: 0.0159 - val_acc: 0.9987
Epoch 22/200
 - 13s - loss: 0.0109 - acc: 0.9997 - val_loss: 0.0198 - val_acc: 0.9962
Epoch 23/200
 - 13s - loss: 0.0114 - acc: 0.9994 - val_loss: 0.0215 - val_acc: 0.9962
Epoch 24/200
 - 14s - loss: 0.0088 - acc: 0.9997 - val_loss: 0.0170 - val_acc: 0.9974
Epoch 25/200
 - 12s - loss: 0.0084 - acc: 0.9997 - val_loss: 0.0131 - val_acc: 0.9987
Epoch 26/200
 - 14s - loss: 0.0070 - acc: 1.0000 - val_loss: 0.0138 - val_acc: 0.9987
Epoch 27/200
 - 13s - loss: 0.0084 - acc: 0.9990 - val_loss: 0.0280 - val_acc: 0.9936
Epoch 28/200
 - 13s - loss: 0.0068 - acc: 0.9997 - val_loss: 0.0226 - val_acc: 0.9962
Epoch 29/200
 - 15s - loss: 0.0059 - acc: 1.0000 - val_loss: 0.0179 - val_acc: 0.9962
Epoch 30/200
 - 21s - loss: 0.0053 - acc: 1.0000 - val_loss: 0.0215 - val_acc: 0.9962
Epoch 31/200
 - 22s - loss: 0.0057 - acc: 0.9994 - val_loss: 0.0153 - val_acc: 0.9962
Epoch 32/200
 - 21s - loss: 0.0050 - acc: 1.0000 - val_loss: 0.0083 - val_acc: 0.9987
Epoch 33/200
 - 21s - loss: 0.0053 - acc: 0.9997 - val_loss: 0.0069 - val_acc: 0.9987
Epoch 34/200
 - 23s - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0308 - val_acc: 0.9936
Epoch 35/200
 - 22s - loss: 0.0060 - acc: 0.9990 - val_loss: 0.0268 - val_acc: 0.9962
Epoch 36/200
 - 25s - loss: 0.0037 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 0.9987
Epoch 37/200
 - 34s - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 0.9974
Epoch 38/200
 - 21s - loss: 0.0032 - acc: 0.9997 - val_loss: 0.0054 - val_acc: 0.9987
Epoch 39/200
 - 20s - loss: 0.0036 - acc: 0.9997 - val_loss: 0.0055 - val_acc: 0.9987
Epoch 40/200
 - 19s - loss: 0.0048 - acc: 0.9994 - val_loss: 0.0144 - val_acc: 0.9974
Epoch 41/200
 - 19s - loss: 0.0036 - acc: 0.9997 - val_loss: 0.0076 - val_acc: 0.9987
Epoch 42/200
 - 19s - loss: 0.0039 - acc: 0.9997 - val_loss: 0.0048 - val_acc: 0.9987
Epoch 43/200
 - 19s - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 0.9987
Epoch 44/200
 - 20s - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0109 - val_acc: 0.9962
Epoch 45/200
 - 12s - loss: 0.0032 - acc: 0.9994 - val_loss: 0.0053 - val_acc: 0.9987
Epoch 46/200
 - 11s - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0203 - val_acc: 0.9949
Epoch 47/200
 - 12s - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0035 - val_acc: 1.0000
Epoch 48/200
 - 12s - loss: 0.0044 - acc: 0.9994 - val_loss: 0.1645 - val_acc: 0.9462
Epoch 49/200
 - 12s - loss: 0.0049 - acc: 0.9994 - val_loss: 0.0051 - val_acc: 0.9987
Epoch 50/200
 - 12s - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0114 - val_acc: 0.9974
Epoch 51/200
 - 13s - loss: 0.0078 - acc: 0.9984 - val_loss: 0.0075 - val_acc: 0.9974
Epoch 52/200
 - 13s - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0198 - val_acc: 0.9962
Epoch 53/200
 - 12s - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0082 - val_acc: 0.9974
Epoch 54/200
 - 12s - loss: 0.0044 - acc: 0.9994 - val_loss: 0.0035 - val_acc: 0.9987
Epoch 55/200
 - 12s - loss: 0.0040 - acc: 0.9994 - val_loss: 0.0048 - val_acc: 0.9987
Epoch 56/200
 - 12s - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0056 - val_acc: 0.9987
Epoch 57/200
 - 12s - loss: 0.0025 - acc: 0.9997 - val_loss: 0.0055 - val_acc: 0.9987
Epoch 58/200
 - 12s - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0034 - val_acc: 0.9987
Epoch 59/200
 - 12s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0036 - val_acc: 0.9987
Epoch 60/200
 - 12s - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0114 - val_acc: 0.9962
Epoch 61/200
 - 11s - loss: 0.0052 - acc: 0.9978 - val_loss: 0.0086 - val_acc: 0.9987
Epoch 62/200
 - 11s - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0094 - val_acc: 0.9974
Epoch 63/200
 - 11s - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 0.9987
Epoch 64/200
 - 11s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 0.9987
Epoch 65/200
 - 11s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0082 - val_acc: 0.9987
Epoch 66/200
 - 12s - loss: 0.0047 - acc: 0.9994 - val_loss: 0.0398 - val_acc: 0.9923
Epoch 67/200
 - 11s - loss: 0.0022 - acc: 0.9997 - val_loss: 0.0156 - val_acc: 0.9962
Epoch 68/200
 - 11s - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0062 - val_acc: 0.9987
Epoch 69/200
 - 11s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0033 - val_acc: 0.9987
Epoch 70/200
 - 11s - loss: 0.0064 - acc: 0.9984 - val_loss: 0.0854 - val_acc: 0.9885
Epoch 71/200
 - 11s - loss: 0.0069 - acc: 0.9987 - val_loss: 0.0449 - val_acc: 0.9949
Epoch 72/200
 - 12s - loss: 0.0024 - acc: 0.9997 - val_loss: 0.0035 - val_acc: 1.0000
Epoch 73/200
 - 12s - loss: 0.0023 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000
Epoch 74/200
 - 12s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 0.9987
Epoch 75/200
 - 12s - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0089 - val_acc: 0.9987
Epoch 76/200
 - 13s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.0028 - val_acc: 0.9987
Epoch 77/200
 - 12s - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 0.9987
Epoch 78/200
 - 12s - loss: 0.0039 - acc: 0.9990 - val_loss: 0.1397 - val_acc: 0.9846
Epoch 79/200
 - 12s - loss: 0.0028 - acc: 0.9994 - val_loss: 0.0596 - val_acc: 0.9910
Epoch 80/200
 - 12s - loss: 0.0069 - acc: 0.9987 - val_loss: 0.0130 - val_acc: 0.9962
Epoch 81/200
 - 12s - loss: 0.0026 - acc: 0.9994 - val_loss: 0.0051 - val_acc: 0.9987
Epoch 82/200
 - 12s - loss: 0.0016 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 0.9962
Epoch 83/200
 - 12s - loss: 0.0022 - acc: 0.9997 - val_loss: 0.0096 - val_acc: 0.9987
Epoch 84/200
 - 11s - loss: 0.0048 - acc: 0.9994 - val_loss: 0.0028 - val_acc: 0.9987
Epoch 85/200
 - 11s - loss: 0.0060 - acc: 0.9990 - val_loss: 0.0105 - val_acc: 0.9962
Epoch 86/200
 - 11s - loss: 0.0051 - acc: 0.9987 - val_loss: 0.0042 - val_acc: 0.9987
Epoch 87/200
 - 11s - loss: 0.0024 - acc: 0.9997 - val_loss: 0.0224 - val_acc: 0.9949
Epoch 88/200
 - 11s - loss: 0.0023 - acc: 1.0000 - val_loss: 0.1402 - val_acc: 0.9846
Restoring model weights from the end of the best epoch
Epoch 00088: early stopping
End-train DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Keras TF Training sfa_bottles_3: 3905/3905 100.0%
              precision    recall  f1-score   support

           B       1.00      1.00      1.00        96
           V       1.00      1.00      1.00      3809

    accuracy                           1.00      3905
   macro avg       1.00      1.00      1.00      3905
weighted avg       1.00      1.00      1.00      3905

Keras TF Testing sfa_bottles_3: 972/976 99.6%
              precision    recall  f1-score   support

           B       1.00      0.83      0.91        24
           V       1.00      1.00      1.00       952

    accuracy                           1.00       976
   macro avg       1.00      0.92      0.95       976
weighted avg       1.00      1.00      1.00       976

Keras TF CV sfa_bottles_3: 2507/2519 99.5%
              precision    recall  f1-score   support

           B       0.95      0.85      0.90        61
           V       1.00      1.00      1.00      2458

    accuracy                           1.00      2519
   macro avg       0.97      0.93      0.95      2519
weighted avg       1.00      1.00      1.00      2519

Keras TF stop cnn_sfa_bottles_3
svm start  sig_bottles_3
SVM Training sig_bottles_3: 3901/3905 99.9%
              precision    recall  f1-score   support

           B       0.96      1.00      0.98        96
           V       1.00      1.00      1.00      3809

    accuracy                           1.00      3905
   macro avg       0.98      1.00      0.99      3905
weighted avg       1.00      1.00      1.00      3905

SVM Testing sig_bottles_3: 970/976 99.4%
              precision    recall  f1-score   support

           B       0.85      0.92      0.88        24
           V       1.00      1.00      1.00       952

    accuracy                           0.99       976
   macro avg       0.92      0.96      0.94       976
weighted avg       0.99      0.99      0.99       976

SVM CV sig_bottles_3: 2394/2519 95.0%
              precision    recall  f1-score   support

           B       0.09      0.11      0.10        61
           V       0.98      0.97      0.97      2458

    accuracy                           0.95      2519
   macro avg       0.53      0.54      0.54      2519
weighted avg       0.96      0.95      0.95      2519

svm finish sig_bottles_3
svm start  pfa_bottles_3
SVM Training pfa_bottles_3: 3905/3905 100.0%
              precision    recall  f1-score   support

           B       1.00      1.00      1.00        96
           V       1.00      1.00      1.00      3809

    accuracy                           1.00      3905
   macro avg       1.00      1.00      1.00      3905
weighted avg       1.00      1.00      1.00      3905

SVM Testing pfa_bottles_3: 971/976 99.5%
              precision    recall  f1-score   support

           B       1.00      0.79      0.88        24
           V       0.99      1.00      1.00       952

    accuracy                           0.99       976
   macro avg       1.00      0.90      0.94       976
weighted avg       0.99      0.99      0.99       976

SVM CV pfa_bottles_3: 2499/2519 99.2%
              precision    recall  f1-score   support

           B       1.00      0.67      0.80        61
           V       0.99      1.00      1.00      2458

    accuracy                           0.99      2519
   macro avg       1.00      0.84      0.90      2519
weighted avg       0.99      0.99      0.99      2519

svm finish pfa_bottles_3
svm start  sfa_bottles_3
SVM Training sfa_bottles_3: 3905/3905 100.0%
              precision    recall  f1-score   support

           B       1.00      1.00      1.00        96
           V       1.00      1.00      1.00      3809

    accuracy                           1.00      3905
   macro avg       1.00      1.00      1.00      3905
weighted avg       1.00      1.00      1.00      3905

SVM Testing sfa_bottles_3: 969/976 99.3%
              precision    recall  f1-score   support

           B       1.00      0.71      0.83        24
           V       0.99      1.00      1.00       952

    accuracy                           0.99       976
   macro avg       1.00      0.85      0.91       976
weighted avg       0.99      0.99      0.99       976

SVM CV sfa_bottles_3: 2468/2519 98.0%
              precision    recall  f1-score   support

           B       1.00      0.16      0.28        61
           V       0.98      1.00      0.99      2458

    accuracy                           0.98      2519
   macro avg       0.99      0.58      0.64      2519
weighted avg       0.98      0.98      0.97      2519

svm finish sfa_bottles_3
trnargs = {'states':1, 'its': [0]}
hmm start  pfa_bottles_3
spl 0
CMP: 960/976 98.4%
HMM Training pfa_bottles_3: 3870/3905 99.1%
              precision    recall  f1-score   support

           B       0.73      1.00      0.85        96
           V       1.00      0.99      1.00      3809

    accuracy                           0.99      3905
   macro avg       0.87      1.00      0.92      3905
weighted avg       0.99      0.99      0.99      3905

HMM Testing pfa_bottles_3: 960/976 98.4%
              precision    recall  f1-score   support

           B       0.60      1.00      0.75        24
           V       1.00      0.98      0.99       952

    accuracy                           0.98       976
   macro avg       0.80      0.99      0.87       976
weighted avg       0.99      0.98      0.99       976

HMM CV pfa_bottles_3: 2484/2519 98.6%
              precision    recall  f1-score   support

           B       0.68      0.82      0.74        61
           V       1.00      0.99      0.99      2458

    accuracy                           0.99      2519
   macro avg       0.84      0.90      0.87      2519
weighted avg       0.99      0.99      0.99      2519

hmm start  sfa_bottles_3
spl 0
CMP: 827/976 84.7%
spl 0 ite 1
CMP: 947/976 97.0%
spl 0 ite 2
CMP: 965/976 98.9%
spl 0 ite 3
CMP: 967/976 99.1%
spl 1
CMP: 967/976 99.1%
spl 1 ite 1
CMP: 967/976 99.1%
spl 1 ite 2
CMP: 968/976 99.2%
spl 1 ite 3
CMP: 968/976 99.2%
spl 1 ite 4
CMP: 969/976 99.3%
spl 1 ite 5
CMP: 971/976 99.5%
spl 2
CMP: 971/976 99.5%
spl 2 ite 1
CMP: 973/976 99.7%
spl 2 ite 2
CMP: 973/976 99.7%
spl 2 ite 3
CMP: 973/976 99.7%
spl 2 ite 4
CMP: 972/976 99.6%
spl 2 ite 5
CMP: 972/976 99.6%
spl 2 ite 6
CMP: 972/976 99.6%
spl 2 ite 7
CMP: 972/976 99.6%
spl 3
CMP: 972/976 99.6%
spl 3 ite 1
CMP: 972/976 99.6%
spl 3 ite 2
CMP: 972/976 99.6%
spl 3 ite 3
CMP: 972/976 99.6%
spl 3 ite 4
CMP: 972/976 99.6%
spl 3 ite 5
CMP: 972/976 99.6%
spl 3 ite 6
CMP: 972/976 99.6%
spl 3 ite 7
CMP: 972/976 99.6%
spl 3 ite 8
CMP: 972/976 99.6%
spl 3 ite 9
CMP: 972/976 99.6%
spl 4
CMP: 972/976 99.6%
spl 4 ite 1
CMP: 970/976 99.4%
spl 4 ite 2
CMP: 970/976 99.4%
spl 4 ite 3
CMP: 970/976 99.4%
spl 4 ite 4
CMP: 970/976 99.4%
spl 4 ite 5
CMP: 970/976 99.4%
spl 4 ite 6
CMP: 970/976 99.4%
spl 4 ite 7
CMP: 970/976 99.4%
spl 4 ite 8
CMP: 970/976 99.4%
spl 4 ite 9
CMP: 970/976 99.4%
spl 4 ite 10
CMP: 970/976 99.4%
spl 4 ite 11
CMP: 970/976 99.4%
spl 5
CMP: 971/976 99.5%
spl 5 ite 1
CMP: 970/976 99.4%
spl 5 ite 2
CMP: 970/976 99.4%
spl 5 ite 3
CMP: 969/976 99.3%
spl 5 ite 4
CMP: 969/976 99.3%
spl 5 ite 5
CMP: 969/976 99.3%
spl 5 ite 6
CMP: 969/976 99.3%
spl 5 ite 7
CMP: 969/976 99.3%
spl 5 ite 8
CMP: 969/976 99.3%
spl 5 ite 9
CMP: 969/976 99.3%
spl 5 ite 10
CMP: 968/976 99.2%
spl 5 ite 11
CMP: 968/976 99.2%
spl 5 ite 12
CMP: 968/976 99.2%
spl 5 ite 13
CMP: 968/976 99.2%
HMM Training sfa_bottles_3: 3905/3905 100.0%
              precision    recall  f1-score   support

           B       1.00      1.00      1.00        96
           V       1.00      1.00      1.00      3809

    accuracy                           1.00      3905
   macro avg       1.00      1.00      1.00      3905
weighted avg       1.00      1.00      1.00      3905

HMM Testing sfa_bottles_3: 968/976 99.2%
              precision    recall  f1-score   support

           B       1.00      0.67      0.80        24
           V       0.99      1.00      1.00       952

    accuracy                           0.99       976
   macro avg       1.00      0.83      0.90       976
weighted avg       0.99      0.99      0.99       976

HMM CV sfa_bottles_3: 2486/2519 98.7%
              precision    recall  f1-score   support

           B       1.00      0.46      0.63        61
           V       0.99      1.00      0.99      2458

    accuracy                           0.99      2519
   macro avg       0.99      0.73      0.81      2519
weighted avg       0.99      0.99      0.98      2519

flst [bottles]
load fdb /home/kraljiva/Projects/uasr-data/bottles/Versuch004_E/log/fdb
trnargs = {'batch_size':32,'max_iter':200,'lay':[('ip',256),('lrelu',),('batch',),('dropout',0.6), ('ip',128),('lrelu',),('batch',),('dropout',0.6)],'base_lr':0.0005,'optimizer':'adagrad','val_split':0.2,'monitor': 'val_loss','patience':10, 'stop': True}
Keras TF start  snn_sig_bottles_4
Train DNN with Keras
Train on 3124 samples, validate on 781 samples
Epoch 1/200
 - 28s - loss: 1.4283 - acc: 0.7660 - val_loss: 0.9019 - val_acc: 0.9654
Epoch 2/200
 - 26s - loss: 0.9316 - acc: 0.9113 - val_loss: 0.7700 - val_acc: 0.9667
Epoch 3/200
 - 26s - loss: 0.7466 - acc: 0.9353 - val_loss: 0.7426 - val_acc: 0.9641
Epoch 4/200
 - 26s - loss: 0.6082 - acc: 0.9558 - val_loss: 0.5664 - val_acc: 0.9667
Epoch 5/200
 - 24s - loss: 0.5451 - acc: 0.9584 - val_loss: 0.5096 - val_acc: 0.9667
Epoch 6/200
 - 25s - loss: 0.4646 - acc: 0.9670 - val_loss: 0.4712 - val_acc: 0.9667
Epoch 7/200
 - 25s - loss: 0.4302 - acc: 0.9706 - val_loss: 0.4664 - val_acc: 0.9667
Epoch 8/200
 - 25s - loss: 0.3994 - acc: 0.9702 - val_loss: 0.4147 - val_acc: 0.9667
Epoch 9/200
 - 25s - loss: 0.3754 - acc: 0.9734 - val_loss: 0.3937 - val_acc: 0.9667
Epoch 10/200
 - 25s - loss: 0.3460 - acc: 0.9754 - val_loss: 0.3798 - val_acc: 0.9654
Epoch 11/200
 - 25s - loss: 0.3300 - acc: 0.9744 - val_loss: 0.4096 - val_acc: 0.9667
Epoch 12/200
 - 25s - loss: 0.3092 - acc: 0.9773 - val_loss: 0.3941 - val_acc: 0.9667
Epoch 13/200
 - 26s - loss: 0.2876 - acc: 0.9798 - val_loss: 0.3192 - val_acc: 0.9654
Epoch 14/200
 - 26s - loss: 0.2951 - acc: 0.9773 - val_loss: 0.3572 - val_acc: 0.9667
Epoch 15/200
 - 25s - loss: 0.2735 - acc: 0.9789 - val_loss: 0.3428 - val_acc: 0.9667
Epoch 16/200
 - 25s - loss: 0.2575 - acc: 0.9792 - val_loss: 0.3668 - val_acc: 0.9667
Epoch 17/200
 - 26s - loss: 0.2480 - acc: 0.9818 - val_loss: 0.3019 - val_acc: 0.9667
Epoch 18/200
 - 27s - loss: 0.2382 - acc: 0.9824 - val_loss: 0.2831 - val_acc: 0.9706
Epoch 19/200
 - 25s - loss: 0.2259 - acc: 0.9850 - val_loss: 0.2824 - val_acc: 0.9680
Epoch 20/200
 - 24s - loss: 0.2255 - acc: 0.9840 - val_loss: 0.2782 - val_acc: 0.9718
Epoch 21/200
 - 24s - loss: 0.2225 - acc: 0.9843 - val_loss: 0.2786 - val_acc: 0.9795
Epoch 22/200
 - 25s - loss: 0.2142 - acc: 0.9853 - val_loss: 0.2622 - val_acc: 0.9718
Epoch 23/200
 - 25s - loss: 0.2161 - acc: 0.9834 - val_loss: 0.2965 - val_acc: 0.9680
Epoch 24/200
 - 26s - loss: 0.2033 - acc: 0.9875 - val_loss: 0.2949 - val_acc: 0.9680
Epoch 25/200
 - 26s - loss: 0.2005 - acc: 0.9862 - val_loss: 0.3028 - val_acc: 0.9680
Epoch 26/200
 - 25s - loss: 0.2010 - acc: 0.9866 - val_loss: 0.4198 - val_acc: 0.9667
Epoch 27/200
 - 26s - loss: 0.1890 - acc: 0.9885 - val_loss: 0.3136 - val_acc: 0.9680
Epoch 28/200
 - 25s - loss: 0.1874 - acc: 0.9891 - val_loss: 0.3514 - val_acc: 0.9667
Epoch 29/200
 - 24s - loss: 0.1882 - acc: 0.9869 - val_loss: 0.2929 - val_acc: 0.9693
Epoch 30/200
 - 24s - loss: 0.1856 - acc: 0.9872 - val_loss: 0.2519 - val_acc: 0.9744
Epoch 31/200
 - 23s - loss: 0.1740 - acc: 0.9898 - val_loss: 0.2407 - val_acc: 0.9706
Epoch 32/200
 - 23s - loss: 0.1749 - acc: 0.9885 - val_loss: 0.2458 - val_acc: 0.9744
Epoch 33/200
 - 23s - loss: 0.1790 - acc: 0.9891 - val_loss: 0.2745 - val_acc: 0.9680
Epoch 34/200
 - 23s - loss: 0.1699 - acc: 0.9891 - val_loss: 0.2709 - val_acc: 0.9693
Epoch 35/200
 - 23s - loss: 0.1616 - acc: 0.9907 - val_loss: 0.2805 - val_acc: 0.9680
Epoch 36/200
 - 23s - loss: 0.1811 - acc: 0.9859 - val_loss: 0.2394 - val_acc: 0.9770
Epoch 37/200
 - 24s - loss: 0.1715 - acc: 0.9888 - val_loss: 0.2827 - val_acc: 0.9680
Epoch 38/200
 - 26s - loss: 0.1647 - acc: 0.9898 - val_loss: 0.3804 - val_acc: 0.9667
Epoch 39/200
 - 24s - loss: 0.1573 - acc: 0.9891 - val_loss: 0.2938 - val_acc: 0.9680
Epoch 40/200
 - 24s - loss: 0.1575 - acc: 0.9894 - val_loss: 0.3070 - val_acc: 0.9680
Epoch 41/200
 - 24s - loss: 0.1517 - acc: 0.9917 - val_loss: 2.0016 - val_acc: 0.1767
Epoch 42/200
 - 25s - loss: 0.1527 - acc: 0.9904 - val_loss: 0.2408 - val_acc: 0.9706
Epoch 43/200
 - 25s - loss: 0.1476 - acc: 0.9907 - val_loss: 0.2608 - val_acc: 0.9680
Epoch 44/200
 - 25s - loss: 0.1391 - acc: 0.9942 - val_loss: 0.2326 - val_acc: 0.9680
Epoch 45/200
 - 25s - loss: 0.1450 - acc: 0.9907 - val_loss: 0.2677 - val_acc: 0.9680
Epoch 46/200
 - 25s - loss: 0.1368 - acc: 0.9926 - val_loss: 0.2452 - val_acc: 0.9693
Epoch 47/200
 - 25s - loss: 0.1326 - acc: 0.9942 - val_loss: 0.3287 - val_acc: 0.9680
Epoch 48/200
 - 25s - loss: 0.1309 - acc: 0.9952 - val_loss: 0.3482 - val_acc: 0.9667
Epoch 49/200
 - 26s - loss: 0.1356 - acc: 0.9901 - val_loss: 0.2250 - val_acc: 0.9731
Epoch 50/200
 - 26s - loss: 0.1391 - acc: 0.9914 - val_loss: 0.4467 - val_acc: 0.9667
Epoch 51/200
 - 24s - loss: 0.1415 - acc: 0.9901 - val_loss: 0.4163 - val_acc: 0.8604
Epoch 52/200
 - 23s - loss: 0.1345 - acc: 0.9917 - val_loss: 0.2865 - val_acc: 0.9680
Epoch 53/200
 - 25s - loss: 0.1409 - acc: 0.9907 - val_loss: 0.2026 - val_acc: 0.9795
Epoch 54/200
 - 27s - loss: 0.1393 - acc: 0.9914 - val_loss: 0.9574 - val_acc: 0.5659
Epoch 55/200
 - 26s - loss: 0.1462 - acc: 0.9888 - val_loss: 0.2040 - val_acc: 0.9744
Epoch 56/200
 - 26s - loss: 0.1457 - acc: 0.9907 - val_loss: 0.5102 - val_acc: 0.8143
Epoch 57/200
 - 25s - loss: 0.1441 - acc: 0.9901 - val_loss: 0.2477 - val_acc: 0.9693
Epoch 58/200
 - 25s - loss: 0.1414 - acc: 0.9910 - val_loss: 0.2304 - val_acc: 0.9693
Epoch 59/200
 - 24s - loss: 0.1359 - acc: 0.9926 - val_loss: 0.2578 - val_acc: 0.9680
Epoch 60/200
 - 24s - loss: 0.1245 - acc: 0.9958 - val_loss: 0.2880 - val_acc: 0.9680
Epoch 61/200
 - 24s - loss: 0.1322 - acc: 0.9907 - val_loss: 0.2394 - val_acc: 0.9693
Epoch 62/200
 - 25s - loss: 0.1272 - acc: 0.9926 - val_loss: 0.2049 - val_acc: 0.9744
Epoch 63/200
 - 23s - loss: 0.1250 - acc: 0.9926 - val_loss: 0.3178 - val_acc: 0.9680
Restoring model weights from the end of the best epoch
Epoch 00063: early stopping
End-train DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Keras TF Training sig_bottles_4: 3886/3905 99.5%
              precision    recall  f1-score   support

           B       0.91      0.89      0.90        96
           V       1.00      1.00      1.00      3809

    accuracy                           1.00      3905
   macro avg       0.96      0.94      0.95      3905
weighted avg       1.00      1.00      1.00      3905

Keras TF Testing sig_bottles_4: 947/976 97.0%
              precision    recall  f1-score   support

           B       0.41      0.50      0.45        24
           V       0.99      0.98      0.98       952

    accuracy                           0.97       976
   macro avg       0.70      0.74      0.72       976
weighted avg       0.97      0.97      0.97       976

Keras TF CV sig_bottles_4: 2421/2519 96.1%
              precision    recall  f1-score   support

           B       0.14      0.11      0.12        61
           V       0.98      0.98      0.98      2458

    accuracy                           0.96      2519
   macro avg       0.56      0.55      0.55      2519
weighted avg       0.96      0.96      0.96      2519

Keras TF stop snn_sig_bottles_4
trnargs = {'batch_size':32,'max_iter':200,'lay':[('ip',256),('lrelu',),('batch',),('dropout',0.7), ('ip',128),('lrelu',),('batch',),('dropout',0.7)],'base_lr':0.0005,'optimizer':'adagrad','val_split':0.2,'monitor': 'val_loss','patience':10, 'stop': True}
Keras TF start  snn_pfa_bottles_4
Train DNN with Keras
Train on 3124 samples, validate on 781 samples
Epoch 1/200
 - 9s - loss: 1.1177 - acc: 0.7273 - val_loss: 0.7466 - val_acc: 0.9667
Epoch 2/200
 - 4s - loss: 0.7193 - acc: 0.8790 - val_loss: 0.4888 - val_acc: 0.9667
Epoch 3/200
 - 5s - loss: 0.5815 - acc: 0.9264 - val_loss: 0.4410 - val_acc: 0.9667
Epoch 4/200
 - 5s - loss: 0.4867 - acc: 0.9405 - val_loss: 0.3936 - val_acc: 0.9667
Epoch 5/200
 - 4s - loss: 0.4280 - acc: 0.9485 - val_loss: 0.3604 - val_acc: 0.9667
Epoch 6/200
 - 5s - loss: 0.3761 - acc: 0.9603 - val_loss: 0.3429 - val_acc: 0.9744
Epoch 7/200
 - 5s - loss: 0.3426 - acc: 0.9635 - val_loss: 0.3398 - val_acc: 0.9667
Epoch 8/200
 - 5s - loss: 0.3185 - acc: 0.9709 - val_loss: 0.3249 - val_acc: 0.9667
Epoch 9/200
 - 6s - loss: 0.2909 - acc: 0.9763 - val_loss: 0.2907 - val_acc: 0.9667
Epoch 10/200
 - 4s - loss: 0.2685 - acc: 0.9789 - val_loss: 0.2685 - val_acc: 0.9936
Epoch 11/200
 - 4s - loss: 0.2517 - acc: 0.9827 - val_loss: 0.2826 - val_acc: 0.9667
Epoch 12/200
 - 5s - loss: 0.2345 - acc: 0.9837 - val_loss: 0.3449 - val_acc: 0.9667
Epoch 13/200
 - 5s - loss: 0.2203 - acc: 0.9862 - val_loss: 0.2325 - val_acc: 0.9706
Epoch 14/200
 - 4s - loss: 0.2157 - acc: 0.9869 - val_loss: 0.2735 - val_acc: 0.9667
Epoch 15/200
 - 5s - loss: 0.2133 - acc: 0.9850 - val_loss: 0.2901 - val_acc: 0.9667
Epoch 16/200
 - 5s - loss: 0.1975 - acc: 0.9878 - val_loss: 0.2227 - val_acc: 0.9706
Epoch 17/200
 - 5s - loss: 0.1957 - acc: 0.9846 - val_loss: 0.2944 - val_acc: 0.9667
Epoch 18/200
 - 4s - loss: 0.1839 - acc: 0.9904 - val_loss: 0.2447 - val_acc: 0.9680
Epoch 19/200
 - 5s - loss: 0.1771 - acc: 0.9910 - val_loss: 0.2588 - val_acc: 0.9667
Epoch 20/200
 - 5s - loss: 0.1707 - acc: 0.9907 - val_loss: 0.2765 - val_acc: 0.9667
Epoch 21/200
 - 4s - loss: 0.1653 - acc: 0.9901 - val_loss: 0.2643 - val_acc: 0.9667
Epoch 22/200
 - 5s - loss: 0.1604 - acc: 0.9907 - val_loss: 0.2116 - val_acc: 0.9693
Epoch 23/200
 - 5s - loss: 0.1548 - acc: 0.9904 - val_loss: 0.2441 - val_acc: 0.9693
Epoch 24/200
 - 4s - loss: 0.1543 - acc: 0.9933 - val_loss: 0.2541 - val_acc: 0.9859
Epoch 25/200
 - 4s - loss: 0.1518 - acc: 0.9914 - val_loss: 0.1814 - val_acc: 0.9731
Epoch 26/200
 - 5s - loss: 0.1523 - acc: 0.9914 - val_loss: 0.1544 - val_acc: 0.9859
Epoch 27/200
 - 5s - loss: 0.1478 - acc: 0.9914 - val_loss: 0.1736 - val_acc: 0.9770
Epoch 28/200
 - 5s - loss: 0.1404 - acc: 0.9939 - val_loss: 0.2585 - val_acc: 0.9667
Epoch 29/200
 - 5s - loss: 0.1403 - acc: 0.9923 - val_loss: 0.2387 - val_acc: 0.9667
Epoch 30/200
 - 5s - loss: 0.1390 - acc: 0.9930 - val_loss: 0.1381 - val_acc: 0.9910
Epoch 31/200
 - 5s - loss: 0.1346 - acc: 0.9958 - val_loss: 0.1479 - val_acc: 0.9859
Epoch 32/200
 - 5s - loss: 0.1347 - acc: 0.9930 - val_loss: 0.2263 - val_acc: 0.9693
Epoch 33/200
 - 5s - loss: 0.1291 - acc: 0.9968 - val_loss: 0.2050 - val_acc: 0.9706
Epoch 34/200
 - 5s - loss: 0.1257 - acc: 0.9955 - val_loss: 0.1618 - val_acc: 0.9782
Epoch 35/200
 - 5s - loss: 0.1279 - acc: 0.9933 - val_loss: 0.1753 - val_acc: 0.9770
Epoch 36/200
 - 5s - loss: 0.1237 - acc: 0.9949 - val_loss: 1.0192 - val_acc: 0.5109
Epoch 37/200
 - 5s - loss: 0.1251 - acc: 0.9936 - val_loss: 0.1344 - val_acc: 0.9872
Epoch 38/200
 - 5s - loss: 0.1220 - acc: 0.9968 - val_loss: 0.1998 - val_acc: 0.9693
Epoch 39/200
 - 5s - loss: 0.1208 - acc: 0.9958 - val_loss: 0.2073 - val_acc: 0.9718
Epoch 40/200
 - 5s - loss: 0.1169 - acc: 0.9939 - val_loss: 0.2110 - val_acc: 0.9706
Epoch 41/200
 - 5s - loss: 0.1138 - acc: 0.9965 - val_loss: 0.1604 - val_acc: 0.9770
Epoch 42/200
 - 5s - loss: 0.1181 - acc: 0.9942 - val_loss: 0.2016 - val_acc: 0.9706
Epoch 43/200
 - 5s - loss: 0.1130 - acc: 0.9958 - val_loss: 0.1794 - val_acc: 0.9744
Epoch 44/200
 - 5s - loss: 0.1073 - acc: 0.9971 - val_loss: 0.2195 - val_acc: 0.9693
Epoch 45/200
 - 5s - loss: 0.1049 - acc: 0.9965 - val_loss: 0.1248 - val_acc: 0.9872
Epoch 46/200
 - 5s - loss: 0.1126 - acc: 0.9926 - val_loss: 0.1357 - val_acc: 0.9795
Epoch 47/200
 - 5s - loss: 0.1024 - acc: 0.9968 - val_loss: 0.2563 - val_acc: 0.9667
Epoch 48/200
 - 5s - loss: 0.1063 - acc: 0.9952 - val_loss: 0.4381 - val_acc: 0.8476
Epoch 49/200
 - 5s - loss: 0.1015 - acc: 0.9974 - val_loss: 0.1204 - val_acc: 0.9898
Epoch 50/200
 - 5s - loss: 0.1025 - acc: 0.9958 - val_loss: 0.1250 - val_acc: 0.9846
Epoch 51/200
 - 5s - loss: 0.1033 - acc: 0.9962 - val_loss: 0.1350 - val_acc: 0.9795
Epoch 52/200
 - 5s - loss: 0.1033 - acc: 0.9965 - val_loss: 0.1955 - val_acc: 0.9693
Epoch 53/200
 - 5s - loss: 0.1050 - acc: 0.9946 - val_loss: 0.2502 - val_acc: 0.9667
Epoch 54/200
 - 6s - loss: 0.0962 - acc: 0.9974 - val_loss: 0.2376 - val_acc: 0.9680
Epoch 55/200
 - 6s - loss: 0.0962 - acc: 0.9974 - val_loss: 0.2991 - val_acc: 0.9667
Epoch 56/200
 - 6s - loss: 0.0968 - acc: 0.9965 - val_loss: 0.1006 - val_acc: 0.9936
Epoch 57/200
 - 5s - loss: 0.0923 - acc: 0.9978 - val_loss: 0.1381 - val_acc: 0.9770
Epoch 58/200
 - 5s - loss: 0.0957 - acc: 0.9955 - val_loss: 0.1058 - val_acc: 0.9910
Epoch 59/200
 - 5s - loss: 0.0942 - acc: 0.9962 - val_loss: 0.3879 - val_acc: 0.8604
Epoch 60/200
 - 4s - loss: 0.0939 - acc: 0.9981 - val_loss: 0.1188 - val_acc: 0.9834
Epoch 61/200
 - 5s - loss: 0.0923 - acc: 0.9971 - val_loss: 0.1555 - val_acc: 0.9770
Epoch 62/200
 - 4s - loss: 0.0924 - acc: 0.9962 - val_loss: 0.1390 - val_acc: 0.9782
Epoch 63/200
 - 5s - loss: 0.0872 - acc: 0.9984 - val_loss: 0.1015 - val_acc: 0.9923
Epoch 64/200
 - 4s - loss: 0.0861 - acc: 0.9990 - val_loss: 0.1031 - val_acc: 0.9987
Epoch 65/200
 - 4s - loss: 0.0872 - acc: 0.9978 - val_loss: 0.1178 - val_acc: 0.9834
Epoch 66/200
 - 5s - loss: 0.0824 - acc: 0.9987 - val_loss: 0.1127 - val_acc: 0.9846
Restoring model weights from the end of the best epoch
Epoch 00066: early stopping
End-train DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Keras TF Training pfa_bottles_4: 3900/3905 99.9%
              precision    recall  f1-score   support

           B       1.00      0.95      0.97        96
           V       1.00      1.00      1.00      3809

    accuracy                           1.00      3905
   macro avg       1.00      0.97      0.99      3905
weighted avg       1.00      1.00      1.00      3905

Keras TF Testing pfa_bottles_4: 972/976 99.6%
              precision    recall  f1-score   support

           B       1.00      0.83      0.91        24
           V       1.00      1.00      1.00       952

    accuracy                           1.00       976
   macro avg       1.00      0.92      0.95       976
weighted avg       1.00      1.00      1.00       976

Keras TF CV pfa_bottles_4: 2501/2519 99.3%
              precision    recall  f1-score   support

           B       0.98      0.72      0.83        61
           V       0.99      1.00      1.00      2458

    accuracy                           0.99      2519
   macro avg       0.99      0.86      0.91      2519
weighted avg       0.99      0.99      0.99      2519

Keras TF stop snn_pfa_bottles_4
trnargs = {'batch_size':32,'max_iter':200,'lay':[('ip',128),('lrelu',),('batch',),('dropout',0.7), ('ip',64),('lrelu',),('batch',),('dropout',0.7)],'base_lr':0.0005,'optimizer':'adagrad','val_split':0.2,'monitor': 'val_loss','patience':10, 'stop': True}
Keras TF start  snn_sfa_bottles_4
Train DNN with Keras
Train on 3124 samples, validate on 781 samples
Epoch 1/200
 - 4s - loss: 1.0726 - acc: 0.6527 - val_loss: 0.5809 - val_acc: 0.9680
Epoch 2/200
 - 2s - loss: 0.7496 - acc: 0.8105 - val_loss: 0.4982 - val_acc: 0.9667
Epoch 3/200
 - 2s - loss: 0.6139 - acc: 0.8774 - val_loss: 0.4457 - val_acc: 0.9667
Epoch 4/200
 - 2s - loss: 0.5625 - acc: 0.8976 - val_loss: 0.4158 - val_acc: 0.9667
Epoch 5/200
 - 2s - loss: 0.5097 - acc: 0.9241 - val_loss: 0.3949 - val_acc: 0.9667
Epoch 6/200
 - 2s - loss: 0.4727 - acc: 0.9395 - val_loss: 0.3805 - val_acc: 0.9667
Epoch 7/200
 - 2s - loss: 0.4428 - acc: 0.9462 - val_loss: 0.3666 - val_acc: 0.9667
Epoch 8/200
 - 2s - loss: 0.4156 - acc: 0.9545 - val_loss: 0.3581 - val_acc: 0.9667
Epoch 9/200
 - 2s - loss: 0.3939 - acc: 0.9625 - val_loss: 0.3428 - val_acc: 0.9667
Epoch 10/200
 - 3s - loss: 0.3798 - acc: 0.9648 - val_loss: 0.3357 - val_acc: 0.9667
Epoch 11/200
 - 3s - loss: 0.3564 - acc: 0.9696 - val_loss: 0.3151 - val_acc: 0.9757
Epoch 12/200
 - 3s - loss: 0.3359 - acc: 0.9750 - val_loss: 0.3075 - val_acc: 0.9770
Epoch 13/200
 - 3s - loss: 0.3263 - acc: 0.9754 - val_loss: 0.3028 - val_acc: 0.9731
Epoch 14/200
 - 3s - loss: 0.3198 - acc: 0.9802 - val_loss: 0.3024 - val_acc: 0.9718
Epoch 15/200
 - 3s - loss: 0.3116 - acc: 0.9802 - val_loss: 0.2998 - val_acc: 0.9693
Epoch 16/200
 - 3s - loss: 0.3029 - acc: 0.9821 - val_loss: 0.2883 - val_acc: 0.9731
Epoch 17/200
 - 3s - loss: 0.2924 - acc: 0.9808 - val_loss: 0.2809 - val_acc: 0.9770
Epoch 18/200
 - 2s - loss: 0.2775 - acc: 0.9850 - val_loss: 0.2762 - val_acc: 0.9757
Epoch 19/200
 - 2s - loss: 0.2763 - acc: 0.9827 - val_loss: 0.2779 - val_acc: 0.9718
Epoch 20/200
 - 2s - loss: 0.2670 - acc: 0.9846 - val_loss: 0.2720 - val_acc: 0.9731
Epoch 21/200
 - 2s - loss: 0.2590 - acc: 0.9866 - val_loss: 0.2621 - val_acc: 0.9770
Epoch 22/200
 - 2s - loss: 0.2482 - acc: 0.9882 - val_loss: 0.2491 - val_acc: 0.9834
Epoch 23/200
 - 2s - loss: 0.2488 - acc: 0.9878 - val_loss: 0.2534 - val_acc: 0.9782
Epoch 24/200
 - 2s - loss: 0.2397 - acc: 0.9894 - val_loss: 0.2433 - val_acc: 0.9795
Epoch 25/200
 - 2s - loss: 0.2353 - acc: 0.9882 - val_loss: 0.2411 - val_acc: 0.9808
Epoch 26/200
 - 2s - loss: 0.2271 - acc: 0.9894 - val_loss: 0.2341 - val_acc: 0.9821
Epoch 27/200
 - 2s - loss: 0.2210 - acc: 0.9914 - val_loss: 0.2355 - val_acc: 0.9795
Epoch 28/200
 - 2s - loss: 0.2240 - acc: 0.9878 - val_loss: 0.2343 - val_acc: 0.9782
Epoch 29/200
 - 2s - loss: 0.2100 - acc: 0.9898 - val_loss: 0.2274 - val_acc: 0.9795
Epoch 30/200
 - 2s - loss: 0.2132 - acc: 0.9914 - val_loss: 0.2220 - val_acc: 0.9808
Epoch 31/200
 - 2s - loss: 0.2064 - acc: 0.9914 - val_loss: 0.2267 - val_acc: 0.9782
Epoch 32/200
 - 2s - loss: 0.2006 - acc: 0.9923 - val_loss: 0.2168 - val_acc: 0.9808
Epoch 33/200
 - 2s - loss: 0.1984 - acc: 0.9914 - val_loss: 0.2217 - val_acc: 0.9782
Epoch 34/200
 - 2s - loss: 0.1918 - acc: 0.9933 - val_loss: 0.2076 - val_acc: 0.9821
Epoch 35/200
 - 2s - loss: 0.1936 - acc: 0.9914 - val_loss: 0.2129 - val_acc: 0.9782
Epoch 36/200
 - 2s - loss: 0.1887 - acc: 0.9939 - val_loss: 0.2074 - val_acc: 0.9795
Epoch 37/200
 - 2s - loss: 0.1857 - acc: 0.9920 - val_loss: 0.2077 - val_acc: 0.9782
Epoch 38/200
 - 2s - loss: 0.1777 - acc: 0.9942 - val_loss: 0.2026 - val_acc: 0.9795
Epoch 39/200
 - 3s - loss: 0.1809 - acc: 0.9926 - val_loss: 0.1986 - val_acc: 0.9795
Epoch 40/200
 - 3s - loss: 0.1732 - acc: 0.9939 - val_loss: 0.1972 - val_acc: 0.9795
Epoch 41/200
 - 3s - loss: 0.1744 - acc: 0.9926 - val_loss: 0.1930 - val_acc: 0.9795
Epoch 42/200
 - 3s - loss: 0.1653 - acc: 0.9958 - val_loss: 0.1850 - val_acc: 0.9821
Epoch 43/200
 - 3s - loss: 0.1615 - acc: 0.9962 - val_loss: 0.1828 - val_acc: 0.9821
Epoch 44/200
 - 3s - loss: 0.1598 - acc: 0.9955 - val_loss: 0.1784 - val_acc: 0.9859
Epoch 45/200
 - 2s - loss: 0.1578 - acc: 0.9965 - val_loss: 0.1904 - val_acc: 0.9782
Epoch 46/200
 - 2s - loss: 0.1576 - acc: 0.9949 - val_loss: 0.1699 - val_acc: 0.9859
Epoch 47/200
 - 2s - loss: 0.1513 - acc: 0.9962 - val_loss: 0.1768 - val_acc: 0.9834
Epoch 48/200
 - 2s - loss: 0.1513 - acc: 0.9949 - val_loss: 0.1651 - val_acc: 0.9885
Epoch 49/200
 - 2s - loss: 0.1474 - acc: 0.9952 - val_loss: 0.1774 - val_acc: 0.9795
Epoch 50/200
 - 2s - loss: 0.1454 - acc: 0.9965 - val_loss: 0.1866 - val_acc: 0.9782
Epoch 51/200
 - 3s - loss: 0.1469 - acc: 0.9936 - val_loss: 0.1783 - val_acc: 0.9795
Epoch 52/200
 - 2s - loss: 0.1385 - acc: 0.9974 - val_loss: 0.1738 - val_acc: 0.9808
Epoch 53/200
 - 2s - loss: 0.1416 - acc: 0.9955 - val_loss: 0.1652 - val_acc: 0.9821
Epoch 54/200
 - 2s - loss: 0.1416 - acc: 0.9949 - val_loss: 0.1622 - val_acc: 0.9821
Epoch 55/200
 - 2s - loss: 0.1368 - acc: 0.9968 - val_loss: 0.1622 - val_acc: 0.9821
Epoch 56/200
 - 2s - loss: 0.1344 - acc: 0.9968 - val_loss: 0.1649 - val_acc: 0.9795
Epoch 57/200
 - 2s - loss: 0.1306 - acc: 0.9968 - val_loss: 0.1620 - val_acc: 0.9795
Epoch 58/200
 - 2s - loss: 0.1289 - acc: 0.9965 - val_loss: 0.1507 - val_acc: 0.9872
Epoch 59/200
 - 2s - loss: 0.1270 - acc: 0.9971 - val_loss: 0.1647 - val_acc: 0.9795
Epoch 60/200
 - 2s - loss: 0.1262 - acc: 0.9965 - val_loss: 0.1589 - val_acc: 0.9808
Epoch 61/200
 - 2s - loss: 0.1267 - acc: 0.9962 - val_loss: 0.1547 - val_acc: 0.9821
Epoch 62/200
 - 2s - loss: 0.1245 - acc: 0.9958 - val_loss: 0.1431 - val_acc: 0.9859
Epoch 63/200
 - 2s - loss: 0.1238 - acc: 0.9958 - val_loss: 0.1458 - val_acc: 0.9834
Epoch 64/200
 - 2s - loss: 0.1191 - acc: 0.9974 - val_loss: 0.1511 - val_acc: 0.9808
Epoch 65/200
 - 2s - loss: 0.1198 - acc: 0.9971 - val_loss: 0.1430 - val_acc: 0.9846
Epoch 66/200
 - 2s - loss: 0.1180 - acc: 0.9965 - val_loss: 0.1529 - val_acc: 0.9808
Epoch 67/200
 - 2s - loss: 0.1162 - acc: 0.9968 - val_loss: 0.1591 - val_acc: 0.9795
Epoch 68/200
 - 2s - loss: 0.1140 - acc: 0.9978 - val_loss: 0.1560 - val_acc: 0.9795
Epoch 69/200
 - 2s - loss: 0.1177 - acc: 0.9958 - val_loss: 0.1391 - val_acc: 0.9846
Epoch 70/200
 - 2s - loss: 0.1163 - acc: 0.9955 - val_loss: 0.1408 - val_acc: 0.9821
Epoch 71/200
 - 2s - loss: 0.1111 - acc: 0.9971 - val_loss: 0.1485 - val_acc: 0.9808
Epoch 72/200
 - 2s - loss: 0.1094 - acc: 0.9978 - val_loss: 0.1423 - val_acc: 0.9821
Epoch 73/200
 - 2s - loss: 0.1084 - acc: 0.9965 - val_loss: 0.1424 - val_acc: 0.9821
Epoch 74/200
 - 2s - loss: 0.1075 - acc: 0.9978 - val_loss: 0.1444 - val_acc: 0.9821
Epoch 75/200
 - 2s - loss: 0.1033 - acc: 0.9984 - val_loss: 0.1560 - val_acc: 0.9808
Epoch 76/200
 - 2s - loss: 0.1035 - acc: 0.9974 - val_loss: 0.1422 - val_acc: 0.9821
Epoch 77/200
 - 2s - loss: 0.1037 - acc: 0.9981 - val_loss: 0.1445 - val_acc: 0.9821
Epoch 78/200
 - 2s - loss: 0.1008 - acc: 0.9974 - val_loss: 0.1445 - val_acc: 0.9821
Epoch 79/200
 - 2s - loss: 0.0972 - acc: 0.9994 - val_loss: 0.1429 - val_acc: 0.9821
Restoring model weights from the end of the best epoch
Epoch 00079: early stopping
End-train DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Keras TF Training sfa_bottles_4: 3893/3905 99.7%
              precision    recall  f1-score   support

           B       1.00      0.88      0.93        96
           V       1.00      1.00      1.00      3809

    accuracy                           1.00      3905
   macro avg       1.00      0.94      0.97      3905
weighted avg       1.00      1.00      1.00      3905

Keras TF Testing sfa_bottles_4: 967/976 99.1%
              precision    recall  f1-score   support

           B       1.00      0.62      0.77        24
           V       0.99      1.00      1.00       952

    accuracy                           0.99       976
   macro avg       1.00      0.81      0.88       976
weighted avg       0.99      0.99      0.99       976

Keras TF CV sfa_bottles_4: 2475/2519 98.3%
              precision    recall  f1-score   support

           B       0.95      0.30      0.45        61
           V       0.98      1.00      0.99      2458

    accuracy                           0.98      2519
   macro avg       0.97      0.65      0.72      2519
weighted avg       0.98      0.98      0.98      2519

Keras TF stop snn_sfa_bottles_4
trnargs = {'batch_size':64,'max_iter':200,'lay':[('conv1d',16,64,2),('relu',),('batch',),('pool',8,8),('conv1d',32,32,2),('relu',),('batch',),('pool',8,8),('conv1d',64,16,8),('relu',),('batch',),('conv1d',128,8,2),('relu',),('batch',),('conv1d',256,4,2),('relu',),('batch',),('pool',4,4),('flatten',),('ip',64),('relu',),('dropout',0.25),('ip',32),('relu',),('dropout',0.25)],'base_lr':0.0005, 'optimizer':'adadelta','val_split':0.2,'monitor': 'val_loss','patience':15, 'stop': True}
Keras TF start  cnn_sig_bottles_4
Train DNN with Keras
Train on 3124 samples, validate on 781 samples
Epoch 1/200
 - 161s - loss: 0.3886 - acc: 0.9590 - val_loss: 0.4182 - val_acc: 0.9667
Epoch 2/200
 - 153s - loss: 0.3425 - acc: 0.9773 - val_loss: 0.3816 - val_acc: 0.9667
Epoch 3/200
 - 167s - loss: 0.3237 - acc: 0.9770 - val_loss: 0.3491 - val_acc: 0.9667
Epoch 4/200
 - 188s - loss: 0.3104 - acc: 0.9757 - val_loss: 0.3135 - val_acc: 0.9667
Epoch 5/200
 - 182s - loss: 0.2806 - acc: 0.9773 - val_loss: 0.4233 - val_acc: 0.9667
Epoch 6/200
 - 182s - loss: 0.2568 - acc: 0.9814 - val_loss: 0.4665 - val_acc: 0.9667
Epoch 7/200
 - 184s - loss: 0.2349 - acc: 0.9866 - val_loss: 0.4153 - val_acc: 0.9667
Epoch 8/200
 - 183s - loss: 0.2235 - acc: 0.9856 - val_loss: 0.3355 - val_acc: 0.9667
Epoch 9/200
 - 172s - loss: 0.2033 - acc: 0.9882 - val_loss: 0.3238 - val_acc: 0.9667
Epoch 10/200
 - 186s - loss: 0.1794 - acc: 0.9952 - val_loss: 0.2825 - val_acc: 0.9718
Epoch 11/200
 - 162s - loss: 0.1726 - acc: 0.9942 - val_loss: 0.1998 - val_acc: 0.9821
Epoch 12/200
 - 147s - loss: 0.1610 - acc: 0.9942 - val_loss: 0.1981 - val_acc: 0.9821
Epoch 13/200
 - 157s - loss: 0.1510 - acc: 0.9962 - val_loss: 0.1835 - val_acc: 0.9872
Epoch 14/200
 - 153s - loss: 0.1462 - acc: 0.9952 - val_loss: 0.2449 - val_acc: 0.9603
Epoch 15/200
 - 150s - loss: 0.1365 - acc: 0.9958 - val_loss: 0.3943 - val_acc: 0.9718
Epoch 16/200
 - 160s - loss: 0.1273 - acc: 0.9968 - val_loss: 0.3026 - val_acc: 0.9757
Epoch 17/200
 - 158s - loss: 0.1154 - acc: 0.9997 - val_loss: 0.1992 - val_acc: 0.9846
Epoch 18/200
 - 154s - loss: 0.1095 - acc: 0.9994 - val_loss: 0.2066 - val_acc: 0.9846
Epoch 19/200
 - 149s - loss: 0.1056 - acc: 0.9984 - val_loss: 0.1810 - val_acc: 0.9846
Epoch 20/200
 - 164s - loss: 0.1028 - acc: 0.9981 - val_loss: 0.1395 - val_acc: 0.9872
Epoch 21/200
 - 154s - loss: 0.0931 - acc: 0.9990 - val_loss: 0.3052 - val_acc: 0.9770
Epoch 22/200
 - 156s - loss: 0.0876 - acc: 0.9994 - val_loss: 0.1366 - val_acc: 0.9885
Epoch 23/200
 - 156s - loss: 0.0847 - acc: 0.9990 - val_loss: 0.3580 - val_acc: 0.9757
Epoch 24/200
 - 165s - loss: 0.0803 - acc: 0.9990 - val_loss: 0.1226 - val_acc: 0.9859
Epoch 25/200
 - 157s - loss: 0.0731 - acc: 1.0000 - val_loss: 0.1239 - val_acc: 0.9898
Epoch 26/200
 - 164s - loss: 0.0678 - acc: 1.0000 - val_loss: 0.1100 - val_acc: 0.9910
Epoch 27/200
 - 152s - loss: 0.0622 - acc: 1.0000 - val_loss: 0.0934 - val_acc: 0.9923
Epoch 28/200
 - 157s - loss: 0.0598 - acc: 0.9987 - val_loss: 1.1864 - val_acc: 0.6786
Epoch 29/200
 - 152s - loss: 0.0591 - acc: 0.9981 - val_loss: 0.2011 - val_acc: 0.9782
Epoch 30/200
 - 151s - loss: 0.0581 - acc: 0.9971 - val_loss: 0.2637 - val_acc: 0.9770
Epoch 31/200
 - 147s - loss: 0.0578 - acc: 0.9968 - val_loss: 0.1103 - val_acc: 0.9744
Epoch 32/200
 - 153s - loss: 0.0477 - acc: 1.0000 - val_loss: 0.0822 - val_acc: 0.9872
Epoch 33/200
 - 157s - loss: 0.0449 - acc: 1.0000 - val_loss: 0.1459 - val_acc: 0.9590
Epoch 34/200
 - 155s - loss: 0.0556 - acc: 0.9965 - val_loss: 1.6790 - val_acc: 0.5736
Epoch 35/200
 - 144s - loss: 0.0494 - acc: 0.9984 - val_loss: 1.8763 - val_acc: 0.6722
Epoch 36/200
 - 149s - loss: 0.0398 - acc: 1.0000 - val_loss: 0.4134 - val_acc: 0.8976
Epoch 37/200
 - 152s - loss: 0.0373 - acc: 1.0000 - val_loss: 0.0638 - val_acc: 0.9936
Epoch 38/200
 - 151s - loss: 0.0495 - acc: 0.9968 - val_loss: 0.3238 - val_acc: 0.9680
Epoch 39/200
 - 147s - loss: 0.0566 - acc: 0.9920 - val_loss: 0.2927 - val_acc: 0.9706
Epoch 40/200
 - 145s - loss: 0.0364 - acc: 0.9994 - val_loss: 0.3400 - val_acc: 0.9731
Epoch 41/200
 - 160s - loss: 0.0347 - acc: 0.9997 - val_loss: 0.1121 - val_acc: 0.9872
Epoch 42/200
 - 152s - loss: 0.0391 - acc: 0.9978 - val_loss: 0.0703 - val_acc: 0.9898
Epoch 43/200
 - 152s - loss: 0.0357 - acc: 0.9984 - val_loss: 0.0790 - val_acc: 0.9872
Epoch 44/200
 - 154s - loss: 0.0306 - acc: 0.9997 - val_loss: 0.1846 - val_acc: 0.9808
Epoch 45/200
 - 152s - loss: 0.0284 - acc: 1.0000 - val_loss: 0.1178 - val_acc: 0.9859
Epoch 46/200
 - 155s - loss: 0.0299 - acc: 0.9984 - val_loss: 0.2244 - val_acc: 0.9757
Epoch 47/200
 - 157s - loss: 0.0276 - acc: 0.9994 - val_loss: 0.1843 - val_acc: 0.9821
Epoch 48/200
 - 155s - loss: 0.0309 - acc: 0.9984 - val_loss: 0.2722 - val_acc: 0.9770
Epoch 49/200
 - 152s - loss: 0.0309 - acc: 0.9974 - val_loss: 0.0536 - val_acc: 0.9910
Epoch 50/200
 - 150s - loss: 0.0262 - acc: 0.9990 - val_loss: 0.0834 - val_acc: 0.9846
Epoch 51/200
 - 149s - loss: 0.0233 - acc: 1.0000 - val_loss: 0.0792 - val_acc: 0.9846
Epoch 52/200
 - 153s - loss: 0.0308 - acc: 0.9978 - val_loss: 0.3240 - val_acc: 0.9757
Epoch 53/200
 - 158s - loss: 0.0234 - acc: 0.9997 - val_loss: 0.1380 - val_acc: 0.9872
Epoch 54/200
 - 162s - loss: 0.0211 - acc: 1.0000 - val_loss: 0.1097 - val_acc: 0.9910
Epoch 55/200
 - 152s - loss: 0.0206 - acc: 0.9997 - val_loss: 0.0905 - val_acc: 0.9885
Epoch 56/200
 - 146s - loss: 0.0189 - acc: 1.0000 - val_loss: 0.0671 - val_acc: 0.9910
Epoch 57/200
 - 151s - loss: 0.0176 - acc: 1.0000 - val_loss: 0.0479 - val_acc: 0.9923
Epoch 58/200
 - 154s - loss: 0.0168 - acc: 0.9997 - val_loss: 0.4248 - val_acc: 0.9001
Epoch 59/200
 - 152s - loss: 0.0155 - acc: 1.0000 - val_loss: 0.0706 - val_acc: 0.9910
Epoch 60/200
 - 152s - loss: 0.0367 - acc: 0.9939 - val_loss: 0.1200 - val_acc: 0.9859
Epoch 61/200
 - 149s - loss: 0.0214 - acc: 0.9971 - val_loss: 0.0641 - val_acc: 0.9834
Epoch 62/200
 - 156s - loss: 0.0201 - acc: 0.9987 - val_loss: 0.2589 - val_acc: 0.9744
Epoch 63/200
 - 152s - loss: 0.0174 - acc: 0.9994 - val_loss: 0.2186 - val_acc: 0.9782
Epoch 64/200
 - 154s - loss: 0.0176 - acc: 0.9997 - val_loss: 0.1012 - val_acc: 0.9872
Epoch 65/200
 - 150s - loss: 0.0144 - acc: 1.0000 - val_loss: 0.0936 - val_acc: 0.9885
Epoch 66/200
 - 152s - loss: 0.0136 - acc: 1.0000 - val_loss: 0.0791 - val_acc: 0.9898
Epoch 67/200
 - 157s - loss: 0.0126 - acc: 1.0000 - val_loss: 0.0787 - val_acc: 0.9885
Epoch 68/200
 - 162s - loss: 0.0116 - acc: 1.0000 - val_loss: 0.0514 - val_acc: 0.9936
Epoch 69/200
 - 161s - loss: 0.0117 - acc: 0.9997 - val_loss: 0.1539 - val_acc: 0.9808
Epoch 70/200
 - 156s - loss: 0.0159 - acc: 0.9984 - val_loss: 0.5765 - val_acc: 0.8361
Epoch 71/200
 - 163s - loss: 0.0166 - acc: 0.9981 - val_loss: 0.0693 - val_acc: 0.9859
Epoch 72/200
 - 162s - loss: 0.0186 - acc: 0.9984 - val_loss: 0.0742 - val_acc: 0.9834
Restoring model weights from the end of the best epoch
Epoch 00072: early stopping
End-train DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Keras TF Training sig_bottles_4: 3899/3905 99.8%
              precision    recall  f1-score   support

           B       0.98      0.96      0.97        96
           V       1.00      1.00      1.00      3809

    accuracy                           1.00      3905
   macro avg       0.99      0.98      0.98      3905
weighted avg       1.00      1.00      1.00      3905

Keras TF Testing sig_bottles_4: 970/976 99.4%
              precision    recall  f1-score   support

           B       0.88      0.88      0.88        24
           V       1.00      1.00      1.00       952

    accuracy                           0.99       976
   macro avg       0.94      0.94      0.94       976
weighted avg       0.99      0.99      0.99       976

Keras TF CV sig_bottles_4: 2491/2519 98.9%
              precision    recall  f1-score   support

           B       0.71      0.90      0.80        61
           V       1.00      0.99      0.99      2458

    accuracy                           0.99      2519
   macro avg       0.86      0.95      0.90      2519
weighted avg       0.99      0.99      0.99      2519

Keras TF stop cnn_sig_bottles_4
trnargs = {'batch_size':32,'max_iter':200,'lay':[('conv2d',32,[5,5],[2,2]),('elu',),('batch',),('dropout',0.1),('pool',[2,2],[2,2]),('conv2d',32,[5,5],[2,2]),('elu',),('batch',),('dropout',0.1),('pool',[2,2],[2,2]),('flatten',),('ip',90),('relu',),('dropout',0.7)],'base_lr':0.0005, 'optimizer':'adadelta','val_split':0.2,'monitor': 'val_loss','patience':15, 'stop': True}
Keras TF start  cnn_pfa_bottles_4
Train DNN with Keras
Train on 3124 samples, validate on 781 samples
Epoch 1/200
 - 17s - loss: 0.2788 - acc: 0.9670 - val_loss: 0.2850 - val_acc: 0.9667
Epoch 2/200
 - 14s - loss: 0.2241 - acc: 0.9760 - val_loss: 0.2513 - val_acc: 0.9667
Epoch 3/200
 - 14s - loss: 0.1766 - acc: 0.9779 - val_loss: 0.1678 - val_acc: 0.9667
Epoch 4/200
 - 14s - loss: 0.1213 - acc: 0.9872 - val_loss: 0.1619 - val_acc: 0.9744
Epoch 5/200
 - 14s - loss: 0.0985 - acc: 0.9910 - val_loss: 0.1273 - val_acc: 0.9770
Epoch 6/200
 - 14s - loss: 0.0802 - acc: 0.9949 - val_loss: 0.0822 - val_acc: 0.9923
Epoch 7/200
 - 14s - loss: 0.0711 - acc: 0.9955 - val_loss: 0.0643 - val_acc: 0.9987
Epoch 8/200
 - 15s - loss: 0.0664 - acc: 0.9955 - val_loss: 0.1950 - val_acc: 0.9385
Epoch 9/200
 - 14s - loss: 0.0573 - acc: 0.9974 - val_loss: 0.0648 - val_acc: 0.9962
Epoch 10/200
 - 14s - loss: 0.0533 - acc: 0.9968 - val_loss: 0.0539 - val_acc: 0.9962
Epoch 11/200
 - 14s - loss: 0.0528 - acc: 0.9958 - val_loss: 0.0455 - val_acc: 0.9974
Epoch 12/200
 - 15s - loss: 0.0442 - acc: 0.9984 - val_loss: 0.0524 - val_acc: 0.9974
Epoch 13/200
 - 15s - loss: 0.0418 - acc: 0.9984 - val_loss: 0.0398 - val_acc: 0.9974
Epoch 14/200
 - 15s - loss: 0.0335 - acc: 0.9994 - val_loss: 0.0508 - val_acc: 0.9974
Epoch 15/200
 - 15s - loss: 0.0341 - acc: 0.9984 - val_loss: 0.0305 - val_acc: 0.9987
Epoch 16/200
 - 14s - loss: 0.0299 - acc: 0.9987 - val_loss: 0.0317 - val_acc: 0.9974
Epoch 17/200
 - 14s - loss: 0.0276 - acc: 0.9987 - val_loss: 0.0317 - val_acc: 0.9974
Epoch 18/200
 - 15s - loss: 0.0236 - acc: 0.9997 - val_loss: 0.0268 - val_acc: 0.9974
Epoch 19/200
 - 15s - loss: 0.0267 - acc: 0.9978 - val_loss: 0.0289 - val_acc: 0.9974
Epoch 20/200
 - 14s - loss: 0.0208 - acc: 0.9997 - val_loss: 0.0201 - val_acc: 1.0000
Epoch 21/200
 - 14s - loss: 0.0214 - acc: 0.9987 - val_loss: 0.0413 - val_acc: 0.9974
Epoch 22/200
 - 14s - loss: 0.0216 - acc: 0.9984 - val_loss: 0.0540 - val_acc: 0.9936
Epoch 23/200
 - 14s - loss: 0.0192 - acc: 0.9990 - val_loss: 0.1077 - val_acc: 0.9834
Epoch 24/200
 - 15s - loss: 0.0187 - acc: 0.9984 - val_loss: 0.0161 - val_acc: 0.9987
Epoch 25/200
 - 14s - loss: 0.0181 - acc: 0.9981 - val_loss: 0.0740 - val_acc: 0.9795
Epoch 26/200
 - 14s - loss: 0.0132 - acc: 1.0000 - val_loss: 0.0162 - val_acc: 0.9987
Epoch 27/200
 - 15s - loss: 0.0199 - acc: 0.9974 - val_loss: 0.0175 - val_acc: 0.9962
Epoch 28/200
 - 14s - loss: 0.0131 - acc: 0.9994 - val_loss: 0.0194 - val_acc: 0.9974
Epoch 29/200
 - 14s - loss: 0.0109 - acc: 1.0000 - val_loss: 0.0138 - val_acc: 0.9987
Epoch 30/200
 - 15s - loss: 0.0139 - acc: 0.9990 - val_loss: 0.0231 - val_acc: 0.9974
Epoch 31/200
 - 15s - loss: 0.0121 - acc: 0.9994 - val_loss: 0.0141 - val_acc: 0.9974
Epoch 32/200
 - 14s - loss: 0.0122 - acc: 0.9987 - val_loss: 0.0164 - val_acc: 0.9974
Epoch 33/200
 - 15s - loss: 0.0114 - acc: 0.9990 - val_loss: 0.0125 - val_acc: 0.9987
Epoch 34/200
 - 15s - loss: 0.0113 - acc: 0.9984 - val_loss: 0.0329 - val_acc: 0.9974
Epoch 35/200
 - 15s - loss: 0.0088 - acc: 0.9994 - val_loss: 0.0421 - val_acc: 0.9974
Epoch 36/200
 - 15s - loss: 0.0093 - acc: 0.9990 - val_loss: 0.0623 - val_acc: 0.9923
Epoch 37/200
 - 14s - loss: 0.0094 - acc: 0.9990 - val_loss: 0.0111 - val_acc: 0.9974
Epoch 38/200
 - 17s - loss: 0.0078 - acc: 0.9994 - val_loss: 0.0098 - val_acc: 0.9987
Epoch 39/200
 - 20s - loss: 0.0067 - acc: 1.0000 - val_loss: 0.0208 - val_acc: 0.9974
Epoch 40/200
 - 16s - loss: 0.0116 - acc: 0.9990 - val_loss: 0.8208 - val_acc: 0.7836
Epoch 41/200
 - 15s - loss: 0.0174 - acc: 0.9971 - val_loss: 0.0217 - val_acc: 0.9974
Epoch 42/200
 - 16s - loss: 0.0060 - acc: 1.0000 - val_loss: 0.0182 - val_acc: 0.9974
Epoch 43/200
 - 16s - loss: 0.0060 - acc: 1.0000 - val_loss: 0.0178 - val_acc: 0.9974
Epoch 44/200
 - 16s - loss: 0.0120 - acc: 0.9981 - val_loss: 0.0219 - val_acc: 0.9949
Epoch 45/200
 - 17s - loss: 0.0078 - acc: 0.9990 - val_loss: 0.0237 - val_acc: 0.9974
Epoch 46/200
 - 15s - loss: 0.0105 - acc: 0.9984 - val_loss: 0.0382 - val_acc: 0.9910
Epoch 47/200
 - 17s - loss: 0.0062 - acc: 0.9997 - val_loss: 0.0093 - val_acc: 0.9987
Epoch 48/200
 - 23s - loss: 0.0052 - acc: 1.0000 - val_loss: 0.0212 - val_acc: 0.9974
Epoch 49/200
 - 24s - loss: 0.0074 - acc: 0.9987 - val_loss: 0.0211 - val_acc: 0.9974
Epoch 50/200
 - 25s - loss: 0.0076 - acc: 0.9990 - val_loss: 0.0115 - val_acc: 0.9974
Epoch 51/200
 - 26s - loss: 0.0135 - acc: 0.9987 - val_loss: 0.0106 - val_acc: 0.9974
Epoch 52/200
 - 27s - loss: 0.0089 - acc: 0.9990 - val_loss: 0.0142 - val_acc: 0.9962
Epoch 53/200
 - 33s - loss: 0.0044 - acc: 1.0000 - val_loss: 0.0122 - val_acc: 0.9974
Epoch 54/200
 - 26s - loss: 0.0082 - acc: 0.9984 - val_loss: 0.0176 - val_acc: 0.9974
Epoch 55/200
 - 24s - loss: 0.0065 - acc: 0.9984 - val_loss: 0.0191 - val_acc: 0.9974
Epoch 56/200
 - 28s - loss: 0.0071 - acc: 0.9987 - val_loss: 0.0101 - val_acc: 0.9974
Epoch 57/200
 - 26s - loss: 0.0131 - acc: 0.9978 - val_loss: 0.0285 - val_acc: 0.9974
Epoch 58/200
 - 25s - loss: 0.0043 - acc: 1.0000 - val_loss: 0.0099 - val_acc: 0.9974
Epoch 59/200
 - 24s - loss: 0.0052 - acc: 0.9997 - val_loss: 0.0165 - val_acc: 0.9974
Epoch 60/200
 - 23s - loss: 0.0063 - acc: 0.9994 - val_loss: 0.0098 - val_acc: 0.9987
Epoch 61/200
 - 25s - loss: 0.0111 - acc: 0.9978 - val_loss: 0.0173 - val_acc: 0.9974
Epoch 62/200
 - 23s - loss: 0.0103 - acc: 0.9984 - val_loss: 0.0430 - val_acc: 0.9936
Restoring model weights from the end of the best epoch
Epoch 00062: early stopping
End-train DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Keras TF Training pfa_bottles_4: 3904/3905 100.0%
              precision    recall  f1-score   support

           B       1.00      0.99      0.99        96
           V       1.00      1.00      1.00      3809

    accuracy                           1.00      3905
   macro avg       1.00      0.99      1.00      3905
weighted avg       1.00      1.00      1.00      3905

Keras TF Testing pfa_bottles_4: 976/976 100.0%
              precision    recall  f1-score   support

           B       1.00      1.00      1.00        24
           V       1.00      1.00      1.00       952

    accuracy                           1.00       976
   macro avg       1.00      1.00      1.00       976
weighted avg       1.00      1.00      1.00       976

Keras TF CV pfa_bottles_4: 2509/2519 99.6%
              precision    recall  f1-score   support

           B       0.92      0.92      0.92        61
           V       1.00      1.00      1.00      2458

    accuracy                           1.00      2519
   macro avg       0.96      0.96      0.96      2519
weighted avg       1.00      1.00      1.00      2519

Keras TF stop cnn_pfa_bottles_4
trnargs = {'batch_size':32,'max_iter':200,'lay':[('conv2d',32,[5,5],[2,2]),('elu',),('batch',),('dropout',0.1),('pool',[2,2],[2,2]),('conv2d',32,[5,5],[2,2]),('elu',),('batch',),('dropout',0.1),('pool',[2,2],[2,2]),('flatten',),('ip',90),('relu',),('dropout',0.7)],'base_lr':0.0005, 'optimizer':'adadelta','val_split':0.2,'monitor': 'val_loss','patience':15, 'stop': True}
Keras TF start  cnn_sfa_bottles_4
Train DNN with Keras
Train on 3124 samples, validate on 781 samples
Epoch 1/200
 - 14s - loss: 0.2682 - acc: 0.9670 - val_loss: 0.2563 - val_acc: 0.9667
Epoch 2/200
 - 13s - loss: 0.1691 - acc: 0.9802 - val_loss: 0.1651 - val_acc: 0.9706
Epoch 3/200
 - 12s - loss: 0.1180 - acc: 0.9914 - val_loss: 0.1276 - val_acc: 0.9821
Epoch 4/200
 - 12s - loss: 0.0936 - acc: 0.9949 - val_loss: 0.0925 - val_acc: 0.9936
Epoch 5/200
 - 12s - loss: 0.0862 - acc: 0.9968 - val_loss: 0.0830 - val_acc: 0.9936
Epoch 6/200
 - 13s - loss: 0.0734 - acc: 0.9971 - val_loss: 0.0710 - val_acc: 0.9962
Epoch 7/200
 - 12s - loss: 0.0679 - acc: 0.9981 - val_loss: 0.0697 - val_acc: 0.9949
Epoch 8/200
 - 12s - loss: 0.0603 - acc: 0.9984 - val_loss: 0.0562 - val_acc: 0.9987
Epoch 9/200
 - 12s - loss: 0.0540 - acc: 0.9994 - val_loss: 0.0514 - val_acc: 0.9974
Epoch 10/200
 - 12s - loss: 0.0516 - acc: 0.9987 - val_loss: 0.0610 - val_acc: 0.9910
Epoch 11/200
 - 11s - loss: 0.0458 - acc: 0.9984 - val_loss: 0.0429 - val_acc: 0.9987
Epoch 12/200
 - 13s - loss: 0.0395 - acc: 0.9997 - val_loss: 0.0397 - val_acc: 0.9987
Epoch 13/200
 - 12s - loss: 0.0350 - acc: 0.9994 - val_loss: 0.0426 - val_acc: 0.9962
Epoch 14/200
 - 11s - loss: 0.0307 - acc: 0.9997 - val_loss: 0.0306 - val_acc: 0.9987
Epoch 15/200
 - 12s - loss: 0.0273 - acc: 0.9997 - val_loss: 0.0384 - val_acc: 0.9936
Epoch 16/200
 - 12s - loss: 0.0240 - acc: 0.9997 - val_loss: 0.0234 - val_acc: 1.0000
Epoch 17/200
 - 11s - loss: 0.0218 - acc: 0.9997 - val_loss: 0.0252 - val_acc: 0.9974
Epoch 18/200
 - 11s - loss: 0.0187 - acc: 1.0000 - val_loss: 0.0237 - val_acc: 0.9962
Epoch 19/200
 - 11s - loss: 0.0164 - acc: 1.0000 - val_loss: 0.0273 - val_acc: 0.9949
Epoch 20/200
 - 11s - loss: 0.0146 - acc: 0.9997 - val_loss: 0.0150 - val_acc: 0.9987
Epoch 21/200
 - 11s - loss: 0.0128 - acc: 1.0000 - val_loss: 0.0347 - val_acc: 0.9936
Epoch 22/200
 - 11s - loss: 0.0136 - acc: 0.9997 - val_loss: 0.0618 - val_acc: 0.9872
Epoch 23/200
 - 12s - loss: 0.0117 - acc: 0.9994 - val_loss: 0.0917 - val_acc: 0.9808
Epoch 24/200
 - 12s - loss: 0.0104 - acc: 1.0000 - val_loss: 0.0252 - val_acc: 0.9949
Epoch 25/200
 - 13s - loss: 0.0101 - acc: 0.9997 - val_loss: 0.0132 - val_acc: 0.9987
Epoch 26/200
 - 12s - loss: 0.0084 - acc: 1.0000 - val_loss: 0.0148 - val_acc: 0.9974
Epoch 27/200
 - 12s - loss: 0.0078 - acc: 0.9997 - val_loss: 0.0093 - val_acc: 1.0000
Epoch 28/200
 - 12s - loss: 0.0066 - acc: 1.0000 - val_loss: 0.0064 - val_acc: 1.0000
Epoch 29/200
 - 12s - loss: 0.0071 - acc: 0.9997 - val_loss: 0.0159 - val_acc: 0.9962
Epoch 30/200
 - 11s - loss: 0.0057 - acc: 1.0000 - val_loss: 0.0185 - val_acc: 0.9949
Epoch 31/200
 - 11s - loss: 0.0058 - acc: 0.9994 - val_loss: 0.0117 - val_acc: 0.9949
Epoch 32/200
 - 12s - loss: 0.0061 - acc: 0.9994 - val_loss: 0.0089 - val_acc: 0.9974
Epoch 33/200
 - 11s - loss: 0.0046 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 1.0000
Epoch 34/200
 - 12s - loss: 0.0042 - acc: 1.0000 - val_loss: 0.0090 - val_acc: 0.9962
Epoch 35/200
 - 11s - loss: 0.0050 - acc: 0.9994 - val_loss: 0.0044 - val_acc: 1.0000
Epoch 36/200
 - 11s - loss: 0.0038 - acc: 1.0000 - val_loss: 0.0080 - val_acc: 0.9974
Epoch 37/200
 - 11s - loss: 0.0041 - acc: 0.9994 - val_loss: 0.0117 - val_acc: 0.9936
Epoch 38/200
 - 11s - loss: 0.0045 - acc: 0.9990 - val_loss: 0.0217 - val_acc: 0.9936
Epoch 39/200
 - 11s - loss: 0.0034 - acc: 1.0000 - val_loss: 0.0088 - val_acc: 0.9974
Epoch 40/200
 - 13s - loss: 0.0028 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 1.0000
Epoch 41/200
 - 13s - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0276 - val_acc: 0.9936
Epoch 42/200
 - 12s - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0024 - val_acc: 1.0000
Epoch 43/200
 - 13s - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0037 - val_acc: 1.0000
Epoch 44/200
 - 13s - loss: 0.0053 - acc: 0.9994 - val_loss: 0.0028 - val_acc: 1.0000
Epoch 45/200
 - 14s - loss: 0.0028 - acc: 0.9997 - val_loss: 0.0067 - val_acc: 0.9974
Epoch 46/200
 - 12s - loss: 0.0044 - acc: 0.9987 - val_loss: 0.0059 - val_acc: 0.9987
Epoch 47/200
 - 12s - loss: 0.0045 - acc: 0.9997 - val_loss: 0.0568 - val_acc: 0.9846
Epoch 48/200
 - 11s - loss: 0.0037 - acc: 0.9994 - val_loss: 0.2002 - val_acc: 0.9347
Epoch 49/200
 - 11s - loss: 0.0035 - acc: 0.9997 - val_loss: 0.0384 - val_acc: 0.9898
Epoch 50/200
 - 12s - loss: 0.0030 - acc: 1.0000 - val_loss: 0.0171 - val_acc: 0.9949
Epoch 51/200
 - 12s - loss: 0.0026 - acc: 1.0000 - val_loss: 0.0025 - val_acc: 1.0000
Epoch 52/200
 - 15s - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0079 - val_acc: 0.9949
Epoch 53/200
 - 13s - loss: 0.0029 - acc: 0.9997 - val_loss: 0.1552 - val_acc: 0.9782
Epoch 54/200
 - 13s - loss: 0.0026 - acc: 0.9997 - val_loss: 0.0095 - val_acc: 0.9949
Epoch 55/200
 - 13s - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0030 - val_acc: 1.0000
Epoch 56/200
 - 14s - loss: 0.0050 - acc: 0.9994 - val_loss: 0.0023 - val_acc: 1.0000
Epoch 57/200
 - 21s - loss: 0.0082 - acc: 0.9984 - val_loss: 0.0050 - val_acc: 0.9987
Epoch 58/200
 - 19s - loss: 0.0035 - acc: 0.9997 - val_loss: 0.0096 - val_acc: 0.9949
Epoch 59/200
 - 20s - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000
Epoch 60/200
 - 21s - loss: 0.0035 - acc: 0.9994 - val_loss: 0.0057 - val_acc: 0.9974
Epoch 61/200
 - 22s - loss: 0.0020 - acc: 1.0000 - val_loss: 0.0029 - val_acc: 1.0000
Epoch 62/200
 - 20s - loss: 0.0044 - acc: 0.9990 - val_loss: 0.1554 - val_acc: 0.9782
Epoch 63/200
 - 22s - loss: 0.0040 - acc: 0.9990 - val_loss: 0.0070 - val_acc: 0.9987
Epoch 64/200
 - 26s - loss: 0.0073 - acc: 0.9981 - val_loss: 0.0583 - val_acc: 0.9808
Epoch 65/200
 - 20s - loss: 0.0027 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000
Epoch 66/200
 - 21s - loss: 0.0039 - acc: 0.9994 - val_loss: 0.0064 - val_acc: 0.9987
Epoch 67/200
 - 19s - loss: 0.0025 - acc: 1.0000 - val_loss: 0.0039 - val_acc: 1.0000
Epoch 68/200
 - 20s - loss: 0.0025 - acc: 0.9997 - val_loss: 0.0877 - val_acc: 0.9834
Epoch 69/200
 - 19s - loss: 0.0024 - acc: 1.0000 - val_loss: 0.1029 - val_acc: 0.9834
Epoch 70/200
 - 20s - loss: 0.0027 - acc: 0.9997 - val_loss: 0.0023 - val_acc: 1.0000
Epoch 71/200
 - 20s - loss: 0.0019 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000
Epoch 72/200
 - 14s - loss: 0.0047 - acc: 0.9994 - val_loss: 0.0051 - val_acc: 0.9974
Epoch 73/200
 - 12s - loss: 0.0022 - acc: 0.9997 - val_loss: 0.0125 - val_acc: 0.9962
Epoch 74/200
 - 11s - loss: 0.0044 - acc: 0.9997 - val_loss: 0.0043 - val_acc: 0.9987
Epoch 75/200
 - 11s - loss: 0.0028 - acc: 0.9994 - val_loss: 0.0166 - val_acc: 0.9949
Epoch 76/200
 - 13s - loss: 0.0024 - acc: 1.0000 - val_loss: 0.0442 - val_acc: 0.9910
Epoch 77/200
 - 13s - loss: 0.0021 - acc: 1.0000 - val_loss: 0.0040 - val_acc: 0.9987
Epoch 78/200
 - 12s - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0183 - val_acc: 0.9936
Epoch 79/200
 - 12s - loss: 0.0027 - acc: 0.9997 - val_loss: 0.0048 - val_acc: 0.9987
Epoch 80/200
 - 12s - loss: 0.0022 - acc: 1.0000 - val_loss: 0.0139 - val_acc: 0.9949
Epoch 81/200
 - 11s - loss: 0.0035 - acc: 0.9990 - val_loss: 0.0023 - val_acc: 1.0000
Epoch 82/200
 - 12s - loss: 0.0032 - acc: 0.9997 - val_loss: 0.0039 - val_acc: 0.9987
Epoch 83/200
 - 12s - loss: 0.0076 - acc: 0.9987 - val_loss: 0.0024 - val_acc: 1.0000
Epoch 84/200
 - 12s - loss: 0.0026 - acc: 0.9997 - val_loss: 0.0029 - val_acc: 1.0000
Epoch 85/200
 - 12s - loss: 0.0038 - acc: 0.9994 - val_loss: 0.0025 - val_acc: 1.0000
Epoch 86/200
 - 11s - loss: 0.0035 - acc: 0.9994 - val_loss: 0.0151 - val_acc: 0.9962
Restoring model weights from the end of the best epoch
Epoch 00086: early stopping
End-train DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Evaluate DNN with Keras
End evaluation DNN with Keras
Keras TF Training sfa_bottles_4: 3905/3905 100.0%
              precision    recall  f1-score   support

           B       1.00      1.00      1.00        96
           V       1.00      1.00      1.00      3809

    accuracy                           1.00      3905
   macro avg       1.00      1.00      1.00      3905
weighted avg       1.00      1.00      1.00      3905

Keras TF Testing sfa_bottles_4: 976/976 100.0%
              precision    recall  f1-score   support

           B       1.00      1.00      1.00        24
           V       1.00      1.00      1.00       952

    accuracy                           1.00       976
   macro avg       1.00      1.00      1.00       976
weighted avg       1.00      1.00      1.00       976

Keras TF CV sfa_bottles_4: 2507/2519 99.5%
              precision    recall  f1-score   support

           B       0.93      0.87      0.90        61
           V       1.00      1.00      1.00      2458

    accuracy                           1.00      2519
   macro avg       0.96      0.93      0.95      2519
weighted avg       1.00      1.00      1.00      2519

Keras TF stop cnn_sfa_bottles_4
svm start  sig_bottles_4
SVM Training sig_bottles_4: 3903/3905 99.9%
              precision    recall  f1-score   support

           B       0.98      1.00      0.99        96
           V       1.00      1.00      1.00      3809

    accuracy                           1.00      3905
   macro avg       0.99      1.00      0.99      3905
weighted avg       1.00      1.00      1.00      3905

SVM Testing sig_bottles_4: 971/976 99.5%
              precision    recall  f1-score   support

           B       0.88      0.92      0.90        24
           V       1.00      1.00      1.00       952

    accuracy                           0.99       976
   macro avg       0.94      0.96      0.95       976
weighted avg       0.99      0.99      0.99       976

SVM CV sig_bottles_4: 2401/2519 95.3%
              precision    recall  f1-score   support

           B       0.09      0.10      0.09        61
           V       0.98      0.97      0.98      2458

    accuracy                           0.95      2519
   macro avg       0.53      0.54      0.53      2519
weighted avg       0.96      0.95      0.95      2519

svm finish sig_bottles_4
svm start  pfa_bottles_4
SVM Training pfa_bottles_4: 3905/3905 100.0%
              precision    recall  f1-score   support

           B       1.00      1.00      1.00        96
           V       1.00      1.00      1.00      3809

    accuracy                           1.00      3905
   macro avg       1.00      1.00      1.00      3905
weighted avg       1.00      1.00      1.00      3905

SVM Testing pfa_bottles_4: 973/976 99.7%
              precision    recall  f1-score   support

           B       1.00      0.88      0.93        24
           V       1.00      1.00      1.00       952

    accuracy                           1.00       976
   macro avg       1.00      0.94      0.97       976
weighted avg       1.00      1.00      1.00       976

SVM CV pfa_bottles_4: 2494/2519 99.0%
              precision    recall  f1-score   support

           B       0.97      0.61      0.75        61
           V       0.99      1.00      0.99      2458

    accuracy                           0.99      2519
   macro avg       0.98      0.80      0.87      2519
weighted avg       0.99      0.99      0.99      2519

svm finish pfa_bottles_4
svm start  sfa_bottles_4
SVM Training sfa_bottles_4: 3905/3905 100.0%
              precision    recall  f1-score   support

           B       1.00      1.00      1.00        96
           V       1.00      1.00      1.00      3809

    accuracy                           1.00      3905
   macro avg       1.00      1.00      1.00      3905
weighted avg       1.00      1.00      1.00      3905

SVM Testing sfa_bottles_4: 969/976 99.3%
              precision    recall  f1-score   support

           B       1.00      0.71      0.83        24
           V       0.99      1.00      1.00       952

    accuracy                           0.99       976
   macro avg       1.00      0.85      0.91       976
weighted avg       0.99      0.99      0.99       976

SVM CV sfa_bottles_4: 2469/2519 98.0%
              precision    recall  f1-score   support

           B       0.92      0.20      0.32        61
           V       0.98      1.00      0.99      2458

    accuracy                           0.98      2519
   macro avg       0.95      0.60      0.66      2519
weighted avg       0.98      0.98      0.97      2519

svm finish sfa_bottles_4
trnargs = {'states':1, 'its': [0]}
hmm start  pfa_bottles_4
spl 0
CMP: 969/976 99.3%
HMM Training pfa_bottles_4: 3868/3905 99.1%
              precision    recall  f1-score   support

           B       0.72      1.00      0.84        96
           V       1.00      0.99      1.00      3809

    accuracy                           0.99      3905
   macro avg       0.86      1.00      0.92      3905
weighted avg       0.99      0.99      0.99      3905

HMM Testing pfa_bottles_4: 969/976 99.3%
              precision    recall  f1-score   support

           B       0.77      1.00      0.87        24
           V       1.00      0.99      1.00       952

    accuracy                           0.99       976
   macro avg       0.89      1.00      0.93       976
weighted avg       0.99      0.99      0.99       976

HMM CV pfa_bottles_4: 2488/2519 98.8%
              precision    recall  f1-score   support

           B       0.71      0.84      0.77        61
           V       1.00      0.99      0.99      2458

    accuracy                           0.99      2519
   macro avg       0.85      0.91      0.88      2519
weighted avg       0.99      0.99      0.99      2519

hmm start  sfa_bottles_4
spl 0
CMP: 825/976 84.5%
spl 0 ite 1
CMP: 946/976 96.9%
spl 0 ite 2
CMP: 963/976 98.7%
spl 0 ite 3
CMP: 966/976 99.0%
spl 1
CMP: 965/976 98.9%
spl 1 ite 1
CMP: 971/976 99.5%
spl 1 ite 2
CMP: 970/976 99.4%
spl 1 ite 3
CMP: 970/976 99.4%
spl 1 ite 4
CMP: 972/976 99.6%
spl 1 ite 5
CMP: 973/976 99.7%
spl 2
CMP: 972/976 99.6%
spl 2 ite 1
CMP: 975/976 99.9%
spl 2 ite 2
CMP: 975/976 99.9%
spl 2 ite 3
CMP: 975/976 99.9%
spl 2 ite 4
CMP: 975/976 99.9%
spl 2 ite 5
CMP: 975/976 99.9%
spl 2 ite 6
CMP: 975/976 99.9%
spl 2 ite 7
CMP: 975/976 99.9%
spl 3
CMP: 975/976 99.9%
spl 3 ite 1
CMP: 975/976 99.9%
spl 3 ite 2
CMP: 974/976 99.8%
spl 3 ite 3
CMP: 974/976 99.8%
spl 3 ite 4
CMP: 974/976 99.8%
spl 3 ite 5
CMP: 974/976 99.8%
spl 3 ite 6
CMP: 974/976 99.8%
spl 3 ite 7
CMP: 974/976 99.8%
spl 3 ite 8
CMP: 974/976 99.8%
spl 3 ite 9
CMP: 974/976 99.8%
spl 4
CMP: 974/976 99.8%
spl 4 ite 1
CMP: 974/976 99.8%
spl 4 ite 2
CMP: 974/976 99.8%
spl 4 ite 3
CMP: 974/976 99.8%
spl 4 ite 4
CMP: 974/976 99.8%
spl 4 ite 5
CMP: 973/976 99.7%
spl 4 ite 6
CMP: 973/976 99.7%
spl 4 ite 7
CMP: 973/976 99.7%
spl 4 ite 8
CMP: 973/976 99.7%
spl 4 ite 9
CMP: 973/976 99.7%
spl 4 ite 10
CMP: 973/976 99.7%
spl 4 ite 11
CMP: 973/976 99.7%
spl 5
CMP: 973/976 99.7%
spl 5 ite 1
CMP: 972/976 99.6%
spl 5 ite 2
CMP: 971/976 99.5%
spl 5 ite 3
CMP: 970/976 99.4%
spl 5 ite 4
CMP: 970/976 99.4%
spl 5 ite 5
CMP: 970/976 99.4%
spl 5 ite 6
CMP: 969/976 99.3%
spl 5 ite 7
CMP: 970/976 99.4%
spl 5 ite 8
CMP: 970/976 99.4%
spl 5 ite 9
CMP: 970/976 99.4%
spl 5 ite 10
CMP: 969/976 99.3%
spl 5 ite 11
CMP: 969/976 99.3%
spl 5 ite 12
CMP: 969/976 99.3%
spl 5 ite 13
CMP: 969/976 99.3%
HMM Training sfa_bottles_4: 3905/3905 100.0%
              precision    recall  f1-score   support

           B       1.00      1.00      1.00        96
           V       1.00      1.00      1.00      3809

    accuracy                           1.00      3905
   macro avg       1.00      1.00      1.00      3905
weighted avg       1.00      1.00      1.00      3905

HMM Testing sfa_bottles_4: 969/976 99.3%
              precision    recall  f1-score   support

           B       1.00      0.71      0.83        24
           V       0.99      1.00      1.00       952

    accuracy                           0.99       976
   macro avg       1.00      0.85      0.91       976
weighted avg       0.99      0.99      0.99       976

HMM CV sfa_bottles_4: 2489/2519 98.8%
              precision    recall  f1-score   support

           B       1.00      0.51      0.67        61
           V       0.99      1.00      0.99      2458

    accuracy                           0.99      2519
   macro avg       0.99      0.75      0.83      2519
weighted avg       0.99      0.99      0.99      2519

